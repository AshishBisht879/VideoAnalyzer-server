{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'inputs': {'gemini_results': [('Carvana', 1), ('Mustang', 1)], 'vi_results': [('Apple Store', 0.99), ('Google Store', 0.99)], 'ocr_text': [('Carvana', 1)]}, 'output': {'final': ['Carvana']}}, {'inputs': {'gemini_results': [('Breeze', 1), ('Febreze', 1)], 'vi_results': [('Febreze', 0.99), ('Procter & Gamble', 0.99)], 'ocr_text': [('Febreze', 0.9)]}, 'output': {'final': ['Febreze']}}, {'inputs': {'gemini_results': [('Dove', 1)], 'vi_results': [('Unilever', 0.99), ('Nike', 0.99)], 'ocr_text': [('Dove', 1), ('Unilever', 0.8)]}, 'output': {'final': ['Unilever', 'Dove']}}, {'inputs': {'gemini_results': [('Paramount+', 1)], 'vi_results': [('Paramount Network', 0.99)], 'ocr_text': [('Paramount+', 0.9)]}, 'output': {'final': ['Paramount+']}}, {'inputs': {'gemini_results': [('Discover Newport', 1)], 'vi_results': [], 'ocr_text': [('Discover Newport', 0.9)]}, 'output': {'final': ['Discover Newport']}}, {'inputs': {'gemini_results': [('Raymour & Flanigan', 1)], 'vi_results': [('Raymour & Flanigan', 0.99), (\"Macy's\", 0.99)], 'ocr_text': [('Raymour & Flanigan', 1)]}, 'output': {'final': ['Raymour & Flanigan']}}, {'inputs': {'gemini_results': [('Nectar', 1), ('Sealy', 1), ('Casper', 1), ('Serta', 1), ('Stearns & Foster', 1), ('SmartLife', 1), ('King Koil', 1)], 'vi_results': [('Raymour & Flanigan', 0.99), ('Sealy Corporation', 0.99)], 'ocr_text': [('Nectar', 0.9), ('Sealy', 0.8), ('Casper', 0.7), ('Serta', 0.6), ('Stearns & Foster', 0.5), ('SmartLife', 0.4), ('King Koil', 0.3)]}, 'output': {'final': ['SmartLife', 'Casper', 'Serta', 'King Koil', 'Stearns & Foster', 'Nectar', 'Sealy']}}, {'inputs': {'gemini_results': [('BETMGM', 1)], 'vi_results': [('National Hockey League', 0.99), ('Taco Bell', 0.99)], 'ocr_text': [('BETMGM', 1)]}, 'output': {'final': ['BETMGM']}}, {'inputs': {'gemini_results': [], 'vi_results': [], 'ocr_text': [('Missouri', 0.9)]}, 'output': {'final': ['Missouri']}}, {'inputs': {'gemini_results': [('Paramount+', 1)], 'vi_results': [('Paramount Network', 0.99)], 'ocr_text': [('Paramount+', 0.9)]}, 'output': {'final': ['Paramount+']}}, {'inputs': {'gemini_results': [('Raymour & Flanigan', 1)], 'vi_results': [('Raymour & Flanigan', 0.99)], 'ocr_text': [('Raymour & Flanigan', 0.9)]}, 'output': {'final': ['Raymour & Flanigan']}}, {'inputs': {'gemini_results': [('HelloFresh', 1), ('Peacock', 0.8)], 'vi_results': [('HelloFresh', 0.99)], 'ocr_text': [('HelloFresh', 0.95)]}, 'output': {'final': ['HelloFresh']}}, {'inputs': {'gemini_results': [('CREATION MUSEUM', 1)], 'vi_results': [], 'ocr_text': [('CREATION MUSEUM', 0.8)]}, 'output': {'final': ['CREATION MUSEUM']}}, {'inputs': {'gemini_results': [('Ruggable', 1)], 'vi_results': [], 'ocr_text': [('Ruggable', 0.9)]}, 'output': {'final': ['Ruggable']}}, {'inputs': {'gemini_results': [('WELLS FARGO', 1)], 'vi_results': [('Wells Fargo', 0.99), ('Visa Inc.', 0.99)], 'ocr_text': [('WELLS FARGO', 1)]}, 'output': {'final': ['WELLS FARGO']}}, {'inputs': {'gemini_results': [('Jacoby & Meyers', 1)], 'vi_results': [('Los Angeles Dodgers', 0.99)], 'ocr_text': [('Jacoby & Meyers', 0.9)]}, 'output': {'final': ['Jacoby & Meyers']}}, {'inputs': {'gemini_results': [('Ziploc', 1), ('Disney', 1), ('Pixar', 1), ('SC Johnson', 1)], 'vi_results': [('Ziploc', 0.99), ('The Walt Disney Company', 0.99)], 'ocr_text': [('Ziploc', 0.9), ('Disney PIXAR', 0.8)]}, 'output': {'final': ['Ziploc']}}, {'inputs': {'gemini_results': [('Xfinity', 1), ('Xfinity Mobile', 1)], 'vi_results': [('Comcast', 0.99)], 'ocr_text': [('Xfinity', 1)]}, 'output': {'final': ['Xfinity']}}, {'inputs': {'gemini_results': [('Comcast', 1)], 'vi_results': [('Comcast Business', 0.99), ('Mini', 0.99)], 'ocr_text': [('Comcast', 0.9)]}, 'output': {'final': ['Comcast']}}, {'inputs': {'gemini_results': [('Comcast Business', 1)], 'vi_results': [('Comcast Business', 0.99)], 'ocr_text': [('COMCAST BUSINESS', 1)]}, 'output': {'final': ['COMCAST BUSINESS']}}, {'inputs': {'gemini_results': [('Xfinity Mobile', 1)], 'vi_results': [], 'ocr_text': [('Xfinity Mobile', 0.95)]}, 'output': {'final': ['Xfinity Mobile']}}, {'inputs': {'gemini_results': [('Jacoby & Meyers', 1)], 'vi_results': [('Los Angeles Dodgers', 0.99)], 'ocr_text': [('Jacoby & Meyers', 0.95)]}, 'output': {'final': ['Jacoby & Meyers']}}, {'inputs': {'gemini_results': [('Mastercard', 1)], 'vi_results': [('Stand Up to Cancer', 0.99), ('Mastercard', 0.99)], 'ocr_text': [('Mastercard', 1)]}, 'output': {'final': ['Mastercard']}}, {'inputs': {'gemini_results': [('Ginger', 0.8), ('BETMGM', 0.9)], 'vi_results': [('NBA', 0.99)], 'ocr_text': [('BETMGM', 1)]}, 'output': {'final': ['BETMGM']}}, {'inputs': {'gemini_results': [], 'vi_results': [('Oris SA', 0.99)], 'ocr_text': [('ORIS', 0.8)]}, 'output': {'final': ['ORIS']}}, {'inputs': {'gemini_results': [('Safelite', 1)], 'vi_results': [('Safelite', 0.99), ('Nike', 0.99)], 'ocr_text': [('Safelite', 1)]}, 'output': {'final': ['Safelite']}}, {'inputs': {'gemini_results': [(\"Baker's\", 1), ('Fox', 1)], 'vi_results': [('KTVU', 0.99), ('Fox Broadcasting Company', 0.99)], 'ocr_text': [('AT&T', 0.9)]}, 'output': {'final': [\"Baker's\", 'Fox']}}, {'inputs': {'gemini_results': [('Freeform', 1), ('Hulu', 1)], 'vi_results': [('Hulu', 0.99)], 'ocr_text': [('Freeform', 0.9), ('hulu', 0.9)]}, 'output': {'final': ['Freeform', 'hulu']}}, {'inputs': {'gemini_results': [('Booking.com', 1), ('Disney', 1)], 'vi_results': [('The Walt Disney Company', 0.99)], 'ocr_text': [('Booking.com', 0.9)]}, 'output': {'final': ['Booking.com']}}, {'inputs': {'gemini_results': [('Paramount+', 0.8), ('Peridot Plus', 0.8)], 'vi_results': [('Paramount Network', 0.99)], 'ocr_text': [('Paramount+', 0.9)]}, 'output': {'final': ['Paramount+']}}, {'inputs': {'gemini_results': [('Sherwin-Williams', 1), ('Williams', 0.8)], 'vi_results': [('Sherwin-Williams', 0.99)], 'ocr_text': [('SHERWIN-WILLIAMS', 1)]}, 'output': {'final': ['SHERWIN-WILLIAMS']}}, {'inputs': {'gemini_results': [('Disney', 1), ('Hulu', 1), ('Google', 1), ('FX', 1), ('20th Century Studios', 1), ('Searchlight Pictures', 1)], 'vi_results': [('The Walt Disney Company', 0.99), ('Hulu', 0.99)], 'ocr_text': [('Disney', 0.9), ('Hulu', 0.8)]}, 'output': {'final': ['Hulu', 'Disney']}}, {'inputs': {'gemini_results': [('MADE IN COOKWARE', 1)], 'vi_results': [('Ballet National de Marseille', 0.99)], 'ocr_text': [('MADE IN COOKWARE', 0.9)]}, 'output': {'final': ['MADE IN COOKWARE']}}, {'inputs': {'gemini_results': [('Pandora', 1)], 'vi_results': [('Pandora', 0.99)], 'ocr_text': [('Pandora', 1)]}, 'output': {'final': ['Pandora']}}, {'inputs': {'gemini_results': [('Lincoln', 1)], 'vi_results': [], 'ocr_text': [('Lincoln', 1)]}, 'output': {'final': ['Lincoln']}}, {'inputs': {'gemini_results': [('U.S. Bank', 1)], 'vi_results': [('U.S. Bancorp', 0.99), ('Citroën', 0.99)], 'ocr_text': [('U.S. Bank', 0.9)]}, 'output': {'final': ['U.S. Bank']}}, {'inputs': {'gemini_results': [('Paramount+', 1), (\"RUPAUL'S DRAG RACE ALL STARS\", 1), ('BIG BROTHER', 1), ('THE CHALLENGE', 1), ('SURVIVOR', 1), ('ARE YOU THE ONE?', 1), ('INK MASTER', 1), ('QUEEN OF THE UNIVERSE', 1), ('BAR RESCUE', 1)], 'vi_results': [], 'ocr_text': [('Paramount+', 0.9), (\"RUPAUL'S DRAG RACE ALL STARS\", 0.8), ('BIG BROTHER', 0.8), ('THE CHALLENGE', 0.7), ('SURVIVOR', 0.6), ('ARE YOU THE ONE?', 0.5), ('INK MASTER', 0.4), ('QUEEN OF THE UNIVERSE', 0.4), ('BAR RESCUE', 0.3)]}, 'output': {'final': ['INK MASTER', \"RUPAUL'S DRAG RACE ALL STARS\", 'ARE YOU THE ONE?', 'Paramount+', 'QUEEN OF THE UNIVERSE', 'BIG BROTHER', 'SURVIVOR', 'THE CHALLENGE', 'BAR RESCUE']}}, {'inputs': {'gemini_results': [('MAIN EVENT', 1)], 'vi_results': [], 'ocr_text': [('MAIN EVENT', 0.9)]}, 'output': {'final': ['MAIN EVENT']}}, {'inputs': {'gemini_results': [], 'vi_results': [], 'ocr_text': [('Amazon Prime', 0.9)]}, 'output': {'final': ['Amazon Prime']}}, {'inputs': {'gemini_results': [('ARIAT', 1)], 'vi_results': [], 'ocr_text': [('ARIAT', 0.9)]}, 'output': {'final': ['ARIAT']}}, {'inputs': {'gemini_results': [('Bassett', 1)], 'vi_results': [('Bassett Furniture', 0.99)], 'ocr_text': [('Bassett', 1)]}, 'output': {'final': ['Bassett']}}, {'inputs': {'gemini_results': [('Taco Bell', 1)], 'vi_results': [('Taco Bell', 0.99)], 'ocr_text': [('Taco Bell', 1)]}, 'output': {'final': ['Taco Bell']}}, {'inputs': {'gemini_results': [('Bassett', 1)], 'vi_results': [('Bassett Furniture', 0.99)], 'ocr_text': [('Bassett', 1), ('Stearns & Foster', 0.8), ('Hunter Douglas', 0.8), ('Chanel', 0.2)]}, 'output': {'final': ['Bassett']}}, {'inputs': {'gemini_results': [('Taco Bell', 0.9)], 'vi_results': [('Taco Bell', 0.99)], 'ocr_text': [('Taco Bell', 1)]}, 'output': {'final': ['Taco Bell']}}]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "\n",
    "res = requests.get('http://35.222.204.206:5000/records')\n",
    "data = res.json()\n",
    "\n",
    "data_set = []\n",
    "\n",
    "for record in data:\n",
    "    \n",
    "    inputs={}\n",
    "    output={}\n",
    "    \n",
    "    transcript_result = record[\"brands_audio\"]\n",
    "    \n",
    "    if len(transcript_result[\"gemini_results\"]):\n",
    "        inputs[\"gemini_results\"] =[(k,v) for k,v in  transcript_result[\"gemini_results\"].items()]\n",
    "    else:\n",
    "        inputs[\"gemini_results\"] = []\n",
    "    \n",
    "    vi_results = [(k,v) for k,v in record[\"brands_video_gcp\"].items()]\n",
    "    \n",
    "    if len(vi_results):\n",
    "        inputs[\"vi_results\"] = vi_results\n",
    "    else:\n",
    "        inputs[\"vi_results\"]=[]\n",
    "    \n",
    "    \n",
    "    ocr_result = record[\"ocr_text\"]\n",
    "    \n",
    "    if len(ocr_result):\n",
    "        inputs[\"ocr_text\"] = [(k[\"brand\"],k[\"confidence\"]) for k in ocr_result]\n",
    "    else:\n",
    "        inputs[\"ocr_text\"] = []\n",
    "    \n",
    "    \n",
    "    output[\"final\"]=[k for k in record[\"final_brands\"]]\n",
    "    \n",
    "    data_set.append({\"inputs\":dict(inputs),\"output\":dict(output)})\n",
    "    \n",
    "    \n",
    "print(data_set)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal weights: [0. 0. 0.]\n",
      "Predictions: ['Disney']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from scipy.optimize import minimize\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "# Example dataset\n",
    "data =data_set\n",
    "\n",
    "\n",
    "# Extracting features and labels\n",
    "def repeat_brand_confidence(data_list):\n",
    "    repeated_list = []\n",
    "    for item in data_list:\n",
    "        repeated_list.extend([item[0]] * int(item[1] * 100))\n",
    "    return ' '.join(repeated_list)\n",
    "\n",
    "gemini_texts = [repeat_brand_confidence(entry['inputs']['gemini_results']) for entry in data]\n",
    "vi_texts = [repeat_brand_confidence(entry['inputs']['vi_results']) for entry in data]\n",
    "ocr_texts = [repeat_brand_confidence(entry['inputs']['ocr_text']) for entry in data]\n",
    "labels = [item['output']['final'][0] for item in data]\n",
    "\n",
    "# Creating the feature DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'gemini_texts': gemini_texts,\n",
    "    'vi_texts': vi_texts,\n",
    "    'ocr_texts': ocr_texts,\n",
    "    'labels': labels\n",
    "})\n",
    "\n",
    "# Combine all texts for a single vectorizer fit\n",
    "all_texts = gemini_texts + vi_texts + ocr_texts\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectorizer.fit(all_texts)\n",
    "\n",
    "# Transform each text set\n",
    "X_gemini = vectorizer.transform(gemini_texts)\n",
    "X_vi = vectorizer.transform(vi_texts)\n",
    "X_ocr = vectorizer.transform(ocr_texts)\n",
    "\n",
    "# Convert to dense arrays and handle NaNs\n",
    "X_gemini = csr_matrix(np.nan_to_num(X_gemini.toarray()))\n",
    "X_vi = csr_matrix(np.nan_to_num(X_vi.toarray()))\n",
    "X_ocr = csr_matrix(np.nan_to_num(X_ocr.toarray()))\n",
    "\n",
    "# Encode labels\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(df['labels'])\n",
    "\n",
    "# Weight calculation\n",
    "initial_weights = [1/3, 1/3, 1/3]\n",
    "\n",
    "# Loss function\n",
    "def loss_function(weights):\n",
    "    weighted_sum = weights[0] * X_gemini + weights[1] * X_vi + weights[2] * X_ocr\n",
    "    model = LogisticRegression(multi_class='ovr')\n",
    "    model.fit(weighted_sum, y)\n",
    "    preds = model.predict_proba(weighted_sum)\n",
    "    loss = -np.mean(np.sum(y[:, None] * np.log(preds), axis=1))\n",
    "    return loss\n",
    "\n",
    "# Optimize weights\n",
    "result = minimize(loss_function, initial_weights, bounds=[(0, 1), (0, 1), (0, 1)])\n",
    "optimal_weights = result.x\n",
    "\n",
    "# Train final model with optimal weights\n",
    "weighted_sum = optimal_weights[0] * X_gemini + optimal_weights[1] * X_vi + optimal_weights[2] * X_ocr\n",
    "final_model = LogisticRegression(multi_class='ovr')\n",
    "final_model.fit(weighted_sum, y)\n",
    "\n",
    "# Print results\n",
    "print(\"Optimal weights:\", optimal_weights)\n",
    "\n",
    "# Function to get predictions for new test samples\n",
    "def get_final_output(test_data, vectorizer, model, optimal_weights, label_encoder):\n",
    "    final_outputs = []\n",
    "    for entry in test_data:\n",
    "        gemini_text = repeat_brand_confidence(entry['inputs']['gemini_results'])\n",
    "        vi_text = repeat_brand_confidence(entry['inputs']['vi_results'])\n",
    "        ocr_text = repeat_brand_confidence(entry['inputs']['ocr_text'])\n",
    "        \n",
    "        X_gemini = vectorizer.transform([gemini_text])\n",
    "        X_vi = vectorizer.transform([vi_text])\n",
    "        X_ocr = vectorizer.transform([ocr_text])\n",
    "        \n",
    "        X_gemini = csr_matrix(np.nan_to_num(X_gemini.toarray()))\n",
    "        X_vi = csr_matrix(np.nan_to_num(X_vi.toarray()))\n",
    "        X_ocr = csr_matrix(np.nan_to_num(X_ocr.toarray()))\n",
    "        \n",
    "        weighted_sum = optimal_weights[0] * X_gemini + optimal_weights[1] * X_vi + optimal_weights[2] * X_ocr\n",
    "        \n",
    "        # Compute confidence scores for each brand in the inputs\n",
    "        all_results = entry['inputs']['gemini_results'] + entry['inputs']['vi_results'] + entry['inputs']['ocr_text']\n",
    "        brand_confidences = {}\n",
    "        for brand, confidence in all_results:\n",
    "            if brand not in brand_confidences:\n",
    "                brand_confidences[brand] = 0\n",
    "            brand_confidences[brand] += confidence\n",
    "        \n",
    "        # Adjust confidence scores using optimal weights\n",
    "        adjusted_confidences = {brand: confidence * sum(optimal_weights) for brand, confidence in brand_confidences.items()}\n",
    "        \n",
    "        # Find the brand with the highest adjusted confidence\n",
    "        final_brand = max(adjusted_confidences, key=adjusted_confidences.get)\n",
    "        final_outputs.append(final_brand)\n",
    "    \n",
    "    return final_outputs\n",
    "\n",
    "# Example test data\n",
    "test_data = [\n",
    "    {'inputs': {'gemini_results': [('Disney', 1.00), ('Ziploc', 1.00), ('SC Johnson', 1.00)], 'vi_results': [('Ziploc', 0.99), ('The Walt Disney Company', 0.99)], 'ocr_text': [('Disney', 0.90), ('Ziploc', 0.80), ('MIPS', 0.50)]}},\n",
    "]\n",
    "\n",
    "# Get predictions for test data\n",
    "predictions = get_final_output(test_data, vectorizer, final_model, optimal_weights, label_encoder)\n",
    "print(\"Predictions:\", predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current weights: [0.33333333 0.33333333 0.33333333], Loss: 2446.716176323632\n",
      "Current weights: [0.33333334 0.33333333 0.33333333], Loss: 2446.7161767418124\n",
      "Current weights: [0.33333333 0.33333334 0.33333333], Loss: 2446.7161767060675\n",
      "Current weights: [0.33333333 0.33333333 0.33333334], Loss: 2446.7161767665034\n",
      "Current weights: [0. 0. 0.], Loss: 2435.03838522478\n",
      "Current weights: [1.e-08 0.e+00 0.e+00], Loss: 2435.03838522478\n",
      "Current weights: [0.e+00 1.e-08 0.e+00], Loss: 2435.03838522478\n",
      "Current weights: [0.e+00 0.e+00 1.e-08], Loss: 2435.03838522478\n",
      "Optimal weights: [0. 0. 0.]\n",
      "Prediction: Disney, Confidence Score: 0.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from scipy.optimize import minimize\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "# Example dataset\n",
    "data = data_set\n",
    "# data = [\n",
    "#     {'inputs': {'gemini_results': [('Dove', 1)], 'vi_results': [('Unilever', 0.99), ('Nike', 0.99)], 'ocr_text': [('Dove', 1)]}, 'output': {'final': ['Dove']}},\n",
    "#     {'inputs': {'gemini_results': [('Nike', 1)], 'vi_results': [('Nike', 0.99), ('Adidas', 0.99)], 'ocr_text': [('Nike', 1)]}, 'output': {'final': ['Nike']}},\n",
    "#     {'inputs': {'gemini_results': [('Unilever', 0.5)], 'vi_results': [('Unilever', 0.6)], 'ocr_text': [('Unilever', 0.7)]}, 'output': {'final': ['Unilever']}}\n",
    "# ]\n",
    "\n",
    "\n",
    "# Extracting features and labels\n",
    "def repeat_brand_confidence(data_list):\n",
    "    repeated_list = []\n",
    "    for item in data_list:\n",
    "        repeated_list.extend([item[0]] * int(item[1] * 100))\n",
    "    return ' '.join(repeated_list)\n",
    "\n",
    "gemini_texts = [repeat_brand_confidence(entry['inputs']['gemini_results']) for entry in data]\n",
    "vi_texts = [repeat_brand_confidence(entry['inputs']['vi_results']) for entry in data]\n",
    "ocr_texts = [repeat_brand_confidence(entry['inputs']['ocr_text']) for entry in data]\n",
    "labels = [item['output']['final'][0] for item in data]\n",
    "\n",
    "# Creating the feature DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'gemini_texts': gemini_texts,\n",
    "    'vi_texts': vi_texts,\n",
    "    'ocr_texts': ocr_texts,\n",
    "    'labels': labels\n",
    "})\n",
    "\n",
    "# Combine all texts for a single vectorizer fit\n",
    "all_texts = gemini_texts + vi_texts + ocr_texts\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectorizer.fit(all_texts)\n",
    "\n",
    "# Transform each text set\n",
    "X_gemini = vectorizer.transform(gemini_texts)\n",
    "X_vi = vectorizer.transform(vi_texts)\n",
    "X_ocr = vectorizer.transform(ocr_texts)\n",
    "\n",
    "# Convert to dense arrays and handle NaNs\n",
    "X_gemini = csr_matrix(np.nan_to_num(X_gemini.toarray()))\n",
    "X_vi = csr_matrix(np.nan_to_num(X_vi.toarray()))\n",
    "X_ocr = csr_matrix(np.nan_to_num(X_ocr.toarray()))\n",
    "\n",
    "# Encode labels\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(df['labels'])\n",
    "\n",
    "# Weight calculation\n",
    "initial_weights = [1/3, 1/3, 1/3]\n",
    "\n",
    "# Regularization parameter\n",
    "C = 1.0\n",
    "\n",
    "# Loss function\n",
    "def loss_function(weights):\n",
    "    weighted_sum = weights[0] * X_gemini + weights[1] * X_vi + weights[2] * X_ocr\n",
    "    model = LogisticRegression(C=C, multi_class='ovr', max_iter=1000)\n",
    "    model.fit(weighted_sum, y)\n",
    "    preds = model.predict_proba(weighted_sum)\n",
    "    loss = -np.mean(np.sum(y[:, None] * np.log(preds), axis=1))\n",
    "    print(f\"Current weights: {weights}, Loss: {loss}\")  # Debugging step\n",
    "    return loss\n",
    "\n",
    "# Optimize weights\n",
    "result = minimize(loss_function, initial_weights, bounds=[(0, 1), (0, 1), (0, 1)])\n",
    "optimal_weights = result.x\n",
    "\n",
    "# Train final model with optimal weights\n",
    "weighted_sum = optimal_weights[0] * X_gemini + optimal_weights[1] * X_vi + optimal_weights[2] * X_ocr\n",
    "final_model = LogisticRegression(C=C, multi_class='ovr', max_iter=1000)\n",
    "final_model.fit(weighted_sum, y)\n",
    "\n",
    "# Print results\n",
    "print(\"Optimal weights:\", optimal_weights)\n",
    "\n",
    "# Function to get predictions and confidence scores for new test samples\n",
    "def get_final_output(test_data, vectorizer, model, optimal_weights, label_encoder):\n",
    "    final_outputs = []\n",
    "    confidence_scores = []\n",
    "    for entry in test_data:\n",
    "        gemini_text = repeat_brand_confidence(entry['inputs']['gemini_results'])\n",
    "        vi_text = repeat_brand_confidence(entry['inputs']['vi_results'])\n",
    "        ocr_text = repeat_brand_confidence(entry['inputs']['ocr_text'])\n",
    "        \n",
    "        X_gemini = vectorizer.transform([gemini_text])\n",
    "        X_vi = vectorizer.transform([vi_text])\n",
    "        X_ocr = vectorizer.transform([ocr_text])\n",
    "        \n",
    "        X_gemini = csr_matrix(np.nan_to_num(X_gemini.toarray()))\n",
    "        X_vi = csr_matrix(np.nan_to_num(X_vi.toarray()))\n",
    "        X_ocr = csr_matrix(np.nan_to_num(X_ocr.toarray()))\n",
    "        \n",
    "        weighted_sum = optimal_weights[0] * X_gemini + optimal_weights[1] * X_vi + optimal_weights[2] * X_ocr\n",
    "        \n",
    "        # Compute confidence scores for each brand in the inputs\n",
    "        all_results = entry['inputs']['gemini_results'] + entry['inputs']['vi_results'] + entry['inputs']['ocr_text']\n",
    "        brand_confidences = {}\n",
    "        for brand, confidence in all_results:\n",
    "            if brand not in brand_confidences:\n",
    "                brand_confidences[brand] = 0\n",
    "            brand_confidences[brand] += confidence\n",
    "        \n",
    "        # Adjust confidence scores using optimal weights\n",
    "        adjusted_confidences = {brand: confidence * sum(optimal_weights) for brand, confidence in brand_confidences.items()}\n",
    "        \n",
    "        # Find the brand with the highest adjusted confidence\n",
    "        final_brand = max(adjusted_confidences, key=adjusted_confidences.get)\n",
    "        final_outputs.append(final_brand)\n",
    "        confidence_scores.append(adjusted_confidences[final_brand])\n",
    "    \n",
    "    return final_outputs, confidence_scores\n",
    "\n",
    "# Example test data\n",
    "test_data = [\n",
    "    {'inputs': {'gemini_results': [('Disney', 1.00), ('Ziploc', 1.00), ('SC Johnson', 1.00)], 'vi_results': [('Ziploc', 0.99), ('The Walt Disney Company', 0.99)], 'ocr_text': [('Disney', 0.90), ('Ziploc', 0.80), ('MIPS', 0.50)]}},\n",
    "]\n",
    "\n",
    "# Get predictions and confidence scores for test data\n",
    "predictions, confidence_scores = get_final_output(test_data, vectorizer, final_model, optimal_weights, label_encoder)\n",
    "for prediction, confidence in zip(predictions, confidence_scores):\n",
    "    print(f\"Prediction: {prediction}, Confidence Score: {confidence}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'inputs': {'gemini_results': [('Carvana', 1), ('Mustang', 1)],\n",
       "   'vi_results': [('Apple Store', 0.99), ('Google Store', 0.99)],\n",
       "   'ocr_text': [('Carvana', 1)]},\n",
       "  'output': {'final': ['Carvana']}},\n",
       " {'inputs': {'gemini_results': [('Breeze', 1), ('Febreze', 1)],\n",
       "   'vi_results': [('Febreze', 0.99), ('Procter & Gamble', 0.99)],\n",
       "   'ocr_text': [('Febreze', 0.9)]},\n",
       "  'output': {'final': ['Febreze']}},\n",
       " {'inputs': {'gemini_results': [('Dove', 1)],\n",
       "   'vi_results': [('Unilever', 0.99), ('Nike', 0.99)],\n",
       "   'ocr_text': [('Dove', 1), ('Unilever', 0.8)]},\n",
       "  'output': {'final': ['Unilever', 'Dove']}},\n",
       " {'inputs': {'gemini_results': [('Paramount+', 1)],\n",
       "   'vi_results': [('Paramount Network', 0.99)],\n",
       "   'ocr_text': [('Paramount+', 0.9)]},\n",
       "  'output': {'final': ['Paramount+']}},\n",
       " {'inputs': {'gemini_results': [('Discover Newport', 1)],\n",
       "   'vi_results': [],\n",
       "   'ocr_text': [('Discover Newport', 0.9)]},\n",
       "  'output': {'final': ['Discover Newport']}},\n",
       " {'inputs': {'gemini_results': [('Raymour & Flanigan', 1)],\n",
       "   'vi_results': [('Raymour & Flanigan', 0.99), (\"Macy's\", 0.99)],\n",
       "   'ocr_text': [('Raymour & Flanigan', 1)]},\n",
       "  'output': {'final': ['Raymour & Flanigan']}},\n",
       " {'inputs': {'gemini_results': [('Nectar', 1),\n",
       "    ('Sealy', 1),\n",
       "    ('Casper', 1),\n",
       "    ('Serta', 1),\n",
       "    ('Stearns & Foster', 1),\n",
       "    ('SmartLife', 1),\n",
       "    ('King Koil', 1)],\n",
       "   'vi_results': [('Raymour & Flanigan', 0.99), ('Sealy Corporation', 0.99)],\n",
       "   'ocr_text': [('Nectar', 0.9),\n",
       "    ('Sealy', 0.8),\n",
       "    ('Casper', 0.7),\n",
       "    ('Serta', 0.6),\n",
       "    ('Stearns & Foster', 0.5),\n",
       "    ('SmartLife', 0.4),\n",
       "    ('King Koil', 0.3)]},\n",
       "  'output': {'final': ['SmartLife',\n",
       "    'Casper',\n",
       "    'Serta',\n",
       "    'King Koil',\n",
       "    'Stearns & Foster',\n",
       "    'Nectar',\n",
       "    'Sealy']}},\n",
       " {'inputs': {'gemini_results': [('BETMGM', 1)],\n",
       "   'vi_results': [('National Hockey League', 0.99), ('Taco Bell', 0.99)],\n",
       "   'ocr_text': [('BETMGM', 1)]},\n",
       "  'output': {'final': ['BETMGM']}},\n",
       " {'inputs': {'gemini_results': [],\n",
       "   'vi_results': [],\n",
       "   'ocr_text': [('Missouri', 0.9)]},\n",
       "  'output': {'final': ['Missouri']}},\n",
       " {'inputs': {'gemini_results': [('Paramount+', 1)],\n",
       "   'vi_results': [('Paramount Network', 0.99)],\n",
       "   'ocr_text': [('Paramount+', 0.9)]},\n",
       "  'output': {'final': ['Paramount+']}},\n",
       " {'inputs': {'gemini_results': [('Raymour & Flanigan', 1)],\n",
       "   'vi_results': [('Raymour & Flanigan', 0.99)],\n",
       "   'ocr_text': [('Raymour & Flanigan', 0.9)]},\n",
       "  'output': {'final': ['Raymour & Flanigan']}},\n",
       " {'inputs': {'gemini_results': [('HelloFresh', 1), ('Peacock', 0.8)],\n",
       "   'vi_results': [('HelloFresh', 0.99)],\n",
       "   'ocr_text': [('HelloFresh', 0.95)]},\n",
       "  'output': {'final': ['HelloFresh']}},\n",
       " {'inputs': {'gemini_results': [('CREATION MUSEUM', 1)],\n",
       "   'vi_results': [],\n",
       "   'ocr_text': [('CREATION MUSEUM', 0.8)]},\n",
       "  'output': {'final': ['CREATION MUSEUM']}},\n",
       " {'inputs': {'gemini_results': [('Ruggable', 1)],\n",
       "   'vi_results': [],\n",
       "   'ocr_text': [('Ruggable', 0.9)]},\n",
       "  'output': {'final': ['Ruggable']}},\n",
       " {'inputs': {'gemini_results': [('WELLS FARGO', 1)],\n",
       "   'vi_results': [('Wells Fargo', 0.99), ('Visa Inc.', 0.99)],\n",
       "   'ocr_text': [('WELLS FARGO', 1)]},\n",
       "  'output': {'final': ['WELLS FARGO']}},\n",
       " {'inputs': {'gemini_results': [('Jacoby & Meyers', 1)],\n",
       "   'vi_results': [('Los Angeles Dodgers', 0.99)],\n",
       "   'ocr_text': [('Jacoby & Meyers', 0.9)]},\n",
       "  'output': {'final': ['Jacoby & Meyers']}},\n",
       " {'inputs': {'gemini_results': [('Ziploc', 1),\n",
       "    ('Disney', 1),\n",
       "    ('Pixar', 1),\n",
       "    ('SC Johnson', 1)],\n",
       "   'vi_results': [('Ziploc', 0.99), ('The Walt Disney Company', 0.99)],\n",
       "   'ocr_text': [('Ziploc', 0.9), ('Disney PIXAR', 0.8)]},\n",
       "  'output': {'final': ['Ziploc']}},\n",
       " {'inputs': {'gemini_results': [('Xfinity', 1), ('Xfinity Mobile', 1)],\n",
       "   'vi_results': [('Comcast', 0.99)],\n",
       "   'ocr_text': [('Xfinity', 1)]},\n",
       "  'output': {'final': ['Xfinity']}},\n",
       " {'inputs': {'gemini_results': [('Comcast', 1)],\n",
       "   'vi_results': [('Comcast Business', 0.99), ('Mini', 0.99)],\n",
       "   'ocr_text': [('Comcast', 0.9)]},\n",
       "  'output': {'final': ['Comcast']}},\n",
       " {'inputs': {'gemini_results': [('Comcast Business', 1)],\n",
       "   'vi_results': [('Comcast Business', 0.99)],\n",
       "   'ocr_text': [('COMCAST BUSINESS', 1)]},\n",
       "  'output': {'final': ['COMCAST BUSINESS']}},\n",
       " {'inputs': {'gemini_results': [('Xfinity Mobile', 1)],\n",
       "   'vi_results': [],\n",
       "   'ocr_text': [('Xfinity Mobile', 0.95)]},\n",
       "  'output': {'final': ['Xfinity Mobile']}},\n",
       " {'inputs': {'gemini_results': [('Jacoby & Meyers', 1)],\n",
       "   'vi_results': [('Los Angeles Dodgers', 0.99)],\n",
       "   'ocr_text': [('Jacoby & Meyers', 0.95)]},\n",
       "  'output': {'final': ['Jacoby & Meyers']}},\n",
       " {'inputs': {'gemini_results': [('Mastercard', 1)],\n",
       "   'vi_results': [('Stand Up to Cancer', 0.99), ('Mastercard', 0.99)],\n",
       "   'ocr_text': [('Mastercard', 1)]},\n",
       "  'output': {'final': ['Mastercard']}},\n",
       " {'inputs': {'gemini_results': [('Ginger', 0.8), ('BETMGM', 0.9)],\n",
       "   'vi_results': [('NBA', 0.99)],\n",
       "   'ocr_text': [('BETMGM', 1)]},\n",
       "  'output': {'final': ['BETMGM']}},\n",
       " {'inputs': {'gemini_results': [],\n",
       "   'vi_results': [('Oris SA', 0.99)],\n",
       "   'ocr_text': [('ORIS', 0.8)]},\n",
       "  'output': {'final': ['ORIS']}},\n",
       " {'inputs': {'gemini_results': [('Safelite', 1)],\n",
       "   'vi_results': [('Safelite', 0.99), ('Nike', 0.99)],\n",
       "   'ocr_text': [('Safelite', 1)]},\n",
       "  'output': {'final': ['Safelite']}},\n",
       " {'inputs': {'gemini_results': [(\"Baker's\", 1), ('Fox', 1)],\n",
       "   'vi_results': [('KTVU', 0.99), ('Fox Broadcasting Company', 0.99)],\n",
       "   'ocr_text': [('AT&T', 0.9)]},\n",
       "  'output': {'final': [\"Baker's\", 'Fox']}},\n",
       " {'inputs': {'gemini_results': [('Freeform', 1), ('Hulu', 1)],\n",
       "   'vi_results': [('Hulu', 0.99)],\n",
       "   'ocr_text': [('Freeform', 0.9), ('hulu', 0.9)]},\n",
       "  'output': {'final': ['Freeform', 'hulu']}},\n",
       " {'inputs': {'gemini_results': [('Booking.com', 1), ('Disney', 1)],\n",
       "   'vi_results': [('The Walt Disney Company', 0.99)],\n",
       "   'ocr_text': [('Booking.com', 0.9)]},\n",
       "  'output': {'final': ['Booking.com']}},\n",
       " {'inputs': {'gemini_results': [('Paramount+', 0.8), ('Peridot Plus', 0.8)],\n",
       "   'vi_results': [('Paramount Network', 0.99)],\n",
       "   'ocr_text': [('Paramount+', 0.9)]},\n",
       "  'output': {'final': ['Paramount+']}},\n",
       " {'inputs': {'gemini_results': [('Sherwin-Williams', 1), ('Williams', 0.8)],\n",
       "   'vi_results': [('Sherwin-Williams', 0.99)],\n",
       "   'ocr_text': [('SHERWIN-WILLIAMS', 1)]},\n",
       "  'output': {'final': ['SHERWIN-WILLIAMS']}},\n",
       " {'inputs': {'gemini_results': [('Disney', 1),\n",
       "    ('Hulu', 1),\n",
       "    ('Google', 1),\n",
       "    ('FX', 1),\n",
       "    ('20th Century Studios', 1),\n",
       "    ('Searchlight Pictures', 1)],\n",
       "   'vi_results': [('The Walt Disney Company', 0.99), ('Hulu', 0.99)],\n",
       "   'ocr_text': [('Disney', 0.9), ('Hulu', 0.8)]},\n",
       "  'output': {'final': ['Hulu', 'Disney']}},\n",
       " {'inputs': {'gemini_results': [('MADE IN COOKWARE', 1)],\n",
       "   'vi_results': [('Ballet National de Marseille', 0.99)],\n",
       "   'ocr_text': [('MADE IN COOKWARE', 0.9)]},\n",
       "  'output': {'final': ['MADE IN COOKWARE']}},\n",
       " {'inputs': {'gemini_results': [('Pandora', 1)],\n",
       "   'vi_results': [('Pandora', 0.99)],\n",
       "   'ocr_text': [('Pandora', 1)]},\n",
       "  'output': {'final': ['Pandora']}},\n",
       " {'inputs': {'gemini_results': [('Lincoln', 1)],\n",
       "   'vi_results': [],\n",
       "   'ocr_text': [('Lincoln', 1)]},\n",
       "  'output': {'final': ['Lincoln']}},\n",
       " {'inputs': {'gemini_results': [('U.S. Bank', 1)],\n",
       "   'vi_results': [('U.S. Bancorp', 0.99), ('Citroën', 0.99)],\n",
       "   'ocr_text': [('U.S. Bank', 0.9)]},\n",
       "  'output': {'final': ['U.S. Bank']}},\n",
       " {'inputs': {'gemini_results': [('Paramount+', 1),\n",
       "    (\"RUPAUL'S DRAG RACE ALL STARS\", 1),\n",
       "    ('BIG BROTHER', 1),\n",
       "    ('THE CHALLENGE', 1),\n",
       "    ('SURVIVOR', 1),\n",
       "    ('ARE YOU THE ONE?', 1),\n",
       "    ('INK MASTER', 1),\n",
       "    ('QUEEN OF THE UNIVERSE', 1),\n",
       "    ('BAR RESCUE', 1)],\n",
       "   'vi_results': [],\n",
       "   'ocr_text': [('Paramount+', 0.9),\n",
       "    (\"RUPAUL'S DRAG RACE ALL STARS\", 0.8),\n",
       "    ('BIG BROTHER', 0.8),\n",
       "    ('THE CHALLENGE', 0.7),\n",
       "    ('SURVIVOR', 0.6),\n",
       "    ('ARE YOU THE ONE?', 0.5),\n",
       "    ('INK MASTER', 0.4),\n",
       "    ('QUEEN OF THE UNIVERSE', 0.4),\n",
       "    ('BAR RESCUE', 0.3)]},\n",
       "  'output': {'final': ['INK MASTER',\n",
       "    \"RUPAUL'S DRAG RACE ALL STARS\",\n",
       "    'ARE YOU THE ONE?',\n",
       "    'Paramount+',\n",
       "    'QUEEN OF THE UNIVERSE',\n",
       "    'BIG BROTHER',\n",
       "    'SURVIVOR',\n",
       "    'THE CHALLENGE',\n",
       "    'BAR RESCUE']}},\n",
       " {'inputs': {'gemini_results': [('MAIN EVENT', 1)],\n",
       "   'vi_results': [],\n",
       "   'ocr_text': [('MAIN EVENT', 0.9)]},\n",
       "  'output': {'final': ['MAIN EVENT']}},\n",
       " {'inputs': {'gemini_results': [],\n",
       "   'vi_results': [],\n",
       "   'ocr_text': [('Amazon Prime', 0.9)]},\n",
       "  'output': {'final': ['Amazon Prime']}},\n",
       " {'inputs': {'gemini_results': [('ARIAT', 1)],\n",
       "   'vi_results': [],\n",
       "   'ocr_text': [('ARIAT', 0.9)]},\n",
       "  'output': {'final': ['ARIAT']}},\n",
       " {'inputs': {'gemini_results': [('Bassett', 1)],\n",
       "   'vi_results': [('Bassett Furniture', 0.99)],\n",
       "   'ocr_text': [('Bassett', 1)]},\n",
       "  'output': {'final': ['Bassett']}},\n",
       " {'inputs': {'gemini_results': [('Taco Bell', 1)],\n",
       "   'vi_results': [('Taco Bell', 0.99)],\n",
       "   'ocr_text': [('Taco Bell', 1)]},\n",
       "  'output': {'final': ['Taco Bell']}},\n",
       " {'inputs': {'gemini_results': [('Bassett', 1)],\n",
       "   'vi_results': [('Bassett Furniture', 0.99)],\n",
       "   'ocr_text': [('Bassett', 1),\n",
       "    ('Stearns & Foster', 0.8),\n",
       "    ('Hunter Douglas', 0.8),\n",
       "    ('Chanel', 0.2)]},\n",
       "  'output': {'final': ['Bassett']}},\n",
       " {'inputs': {'gemini_results': [('Taco Bell', 0.9)],\n",
       "   'vi_results': [('Taco Bell', 0.99)],\n",
       "   'ocr_text': [('Taco Bell', 1)]},\n",
       "  'output': {'final': ['Taco Bell']}}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Loss: 7, Weights: [0.30952381 0.30952381 0.38095238] min_loss_Weights: [0.30952381 0.30952381 0.38095238] ads: [(2, {'inputs': {'gemini_results': [('Dove', 1)], 'vi_results': [('Unilever', 0.99), ('Nike', 0.99)], 'ocr_text': [('Dove', 1), ('Unilever', 0.8)]}, 'output': {'final': ['Unilever', 'Dove']}}), (6, {'inputs': {'gemini_results': [('Nectar', 1), ('Sealy', 1), ('Casper', 1), ('Serta', 1), ('Stearns & Foster', 1), ('SmartLife', 1), ('King Koil', 1)], 'vi_results': [('Raymour & Flanigan', 0.99), ('Sealy Corporation', 0.99)], 'ocr_text': [('Nectar', 0.9), ('Sealy', 0.8), ('Casper', 0.7), ('Serta', 0.6), ('Stearns & Foster', 0.5), ('SmartLife', 0.4), ('King Koil', 0.3)]}, 'output': {'final': ['SmartLife', 'Casper', 'Serta', 'King Koil', 'Stearns & Foster', 'Nectar', 'Sealy']}}), (19, {'inputs': {'gemini_results': [('Comcast Business', 1)], 'vi_results': [('Comcast Business', 0.99)], 'ocr_text': [('COMCAST BUSINESS', 1)]}, 'output': {'final': ['COMCAST BUSINESS']}}), (24, {'inputs': {'gemini_results': [], 'vi_results': [('Oris SA', 0.99)], 'ocr_text': [('ORIS', 0.8)]}, 'output': {'final': ['ORIS']}}), (27, {'inputs': {'gemini_results': [('Freeform', 1), ('Hulu', 1)], 'vi_results': [('Hulu', 0.99)], 'ocr_text': [('Freeform', 0.9), ('hulu', 0.9)]}, 'output': {'final': ['Freeform', 'hulu']}}), (30, {'inputs': {'gemini_results': [('Sherwin-Williams', 1), ('Williams', 0.8)], 'vi_results': [('Sherwin-Williams', 0.99)], 'ocr_text': [('SHERWIN-WILLIAMS', 1)]}, 'output': {'final': ['SHERWIN-WILLIAMS']}}), (36, {'inputs': {'gemini_results': [('Paramount+', 1), (\"RUPAUL'S DRAG RACE ALL STARS\", 1), ('BIG BROTHER', 1), ('THE CHALLENGE', 1), ('SURVIVOR', 1), ('ARE YOU THE ONE?', 1), ('INK MASTER', 1), ('QUEEN OF THE UNIVERSE', 1), ('BAR RESCUE', 1)], 'vi_results': [], 'ocr_text': [('Paramount+', 0.9), (\"RUPAUL'S DRAG RACE ALL STARS\", 0.8), ('BIG BROTHER', 0.8), ('THE CHALLENGE', 0.7), ('SURVIVOR', 0.6), ('ARE YOU THE ONE?', 0.5), ('INK MASTER', 0.4), ('QUEEN OF THE UNIVERSE', 0.4), ('BAR RESCUE', 0.3)]}, 'output': {'final': ['INK MASTER', \"RUPAUL'S DRAG RACE ALL STARS\", 'ARE YOU THE ONE?', 'Paramount+', 'QUEEN OF THE UNIVERSE', 'BIG BROTHER', 'SURVIVOR', 'THE CHALLENGE', 'BAR RESCUE']}})]\n",
      "Epoch 2/100, Loss: 7, Weights: [0.29543246 0.29543246 0.40913508] min_loss_Weights: [0.28952381 0.28952381 0.40095238] ads: [(2, {'inputs': {'gemini_results': [('Dove', 1)], 'vi_results': [('Unilever', 0.99), ('Nike', 0.99)], 'ocr_text': [('Dove', 1), ('Unilever', 0.8)]}, 'output': {'final': ['Unilever', 'Dove']}}), (6, {'inputs': {'gemini_results': [('Nectar', 1), ('Sealy', 1), ('Casper', 1), ('Serta', 1), ('Stearns & Foster', 1), ('SmartLife', 1), ('King Koil', 1)], 'vi_results': [('Raymour & Flanigan', 0.99), ('Sealy Corporation', 0.99)], 'ocr_text': [('Nectar', 0.9), ('Sealy', 0.8), ('Casper', 0.7), ('Serta', 0.6), ('Stearns & Foster', 0.5), ('SmartLife', 0.4), ('King Koil', 0.3)]}, 'output': {'final': ['SmartLife', 'Casper', 'Serta', 'King Koil', 'Stearns & Foster', 'Nectar', 'Sealy']}}), (19, {'inputs': {'gemini_results': [('Comcast Business', 1)], 'vi_results': [('Comcast Business', 0.99)], 'ocr_text': [('COMCAST BUSINESS', 1)]}, 'output': {'final': ['COMCAST BUSINESS']}}), (24, {'inputs': {'gemini_results': [], 'vi_results': [('Oris SA', 0.99)], 'ocr_text': [('ORIS', 0.8)]}, 'output': {'final': ['ORIS']}}), (27, {'inputs': {'gemini_results': [('Freeform', 1), ('Hulu', 1)], 'vi_results': [('Hulu', 0.99)], 'ocr_text': [('Freeform', 0.9), ('hulu', 0.9)]}, 'output': {'final': ['Freeform', 'hulu']}}), (30, {'inputs': {'gemini_results': [('Sherwin-Williams', 1), ('Williams', 0.8)], 'vi_results': [('Sherwin-Williams', 0.99)], 'ocr_text': [('SHERWIN-WILLIAMS', 1)]}, 'output': {'final': ['SHERWIN-WILLIAMS']}}), (36, {'inputs': {'gemini_results': [('Paramount+', 1), (\"RUPAUL'S DRAG RACE ALL STARS\", 1), ('BIG BROTHER', 1), ('THE CHALLENGE', 1), ('SURVIVOR', 1), ('ARE YOU THE ONE?', 1), ('INK MASTER', 1), ('QUEEN OF THE UNIVERSE', 1), ('BAR RESCUE', 1)], 'vi_results': [], 'ocr_text': [('Paramount+', 0.9), (\"RUPAUL'S DRAG RACE ALL STARS\", 0.8), ('BIG BROTHER', 0.8), ('THE CHALLENGE', 0.7), ('SURVIVOR', 0.6), ('ARE YOU THE ONE?', 0.5), ('INK MASTER', 0.4), ('QUEEN OF THE UNIVERSE', 0.4), ('BAR RESCUE', 0.3)]}, 'output': {'final': ['INK MASTER', \"RUPAUL'S DRAG RACE ALL STARS\", 'ARE YOU THE ONE?', 'Paramount+', 'QUEEN OF THE UNIVERSE', 'BIG BROTHER', 'SURVIVOR', 'THE CHALLENGE', 'BAR RESCUE']}})]\n",
      "Epoch 3/100, Loss: 6, Weights: [0.28105353 0.29125761 0.42768886] min_loss_Weights: [0.28105353 0.29125761 0.42768886] ads: [(2, {'inputs': {'gemini_results': [('Dove', 1)], 'vi_results': [('Unilever', 0.99), ('Nike', 0.99)], 'ocr_text': [('Dove', 1), ('Unilever', 0.8)]}, 'output': {'final': ['Unilever', 'Dove']}}), (6, {'inputs': {'gemini_results': [('Nectar', 1), ('Sealy', 1), ('Casper', 1), ('Serta', 1), ('Stearns & Foster', 1), ('SmartLife', 1), ('King Koil', 1)], 'vi_results': [('Raymour & Flanigan', 0.99), ('Sealy Corporation', 0.99)], 'ocr_text': [('Nectar', 0.9), ('Sealy', 0.8), ('Casper', 0.7), ('Serta', 0.6), ('Stearns & Foster', 0.5), ('SmartLife', 0.4), ('King Koil', 0.3)]}, 'output': {'final': ['SmartLife', 'Casper', 'Serta', 'King Koil', 'Stearns & Foster', 'Nectar', 'Sealy']}}), (19, {'inputs': {'gemini_results': [('Comcast Business', 1)], 'vi_results': [('Comcast Business', 0.99)], 'ocr_text': [('COMCAST BUSINESS', 1)]}, 'output': {'final': ['COMCAST BUSINESS']}}), (26, {'inputs': {'gemini_results': [(\"Baker's\", 1), ('Fox', 1)], 'vi_results': [('KTVU', 0.99), ('Fox Broadcasting Company', 0.99)], 'ocr_text': [('AT&T', 0.9)]}, 'output': {'final': [\"Baker's\", 'Fox']}}), (30, {'inputs': {'gemini_results': [('Sherwin-Williams', 1), ('Williams', 0.8)], 'vi_results': [('Sherwin-Williams', 0.99)], 'ocr_text': [('SHERWIN-WILLIAMS', 1)]}, 'output': {'final': ['SHERWIN-WILLIAMS']}}), (36, {'inputs': {'gemini_results': [('Paramount+', 1), (\"RUPAUL'S DRAG RACE ALL STARS\", 1), ('BIG BROTHER', 1), ('THE CHALLENGE', 1), ('SURVIVOR', 1), ('ARE YOU THE ONE?', 1), ('INK MASTER', 1), ('QUEEN OF THE UNIVERSE', 1), ('BAR RESCUE', 1)], 'vi_results': [], 'ocr_text': [('Paramount+', 0.9), (\"RUPAUL'S DRAG RACE ALL STARS\", 0.8), ('BIG BROTHER', 0.8), ('THE CHALLENGE', 0.7), ('SURVIVOR', 0.6), ('ARE YOU THE ONE?', 0.5), ('INK MASTER', 0.4), ('QUEEN OF THE UNIVERSE', 0.4), ('BAR RESCUE', 0.3)]}, 'output': {'final': ['INK MASTER', \"RUPAUL'S DRAG RACE ALL STARS\", 'ARE YOU THE ONE?', 'Paramount+', 'QUEEN OF THE UNIVERSE', 'BIG BROTHER', 'SURVIVOR', 'THE CHALLENGE', 'BAR RESCUE']}})]\n",
      "Epoch 4/100, Loss: 6, Weights: [0.26638115 0.28699756 0.44662129] min_loss_Weights: [0.26105353 0.28125761 0.43768886] ads: [(2, {'inputs': {'gemini_results': [('Dove', 1)], 'vi_results': [('Unilever', 0.99), ('Nike', 0.99)], 'ocr_text': [('Dove', 1), ('Unilever', 0.8)]}, 'output': {'final': ['Unilever', 'Dove']}}), (6, {'inputs': {'gemini_results': [('Nectar', 1), ('Sealy', 1), ('Casper', 1), ('Serta', 1), ('Stearns & Foster', 1), ('SmartLife', 1), ('King Koil', 1)], 'vi_results': [('Raymour & Flanigan', 0.99), ('Sealy Corporation', 0.99)], 'ocr_text': [('Nectar', 0.9), ('Sealy', 0.8), ('Casper', 0.7), ('Serta', 0.6), ('Stearns & Foster', 0.5), ('SmartLife', 0.4), ('King Koil', 0.3)]}, 'output': {'final': ['SmartLife', 'Casper', 'Serta', 'King Koil', 'Stearns & Foster', 'Nectar', 'Sealy']}}), (19, {'inputs': {'gemini_results': [('Comcast Business', 1)], 'vi_results': [('Comcast Business', 0.99)], 'ocr_text': [('COMCAST BUSINESS', 1)]}, 'output': {'final': ['COMCAST BUSINESS']}}), (26, {'inputs': {'gemini_results': [(\"Baker's\", 1), ('Fox', 1)], 'vi_results': [('KTVU', 0.99), ('Fox Broadcasting Company', 0.99)], 'ocr_text': [('AT&T', 0.9)]}, 'output': {'final': [\"Baker's\", 'Fox']}}), (30, {'inputs': {'gemini_results': [('Sherwin-Williams', 1), ('Williams', 0.8)], 'vi_results': [('Sherwin-Williams', 0.99)], 'ocr_text': [('SHERWIN-WILLIAMS', 1)]}, 'output': {'final': ['SHERWIN-WILLIAMS']}}), (36, {'inputs': {'gemini_results': [('Paramount+', 1), (\"RUPAUL'S DRAG RACE ALL STARS\", 1), ('BIG BROTHER', 1), ('THE CHALLENGE', 1), ('SURVIVOR', 1), ('ARE YOU THE ONE?', 1), ('INK MASTER', 1), ('QUEEN OF THE UNIVERSE', 1), ('BAR RESCUE', 1)], 'vi_results': [], 'ocr_text': [('Paramount+', 0.9), (\"RUPAUL'S DRAG RACE ALL STARS\", 0.8), ('BIG BROTHER', 0.8), ('THE CHALLENGE', 0.7), ('SURVIVOR', 0.6), ('ARE YOU THE ONE?', 0.5), ('INK MASTER', 0.4), ('QUEEN OF THE UNIVERSE', 0.4), ('BAR RESCUE', 0.3)]}, 'output': {'final': ['INK MASTER', \"RUPAUL'S DRAG RACE ALL STARS\", 'ARE YOU THE ONE?', 'Paramount+', 'QUEEN OF THE UNIVERSE', 'BIG BROTHER', 'SURVIVOR', 'THE CHALLENGE', 'BAR RESCUE']}})]\n",
      "Epoch 5/100, Loss: 6, Weights: [0.25140934 0.28265057 0.46594009] min_loss_Weights: [0.26105353 0.28125761 0.43768886] ads: [(2, {'inputs': {'gemini_results': [('Dove', 1)], 'vi_results': [('Unilever', 0.99), ('Nike', 0.99)], 'ocr_text': [('Dove', 1), ('Unilever', 0.8)]}, 'output': {'final': ['Unilever', 'Dove']}}), (6, {'inputs': {'gemini_results': [('Nectar', 1), ('Sealy', 1), ('Casper', 1), ('Serta', 1), ('Stearns & Foster', 1), ('SmartLife', 1), ('King Koil', 1)], 'vi_results': [('Raymour & Flanigan', 0.99), ('Sealy Corporation', 0.99)], 'ocr_text': [('Nectar', 0.9), ('Sealy', 0.8), ('Casper', 0.7), ('Serta', 0.6), ('Stearns & Foster', 0.5), ('SmartLife', 0.4), ('King Koil', 0.3)]}, 'output': {'final': ['SmartLife', 'Casper', 'Serta', 'King Koil', 'Stearns & Foster', 'Nectar', 'Sealy']}}), (19, {'inputs': {'gemini_results': [('Comcast Business', 1)], 'vi_results': [('Comcast Business', 0.99)], 'ocr_text': [('COMCAST BUSINESS', 1)]}, 'output': {'final': ['COMCAST BUSINESS']}}), (26, {'inputs': {'gemini_results': [(\"Baker's\", 1), ('Fox', 1)], 'vi_results': [('KTVU', 0.99), ('Fox Broadcasting Company', 0.99)], 'ocr_text': [('AT&T', 0.9)]}, 'output': {'final': [\"Baker's\", 'Fox']}}), (30, {'inputs': {'gemini_results': [('Sherwin-Williams', 1), ('Williams', 0.8)], 'vi_results': [('Sherwin-Williams', 0.99)], 'ocr_text': [('SHERWIN-WILLIAMS', 1)]}, 'output': {'final': ['SHERWIN-WILLIAMS']}}), (36, {'inputs': {'gemini_results': [('Paramount+', 1), (\"RUPAUL'S DRAG RACE ALL STARS\", 1), ('BIG BROTHER', 1), ('THE CHALLENGE', 1), ('SURVIVOR', 1), ('ARE YOU THE ONE?', 1), ('INK MASTER', 1), ('QUEEN OF THE UNIVERSE', 1), ('BAR RESCUE', 1)], 'vi_results': [], 'ocr_text': [('Paramount+', 0.9), (\"RUPAUL'S DRAG RACE ALL STARS\", 0.8), ('BIG BROTHER', 0.8), ('THE CHALLENGE', 0.7), ('SURVIVOR', 0.6), ('ARE YOU THE ONE?', 0.5), ('INK MASTER', 0.4), ('QUEEN OF THE UNIVERSE', 0.4), ('BAR RESCUE', 0.3)]}, 'output': {'final': ['INK MASTER', \"RUPAUL'S DRAG RACE ALL STARS\", 'ARE YOU THE ONE?', 'Paramount+', 'QUEEN OF THE UNIVERSE', 'BIG BROTHER', 'SURVIVOR', 'THE CHALLENGE', 'BAR RESCUE']}})]\n",
      "Epoch 6/100, Loss: 6, Weights: [0.23613198 0.27821487 0.48565315] min_loss_Weights: [0.26105353 0.28125761 0.43768886] ads: [(2, {'inputs': {'gemini_results': [('Dove', 1)], 'vi_results': [('Unilever', 0.99), ('Nike', 0.99)], 'ocr_text': [('Dove', 1), ('Unilever', 0.8)]}, 'output': {'final': ['Unilever', 'Dove']}}), (6, {'inputs': {'gemini_results': [('Nectar', 1), ('Sealy', 1), ('Casper', 1), ('Serta', 1), ('Stearns & Foster', 1), ('SmartLife', 1), ('King Koil', 1)], 'vi_results': [('Raymour & Flanigan', 0.99), ('Sealy Corporation', 0.99)], 'ocr_text': [('Nectar', 0.9), ('Sealy', 0.8), ('Casper', 0.7), ('Serta', 0.6), ('Stearns & Foster', 0.5), ('SmartLife', 0.4), ('King Koil', 0.3)]}, 'output': {'final': ['SmartLife', 'Casper', 'Serta', 'King Koil', 'Stearns & Foster', 'Nectar', 'Sealy']}}), (19, {'inputs': {'gemini_results': [('Comcast Business', 1)], 'vi_results': [('Comcast Business', 0.99)], 'ocr_text': [('COMCAST BUSINESS', 1)]}, 'output': {'final': ['COMCAST BUSINESS']}}), (26, {'inputs': {'gemini_results': [(\"Baker's\", 1), ('Fox', 1)], 'vi_results': [('KTVU', 0.99), ('Fox Broadcasting Company', 0.99)], 'ocr_text': [('AT&T', 0.9)]}, 'output': {'final': [\"Baker's\", 'Fox']}}), (30, {'inputs': {'gemini_results': [('Sherwin-Williams', 1), ('Williams', 0.8)], 'vi_results': [('Sherwin-Williams', 0.99)], 'ocr_text': [('SHERWIN-WILLIAMS', 1)]}, 'output': {'final': ['SHERWIN-WILLIAMS']}}), (36, {'inputs': {'gemini_results': [('Paramount+', 1), (\"RUPAUL'S DRAG RACE ALL STARS\", 1), ('BIG BROTHER', 1), ('THE CHALLENGE', 1), ('SURVIVOR', 1), ('ARE YOU THE ONE?', 1), ('INK MASTER', 1), ('QUEEN OF THE UNIVERSE', 1), ('BAR RESCUE', 1)], 'vi_results': [], 'ocr_text': [('Paramount+', 0.9), (\"RUPAUL'S DRAG RACE ALL STARS\", 0.8), ('BIG BROTHER', 0.8), ('THE CHALLENGE', 0.7), ('SURVIVOR', 0.6), ('ARE YOU THE ONE?', 0.5), ('INK MASTER', 0.4), ('QUEEN OF THE UNIVERSE', 0.4), ('BAR RESCUE', 0.3)]}, 'output': {'final': ['INK MASTER', \"RUPAUL'S DRAG RACE ALL STARS\", 'ARE YOU THE ONE?', 'Paramount+', 'QUEEN OF THE UNIVERSE', 'BIG BROTHER', 'SURVIVOR', 'THE CHALLENGE', 'BAR RESCUE']}})]\n",
      "Epoch 7/100, Loss: 6, Weights: [0.22054284 0.27368864 0.50576852] min_loss_Weights: [0.26105353 0.28125761 0.43768886] ads: [(2, {'inputs': {'gemini_results': [('Dove', 1)], 'vi_results': [('Unilever', 0.99), ('Nike', 0.99)], 'ocr_text': [('Dove', 1), ('Unilever', 0.8)]}, 'output': {'final': ['Unilever', 'Dove']}}), (6, {'inputs': {'gemini_results': [('Nectar', 1), ('Sealy', 1), ('Casper', 1), ('Serta', 1), ('Stearns & Foster', 1), ('SmartLife', 1), ('King Koil', 1)], 'vi_results': [('Raymour & Flanigan', 0.99), ('Sealy Corporation', 0.99)], 'ocr_text': [('Nectar', 0.9), ('Sealy', 0.8), ('Casper', 0.7), ('Serta', 0.6), ('Stearns & Foster', 0.5), ('SmartLife', 0.4), ('King Koil', 0.3)]}, 'output': {'final': ['SmartLife', 'Casper', 'Serta', 'King Koil', 'Stearns & Foster', 'Nectar', 'Sealy']}}), (19, {'inputs': {'gemini_results': [('Comcast Business', 1)], 'vi_results': [('Comcast Business', 0.99)], 'ocr_text': [('COMCAST BUSINESS', 1)]}, 'output': {'final': ['COMCAST BUSINESS']}}), (26, {'inputs': {'gemini_results': [(\"Baker's\", 1), ('Fox', 1)], 'vi_results': [('KTVU', 0.99), ('Fox Broadcasting Company', 0.99)], 'ocr_text': [('AT&T', 0.9)]}, 'output': {'final': [\"Baker's\", 'Fox']}}), (30, {'inputs': {'gemini_results': [('Sherwin-Williams', 1), ('Williams', 0.8)], 'vi_results': [('Sherwin-Williams', 0.99)], 'ocr_text': [('SHERWIN-WILLIAMS', 1)]}, 'output': {'final': ['SHERWIN-WILLIAMS']}}), (36, {'inputs': {'gemini_results': [('Paramount+', 1), (\"RUPAUL'S DRAG RACE ALL STARS\", 1), ('BIG BROTHER', 1), ('THE CHALLENGE', 1), ('SURVIVOR', 1), ('ARE YOU THE ONE?', 1), ('INK MASTER', 1), ('QUEEN OF THE UNIVERSE', 1), ('BAR RESCUE', 1)], 'vi_results': [], 'ocr_text': [('Paramount+', 0.9), (\"RUPAUL'S DRAG RACE ALL STARS\", 0.8), ('BIG BROTHER', 0.8), ('THE CHALLENGE', 0.7), ('SURVIVOR', 0.6), ('ARE YOU THE ONE?', 0.5), ('INK MASTER', 0.4), ('QUEEN OF THE UNIVERSE', 0.4), ('BAR RESCUE', 0.3)]}, 'output': {'final': ['INK MASTER', \"RUPAUL'S DRAG RACE ALL STARS\", 'ARE YOU THE ONE?', 'Paramount+', 'QUEEN OF THE UNIVERSE', 'BIG BROTHER', 'SURVIVOR', 'THE CHALLENGE', 'BAR RESCUE']}})]\n",
      "Epoch 8/100, Loss: 4, Weights: [0.22054284 0.28368864 0.49576852] min_loss_Weights: [0.22054284 0.28368864 0.49576852] ads: [(2, {'inputs': {'gemini_results': [('Dove', 1)], 'vi_results': [('Unilever', 0.99), ('Nike', 0.99)], 'ocr_text': [('Dove', 1), ('Unilever', 0.8)]}, 'output': {'final': ['Unilever', 'Dove']}}), (6, {'inputs': {'gemini_results': [('Nectar', 1), ('Sealy', 1), ('Casper', 1), ('Serta', 1), ('Stearns & Foster', 1), ('SmartLife', 1), ('King Koil', 1)], 'vi_results': [('Raymour & Flanigan', 0.99), ('Sealy Corporation', 0.99)], 'ocr_text': [('Nectar', 0.9), ('Sealy', 0.8), ('Casper', 0.7), ('Serta', 0.6), ('Stearns & Foster', 0.5), ('SmartLife', 0.4), ('King Koil', 0.3)]}, 'output': {'final': ['SmartLife', 'Casper', 'Serta', 'King Koil', 'Stearns & Foster', 'Nectar', 'Sealy']}}), (26, {'inputs': {'gemini_results': [(\"Baker's\", 1), ('Fox', 1)], 'vi_results': [('KTVU', 0.99), ('Fox Broadcasting Company', 0.99)], 'ocr_text': [('AT&T', 0.9)]}, 'output': {'final': [\"Baker's\", 'Fox']}}), (36, {'inputs': {'gemini_results': [('Paramount+', 1), (\"RUPAUL'S DRAG RACE ALL STARS\", 1), ('BIG BROTHER', 1), ('THE CHALLENGE', 1), ('SURVIVOR', 1), ('ARE YOU THE ONE?', 1), ('INK MASTER', 1), ('QUEEN OF THE UNIVERSE', 1), ('BAR RESCUE', 1)], 'vi_results': [], 'ocr_text': [('Paramount+', 0.9), (\"RUPAUL'S DRAG RACE ALL STARS\", 0.8), ('BIG BROTHER', 0.8), ('THE CHALLENGE', 0.7), ('SURVIVOR', 0.6), ('ARE YOU THE ONE?', 0.5), ('INK MASTER', 0.4), ('QUEEN OF THE UNIVERSE', 0.4), ('BAR RESCUE', 0.3)]}, 'output': {'final': ['INK MASTER', \"RUPAUL'S DRAG RACE ALL STARS\", 'ARE YOU THE ONE?', 'Paramount+', 'QUEEN OF THE UNIVERSE', 'BIG BROTHER', 'SURVIVOR', 'THE CHALLENGE', 'BAR RESCUE']}})]\n",
      "Epoch 9/100, Loss: 6, Weights: [0.20463555 0.27927413 0.51609033] min_loss_Weights: [0.20054284 0.27368864 0.50576852] ads: [(2, {'inputs': {'gemini_results': [('Dove', 1)], 'vi_results': [('Unilever', 0.99), ('Nike', 0.99)], 'ocr_text': [('Dove', 1), ('Unilever', 0.8)]}, 'output': {'final': ['Unilever', 'Dove']}}), (6, {'inputs': {'gemini_results': [('Nectar', 1), ('Sealy', 1), ('Casper', 1), ('Serta', 1), ('Stearns & Foster', 1), ('SmartLife', 1), ('King Koil', 1)], 'vi_results': [('Raymour & Flanigan', 0.99), ('Sealy Corporation', 0.99)], 'ocr_text': [('Nectar', 0.9), ('Sealy', 0.8), ('Casper', 0.7), ('Serta', 0.6), ('Stearns & Foster', 0.5), ('SmartLife', 0.4), ('King Koil', 0.3)]}, 'output': {'final': ['SmartLife', 'Casper', 'Serta', 'King Koil', 'Stearns & Foster', 'Nectar', 'Sealy']}}), (26, {'inputs': {'gemini_results': [(\"Baker's\", 1), ('Fox', 1)], 'vi_results': [('KTVU', 0.99), ('Fox Broadcasting Company', 0.99)], 'ocr_text': [('AT&T', 0.9)]}, 'output': {'final': [\"Baker's\", 'Fox']}}), (36, {'inputs': {'gemini_results': [('Paramount+', 1), (\"RUPAUL'S DRAG RACE ALL STARS\", 1), ('BIG BROTHER', 1), ('THE CHALLENGE', 1), ('SURVIVOR', 1), ('ARE YOU THE ONE?', 1), ('INK MASTER', 1), ('QUEEN OF THE UNIVERSE', 1), ('BAR RESCUE', 1)], 'vi_results': [], 'ocr_text': [('Paramount+', 0.9), (\"RUPAUL'S DRAG RACE ALL STARS\", 0.8), ('BIG BROTHER', 0.8), ('THE CHALLENGE', 0.7), ('SURVIVOR', 0.6), ('ARE YOU THE ONE?', 0.5), ('INK MASTER', 0.4), ('QUEEN OF THE UNIVERSE', 0.4), ('BAR RESCUE', 0.3)]}, 'output': {'final': ['INK MASTER', \"RUPAUL'S DRAG RACE ALL STARS\", 'ARE YOU THE ONE?', 'Paramount+', 'QUEEN OF THE UNIVERSE', 'BIG BROTHER', 'SURVIVOR', 'THE CHALLENGE', 'BAR RESCUE']}})]\n",
      "Epoch 10/100, Loss: 4, Weights: [0.20463555 0.28927413 0.50609033] min_loss_Weights: [0.20054284 0.27368864 0.50576852] ads: [(2, {'inputs': {'gemini_results': [('Dove', 1)], 'vi_results': [('Unilever', 0.99), ('Nike', 0.99)], 'ocr_text': [('Dove', 1), ('Unilever', 0.8)]}, 'output': {'final': ['Unilever', 'Dove']}}), (6, {'inputs': {'gemini_results': [('Nectar', 1), ('Sealy', 1), ('Casper', 1), ('Serta', 1), ('Stearns & Foster', 1), ('SmartLife', 1), ('King Koil', 1)], 'vi_results': [('Raymour & Flanigan', 0.99), ('Sealy Corporation', 0.99)], 'ocr_text': [('Nectar', 0.9), ('Sealy', 0.8), ('Casper', 0.7), ('Serta', 0.6), ('Stearns & Foster', 0.5), ('SmartLife', 0.4), ('King Koil', 0.3)]}, 'output': {'final': ['SmartLife', 'Casper', 'Serta', 'King Koil', 'Stearns & Foster', 'Nectar', 'Sealy']}}), (26, {'inputs': {'gemini_results': [(\"Baker's\", 1), ('Fox', 1)], 'vi_results': [('KTVU', 0.99), ('Fox Broadcasting Company', 0.99)], 'ocr_text': [('AT&T', 0.9)]}, 'output': {'final': [\"Baker's\", 'Fox']}}), (36, {'inputs': {'gemini_results': [('Paramount+', 1), (\"RUPAUL'S DRAG RACE ALL STARS\", 1), ('BIG BROTHER', 1), ('THE CHALLENGE', 1), ('SURVIVOR', 1), ('ARE YOU THE ONE?', 1), ('INK MASTER', 1), ('QUEEN OF THE UNIVERSE', 1), ('BAR RESCUE', 1)], 'vi_results': [], 'ocr_text': [('Paramount+', 0.9), (\"RUPAUL'S DRAG RACE ALL STARS\", 0.8), ('BIG BROTHER', 0.8), ('THE CHALLENGE', 0.7), ('SURVIVOR', 0.6), ('ARE YOU THE ONE?', 0.5), ('INK MASTER', 0.4), ('QUEEN OF THE UNIVERSE', 0.4), ('BAR RESCUE', 0.3)]}, 'output': {'final': ['INK MASTER', \"RUPAUL'S DRAG RACE ALL STARS\", 'ARE YOU THE ONE?', 'Paramount+', 'QUEEN OF THE UNIVERSE', 'BIG BROTHER', 'SURVIVOR', 'THE CHALLENGE', 'BAR RESCUE']}})]\n",
      "Epoch 11/100, Loss: 4, Weights: [0.20463555 0.29927413 0.49609033] min_loss_Weights: [0.20054284 0.27368864 0.50576852] ads: [(2, {'inputs': {'gemini_results': [('Dove', 1)], 'vi_results': [('Unilever', 0.99), ('Nike', 0.99)], 'ocr_text': [('Dove', 1), ('Unilever', 0.8)]}, 'output': {'final': ['Unilever', 'Dove']}}), (6, {'inputs': {'gemini_results': [('Nectar', 1), ('Sealy', 1), ('Casper', 1), ('Serta', 1), ('Stearns & Foster', 1), ('SmartLife', 1), ('King Koil', 1)], 'vi_results': [('Raymour & Flanigan', 0.99), ('Sealy Corporation', 0.99)], 'ocr_text': [('Nectar', 0.9), ('Sealy', 0.8), ('Casper', 0.7), ('Serta', 0.6), ('Stearns & Foster', 0.5), ('SmartLife', 0.4), ('King Koil', 0.3)]}, 'output': {'final': ['SmartLife', 'Casper', 'Serta', 'King Koil', 'Stearns & Foster', 'Nectar', 'Sealy']}}), (26, {'inputs': {'gemini_results': [(\"Baker's\", 1), ('Fox', 1)], 'vi_results': [('KTVU', 0.99), ('Fox Broadcasting Company', 0.99)], 'ocr_text': [('AT&T', 0.9)]}, 'output': {'final': [\"Baker's\", 'Fox']}}), (36, {'inputs': {'gemini_results': [('Paramount+', 1), (\"RUPAUL'S DRAG RACE ALL STARS\", 1), ('BIG BROTHER', 1), ('THE CHALLENGE', 1), ('SURVIVOR', 1), ('ARE YOU THE ONE?', 1), ('INK MASTER', 1), ('QUEEN OF THE UNIVERSE', 1), ('BAR RESCUE', 1)], 'vi_results': [], 'ocr_text': [('Paramount+', 0.9), (\"RUPAUL'S DRAG RACE ALL STARS\", 0.8), ('BIG BROTHER', 0.8), ('THE CHALLENGE', 0.7), ('SURVIVOR', 0.6), ('ARE YOU THE ONE?', 0.5), ('INK MASTER', 0.4), ('QUEEN OF THE UNIVERSE', 0.4), ('BAR RESCUE', 0.3)]}, 'output': {'final': ['INK MASTER', \"RUPAUL'S DRAG RACE ALL STARS\", 'ARE YOU THE ONE?', 'Paramount+', 'QUEEN OF THE UNIVERSE', 'BIG BROTHER', 'SURVIVOR', 'THE CHALLENGE', 'BAR RESCUE']}})]\n",
      "Epoch 12/100, Loss: 6, Weights: [0.18840362 0.29517768 0.5164187 ] min_loss_Weights: [0.20054284 0.27368864 0.50576852] ads: [(2, {'inputs': {'gemini_results': [('Dove', 1)], 'vi_results': [('Unilever', 0.99), ('Nike', 0.99)], 'ocr_text': [('Dove', 1), ('Unilever', 0.8)]}, 'output': {'final': ['Unilever', 'Dove']}}), (6, {'inputs': {'gemini_results': [('Nectar', 1), ('Sealy', 1), ('Casper', 1), ('Serta', 1), ('Stearns & Foster', 1), ('SmartLife', 1), ('King Koil', 1)], 'vi_results': [('Raymour & Flanigan', 0.99), ('Sealy Corporation', 0.99)], 'ocr_text': [('Nectar', 0.9), ('Sealy', 0.8), ('Casper', 0.7), ('Serta', 0.6), ('Stearns & Foster', 0.5), ('SmartLife', 0.4), ('King Koil', 0.3)]}, 'output': {'final': ['SmartLife', 'Casper', 'Serta', 'King Koil', 'Stearns & Foster', 'Nectar', 'Sealy']}}), (26, {'inputs': {'gemini_results': [(\"Baker's\", 1), ('Fox', 1)], 'vi_results': [('KTVU', 0.99), ('Fox Broadcasting Company', 0.99)], 'ocr_text': [('AT&T', 0.9)]}, 'output': {'final': [\"Baker's\", 'Fox']}}), (36, {'inputs': {'gemini_results': [('Paramount+', 1), (\"RUPAUL'S DRAG RACE ALL STARS\", 1), ('BIG BROTHER', 1), ('THE CHALLENGE', 1), ('SURVIVOR', 1), ('ARE YOU THE ONE?', 1), ('INK MASTER', 1), ('QUEEN OF THE UNIVERSE', 1), ('BAR RESCUE', 1)], 'vi_results': [], 'ocr_text': [('Paramount+', 0.9), (\"RUPAUL'S DRAG RACE ALL STARS\", 0.8), ('BIG BROTHER', 0.8), ('THE CHALLENGE', 0.7), ('SURVIVOR', 0.6), ('ARE YOU THE ONE?', 0.5), ('INK MASTER', 0.4), ('QUEEN OF THE UNIVERSE', 0.4), ('BAR RESCUE', 0.3)]}, 'output': {'final': ['INK MASTER', \"RUPAUL'S DRAG RACE ALL STARS\", 'ARE YOU THE ONE?', 'Paramount+', 'QUEEN OF THE UNIVERSE', 'BIG BROTHER', 'SURVIVOR', 'THE CHALLENGE', 'BAR RESCUE']}})]\n",
      "Epoch 13/100, Loss: 3, Weights: [0.19840362 0.29517768 0.5064187 ] min_loss_Weights: [0.19840362 0.29517768 0.5064187 ] ads: [(6, {'inputs': {'gemini_results': [('Nectar', 1), ('Sealy', 1), ('Casper', 1), ('Serta', 1), ('Stearns & Foster', 1), ('SmartLife', 1), ('King Koil', 1)], 'vi_results': [('Raymour & Flanigan', 0.99), ('Sealy Corporation', 0.99)], 'ocr_text': [('Nectar', 0.9), ('Sealy', 0.8), ('Casper', 0.7), ('Serta', 0.6), ('Stearns & Foster', 0.5), ('SmartLife', 0.4), ('King Koil', 0.3)]}, 'output': {'final': ['SmartLife', 'Casper', 'Serta', 'King Koil', 'Stearns & Foster', 'Nectar', 'Sealy']}}), (26, {'inputs': {'gemini_results': [(\"Baker's\", 1), ('Fox', 1)], 'vi_results': [('KTVU', 0.99), ('Fox Broadcasting Company', 0.99)], 'ocr_text': [('AT&T', 0.9)]}, 'output': {'final': [\"Baker's\", 'Fox']}}), (36, {'inputs': {'gemini_results': [('Paramount+', 1), (\"RUPAUL'S DRAG RACE ALL STARS\", 1), ('BIG BROTHER', 1), ('THE CHALLENGE', 1), ('SURVIVOR', 1), ('ARE YOU THE ONE?', 1), ('INK MASTER', 1), ('QUEEN OF THE UNIVERSE', 1), ('BAR RESCUE', 1)], 'vi_results': [], 'ocr_text': [('Paramount+', 0.9), (\"RUPAUL'S DRAG RACE ALL STARS\", 0.8), ('BIG BROTHER', 0.8), ('THE CHALLENGE', 0.7), ('SURVIVOR', 0.6), ('ARE YOU THE ONE?', 0.5), ('INK MASTER', 0.4), ('QUEEN OF THE UNIVERSE', 0.4), ('BAR RESCUE', 0.3)]}, 'output': {'final': ['INK MASTER', \"RUPAUL'S DRAG RACE ALL STARS\", 'ARE YOU THE ONE?', 'Paramount+', 'QUEEN OF THE UNIVERSE', 'BIG BROTHER', 'SURVIVOR', 'THE CHALLENGE', 'BAR RESCUE']}})]\n",
      "Epoch 14/100, Loss: 4, Weights: [0.19840362 0.30517768 0.4964187 ] min_loss_Weights: [0.19840362 0.30517768 0.4964187 ] ads: [(6, {'inputs': {'gemini_results': [('Nectar', 1), ('Sealy', 1), ('Casper', 1), ('Serta', 1), ('Stearns & Foster', 1), ('SmartLife', 1), ('King Koil', 1)], 'vi_results': [('Raymour & Flanigan', 0.99), ('Sealy Corporation', 0.99)], 'ocr_text': [('Nectar', 0.9), ('Sealy', 0.8), ('Casper', 0.7), ('Serta', 0.6), ('Stearns & Foster', 0.5), ('SmartLife', 0.4), ('King Koil', 0.3)]}, 'output': {'final': ['SmartLife', 'Casper', 'Serta', 'King Koil', 'Stearns & Foster', 'Nectar', 'Sealy']}}), (26, {'inputs': {'gemini_results': [(\"Baker's\", 1), ('Fox', 1)], 'vi_results': [('KTVU', 0.99), ('Fox Broadcasting Company', 0.99)], 'ocr_text': [('AT&T', 0.9)]}, 'output': {'final': [\"Baker's\", 'Fox']}}), (36, {'inputs': {'gemini_results': [('Paramount+', 1), (\"RUPAUL'S DRAG RACE ALL STARS\", 1), ('BIG BROTHER', 1), ('THE CHALLENGE', 1), ('SURVIVOR', 1), ('ARE YOU THE ONE?', 1), ('INK MASTER', 1), ('QUEEN OF THE UNIVERSE', 1), ('BAR RESCUE', 1)], 'vi_results': [], 'ocr_text': [('Paramount+', 0.9), (\"RUPAUL'S DRAG RACE ALL STARS\", 0.8), ('BIG BROTHER', 0.8), ('THE CHALLENGE', 0.7), ('SURVIVOR', 0.6), ('ARE YOU THE ONE?', 0.5), ('INK MASTER', 0.4), ('QUEEN OF THE UNIVERSE', 0.4), ('BAR RESCUE', 0.3)]}, 'output': {'final': ['INK MASTER', \"RUPAUL'S DRAG RACE ALL STARS\", 'ARE YOU THE ONE?', 'Paramount+', 'QUEEN OF THE UNIVERSE', 'BIG BROTHER', 'SURVIVOR', 'THE CHALLENGE', 'BAR RESCUE']}})]\n",
      "Epoch 15/100, Loss: 5, Weights: [0.19224859 0.29099763 0.51675378] min_loss_Weights: [0.19840362 0.30517768 0.4964187 ] ads: [(6, {'inputs': {'gemini_results': [('Nectar', 1), ('Sealy', 1), ('Casper', 1), ('Serta', 1), ('Stearns & Foster', 1), ('SmartLife', 1), ('King Koil', 1)], 'vi_results': [('Raymour & Flanigan', 0.99), ('Sealy Corporation', 0.99)], 'ocr_text': [('Nectar', 0.9), ('Sealy', 0.8), ('Casper', 0.7), ('Serta', 0.6), ('Stearns & Foster', 0.5), ('SmartLife', 0.4), ('King Koil', 0.3)]}, 'output': {'final': ['SmartLife', 'Casper', 'Serta', 'King Koil', 'Stearns & Foster', 'Nectar', 'Sealy']}}), (26, {'inputs': {'gemini_results': [(\"Baker's\", 1), ('Fox', 1)], 'vi_results': [('KTVU', 0.99), ('Fox Broadcasting Company', 0.99)], 'ocr_text': [('AT&T', 0.9)]}, 'output': {'final': [\"Baker's\", 'Fox']}}), (36, {'inputs': {'gemini_results': [('Paramount+', 1), (\"RUPAUL'S DRAG RACE ALL STARS\", 1), ('BIG BROTHER', 1), ('THE CHALLENGE', 1), ('SURVIVOR', 1), ('ARE YOU THE ONE?', 1), ('INK MASTER', 1), ('QUEEN OF THE UNIVERSE', 1), ('BAR RESCUE', 1)], 'vi_results': [], 'ocr_text': [('Paramount+', 0.9), (\"RUPAUL'S DRAG RACE ALL STARS\", 0.8), ('BIG BROTHER', 0.8), ('THE CHALLENGE', 0.7), ('SURVIVOR', 0.6), ('ARE YOU THE ONE?', 0.5), ('INK MASTER', 0.4), ('QUEEN OF THE UNIVERSE', 0.4), ('BAR RESCUE', 0.3)]}, 'output': {'final': ['INK MASTER', \"RUPAUL'S DRAG RACE ALL STARS\", 'ARE YOU THE ONE?', 'Paramount+', 'QUEEN OF THE UNIVERSE', 'BIG BROTHER', 'SURVIVOR', 'THE CHALLENGE', 'BAR RESCUE']}})]\n",
      "Epoch 16/100, Loss: 4, Weights: [0.19224859 0.30099763 0.50675378] min_loss_Weights: [0.19840362 0.30517768 0.4964187 ] ads: [(6, {'inputs': {'gemini_results': [('Nectar', 1), ('Sealy', 1), ('Casper', 1), ('Serta', 1), ('Stearns & Foster', 1), ('SmartLife', 1), ('King Koil', 1)], 'vi_results': [('Raymour & Flanigan', 0.99), ('Sealy Corporation', 0.99)], 'ocr_text': [('Nectar', 0.9), ('Sealy', 0.8), ('Casper', 0.7), ('Serta', 0.6), ('Stearns & Foster', 0.5), ('SmartLife', 0.4), ('King Koil', 0.3)]}, 'output': {'final': ['SmartLife', 'Casper', 'Serta', 'King Koil', 'Stearns & Foster', 'Nectar', 'Sealy']}}), (26, {'inputs': {'gemini_results': [(\"Baker's\", 1), ('Fox', 1)], 'vi_results': [('KTVU', 0.99), ('Fox Broadcasting Company', 0.99)], 'ocr_text': [('AT&T', 0.9)]}, 'output': {'final': [\"Baker's\", 'Fox']}}), (36, {'inputs': {'gemini_results': [('Paramount+', 1), (\"RUPAUL'S DRAG RACE ALL STARS\", 1), ('BIG BROTHER', 1), ('THE CHALLENGE', 1), ('SURVIVOR', 1), ('ARE YOU THE ONE?', 1), ('INK MASTER', 1), ('QUEEN OF THE UNIVERSE', 1), ('BAR RESCUE', 1)], 'vi_results': [], 'ocr_text': [('Paramount+', 0.9), (\"RUPAUL'S DRAG RACE ALL STARS\", 0.8), ('BIG BROTHER', 0.8), ('THE CHALLENGE', 0.7), ('SURVIVOR', 0.6), ('ARE YOU THE ONE?', 0.5), ('INK MASTER', 0.4), ('QUEEN OF THE UNIVERSE', 0.4), ('BAR RESCUE', 0.3)]}, 'output': {'final': ['INK MASTER', \"RUPAUL'S DRAG RACE ALL STARS\", 'ARE YOU THE ONE?', 'Paramount+', 'QUEEN OF THE UNIVERSE', 'BIG BROTHER', 'SURVIVOR', 'THE CHALLENGE', 'BAR RESCUE']}})]\n",
      "Epoch 17/100, Loss: 3, Weights: [0.20224859 0.30099763 0.49675378] min_loss_Weights: [0.19840362 0.30517768 0.4964187 ] ads: [(6, {'inputs': {'gemini_results': [('Nectar', 1), ('Sealy', 1), ('Casper', 1), ('Serta', 1), ('Stearns & Foster', 1), ('SmartLife', 1), ('King Koil', 1)], 'vi_results': [('Raymour & Flanigan', 0.99), ('Sealy Corporation', 0.99)], 'ocr_text': [('Nectar', 0.9), ('Sealy', 0.8), ('Casper', 0.7), ('Serta', 0.6), ('Stearns & Foster', 0.5), ('SmartLife', 0.4), ('King Koil', 0.3)]}, 'output': {'final': ['SmartLife', 'Casper', 'Serta', 'King Koil', 'Stearns & Foster', 'Nectar', 'Sealy']}}), (26, {'inputs': {'gemini_results': [(\"Baker's\", 1), ('Fox', 1)], 'vi_results': [('KTVU', 0.99), ('Fox Broadcasting Company', 0.99)], 'ocr_text': [('AT&T', 0.9)]}, 'output': {'final': [\"Baker's\", 'Fox']}}), (36, {'inputs': {'gemini_results': [('Paramount+', 1), (\"RUPAUL'S DRAG RACE ALL STARS\", 1), ('BIG BROTHER', 1), ('THE CHALLENGE', 1), ('SURVIVOR', 1), ('ARE YOU THE ONE?', 1), ('INK MASTER', 1), ('QUEEN OF THE UNIVERSE', 1), ('BAR RESCUE', 1)], 'vi_results': [], 'ocr_text': [('Paramount+', 0.9), (\"RUPAUL'S DRAG RACE ALL STARS\", 0.8), ('BIG BROTHER', 0.8), ('THE CHALLENGE', 0.7), ('SURVIVOR', 0.6), ('ARE YOU THE ONE?', 0.5), ('INK MASTER', 0.4), ('QUEEN OF THE UNIVERSE', 0.4), ('BAR RESCUE', 0.3)]}, 'output': {'final': ['INK MASTER', \"RUPAUL'S DRAG RACE ALL STARS\", 'ARE YOU THE ONE?', 'Paramount+', 'QUEEN OF THE UNIVERSE', 'BIG BROTHER', 'SURVIVOR', 'THE CHALLENGE', 'BAR RESCUE']}})]\n",
      "Epoch 18/100, Loss: 6, Weights: [0.18596795 0.29693636 0.51709569] min_loss_Weights: [0.19840362 0.30517768 0.4964187 ] ads: [(6, {'inputs': {'gemini_results': [('Nectar', 1), ('Sealy', 1), ('Casper', 1), ('Serta', 1), ('Stearns & Foster', 1), ('SmartLife', 1), ('King Koil', 1)], 'vi_results': [('Raymour & Flanigan', 0.99), ('Sealy Corporation', 0.99)], 'ocr_text': [('Nectar', 0.9), ('Sealy', 0.8), ('Casper', 0.7), ('Serta', 0.6), ('Stearns & Foster', 0.5), ('SmartLife', 0.4), ('King Koil', 0.3)]}, 'output': {'final': ['SmartLife', 'Casper', 'Serta', 'King Koil', 'Stearns & Foster', 'Nectar', 'Sealy']}}), (26, {'inputs': {'gemini_results': [(\"Baker's\", 1), ('Fox', 1)], 'vi_results': [('KTVU', 0.99), ('Fox Broadcasting Company', 0.99)], 'ocr_text': [('AT&T', 0.9)]}, 'output': {'final': [\"Baker's\", 'Fox']}}), (36, {'inputs': {'gemini_results': [('Paramount+', 1), (\"RUPAUL'S DRAG RACE ALL STARS\", 1), ('BIG BROTHER', 1), ('THE CHALLENGE', 1), ('SURVIVOR', 1), ('ARE YOU THE ONE?', 1), ('INK MASTER', 1), ('QUEEN OF THE UNIVERSE', 1), ('BAR RESCUE', 1)], 'vi_results': [], 'ocr_text': [('Paramount+', 0.9), (\"RUPAUL'S DRAG RACE ALL STARS\", 0.8), ('BIG BROTHER', 0.8), ('THE CHALLENGE', 0.7), ('SURVIVOR', 0.6), ('ARE YOU THE ONE?', 0.5), ('INK MASTER', 0.4), ('QUEEN OF THE UNIVERSE', 0.4), ('BAR RESCUE', 0.3)]}, 'output': {'final': ['INK MASTER', \"RUPAUL'S DRAG RACE ALL STARS\", 'ARE YOU THE ONE?', 'Paramount+', 'QUEEN OF THE UNIVERSE', 'BIG BROTHER', 'SURVIVOR', 'THE CHALLENGE', 'BAR RESCUE']}})]\n",
      "Epoch 19/100, Loss: 3, Weights: [0.19596795 0.29693636 0.50709569] min_loss_Weights: [0.19840362 0.30517768 0.4964187 ] ads: [(6, {'inputs': {'gemini_results': [('Nectar', 1), ('Sealy', 1), ('Casper', 1), ('Serta', 1), ('Stearns & Foster', 1), ('SmartLife', 1), ('King Koil', 1)], 'vi_results': [('Raymour & Flanigan', 0.99), ('Sealy Corporation', 0.99)], 'ocr_text': [('Nectar', 0.9), ('Sealy', 0.8), ('Casper', 0.7), ('Serta', 0.6), ('Stearns & Foster', 0.5), ('SmartLife', 0.4), ('King Koil', 0.3)]}, 'output': {'final': ['SmartLife', 'Casper', 'Serta', 'King Koil', 'Stearns & Foster', 'Nectar', 'Sealy']}}), (26, {'inputs': {'gemini_results': [(\"Baker's\", 1), ('Fox', 1)], 'vi_results': [('KTVU', 0.99), ('Fox Broadcasting Company', 0.99)], 'ocr_text': [('AT&T', 0.9)]}, 'output': {'final': [\"Baker's\", 'Fox']}}), (36, {'inputs': {'gemini_results': [('Paramount+', 1), (\"RUPAUL'S DRAG RACE ALL STARS\", 1), ('BIG BROTHER', 1), ('THE CHALLENGE', 1), ('SURVIVOR', 1), ('ARE YOU THE ONE?', 1), ('INK MASTER', 1), ('QUEEN OF THE UNIVERSE', 1), ('BAR RESCUE', 1)], 'vi_results': [], 'ocr_text': [('Paramount+', 0.9), (\"RUPAUL'S DRAG RACE ALL STARS\", 0.8), ('BIG BROTHER', 0.8), ('THE CHALLENGE', 0.7), ('SURVIVOR', 0.6), ('ARE YOU THE ONE?', 0.5), ('INK MASTER', 0.4), ('QUEEN OF THE UNIVERSE', 0.4), ('BAR RESCUE', 0.3)]}, 'output': {'final': ['INK MASTER', \"RUPAUL'S DRAG RACE ALL STARS\", 'ARE YOU THE ONE?', 'Paramount+', 'QUEEN OF THE UNIVERSE', 'BIG BROTHER', 'SURVIVOR', 'THE CHALLENGE', 'BAR RESCUE']}})]\n",
      "Epoch 20/100, Loss: 4, Weights: [0.19596795 0.30693636 0.49709569] min_loss_Weights: [0.19840362 0.30517768 0.4964187 ] ads: [(6, {'inputs': {'gemini_results': [('Nectar', 1), ('Sealy', 1), ('Casper', 1), ('Serta', 1), ('Stearns & Foster', 1), ('SmartLife', 1), ('King Koil', 1)], 'vi_results': [('Raymour & Flanigan', 0.99), ('Sealy Corporation', 0.99)], 'ocr_text': [('Nectar', 0.9), ('Sealy', 0.8), ('Casper', 0.7), ('Serta', 0.6), ('Stearns & Foster', 0.5), ('SmartLife', 0.4), ('King Koil', 0.3)]}, 'output': {'final': ['SmartLife', 'Casper', 'Serta', 'King Koil', 'Stearns & Foster', 'Nectar', 'Sealy']}}), (26, {'inputs': {'gemini_results': [(\"Baker's\", 1), ('Fox', 1)], 'vi_results': [('KTVU', 0.99), ('Fox Broadcasting Company', 0.99)], 'ocr_text': [('AT&T', 0.9)]}, 'output': {'final': [\"Baker's\", 'Fox']}}), (36, {'inputs': {'gemini_results': [('Paramount+', 1), (\"RUPAUL'S DRAG RACE ALL STARS\", 1), ('BIG BROTHER', 1), ('THE CHALLENGE', 1), ('SURVIVOR', 1), ('ARE YOU THE ONE?', 1), ('INK MASTER', 1), ('QUEEN OF THE UNIVERSE', 1), ('BAR RESCUE', 1)], 'vi_results': [], 'ocr_text': [('Paramount+', 0.9), (\"RUPAUL'S DRAG RACE ALL STARS\", 0.8), ('BIG BROTHER', 0.8), ('THE CHALLENGE', 0.7), ('SURVIVOR', 0.6), ('ARE YOU THE ONE?', 0.5), ('INK MASTER', 0.4), ('QUEEN OF THE UNIVERSE', 0.4), ('BAR RESCUE', 0.3)]}, 'output': {'final': ['INK MASTER', \"RUPAUL'S DRAG RACE ALL STARS\", 'ARE YOU THE ONE?', 'Paramount+', 'QUEEN OF THE UNIVERSE', 'BIG BROTHER', 'SURVIVOR', 'THE CHALLENGE', 'BAR RESCUE']}})]\n",
      "Epoch 21/100, Loss: 5, Weights: [0.18976321 0.2927922  0.51744458] min_loss_Weights: [0.19840362 0.30517768 0.4964187 ] ads: [(6, {'inputs': {'gemini_results': [('Nectar', 1), ('Sealy', 1), ('Casper', 1), ('Serta', 1), ('Stearns & Foster', 1), ('SmartLife', 1), ('King Koil', 1)], 'vi_results': [('Raymour & Flanigan', 0.99), ('Sealy Corporation', 0.99)], 'ocr_text': [('Nectar', 0.9), ('Sealy', 0.8), ('Casper', 0.7), ('Serta', 0.6), ('Stearns & Foster', 0.5), ('SmartLife', 0.4), ('King Koil', 0.3)]}, 'output': {'final': ['SmartLife', 'Casper', 'Serta', 'King Koil', 'Stearns & Foster', 'Nectar', 'Sealy']}}), (26, {'inputs': {'gemini_results': [(\"Baker's\", 1), ('Fox', 1)], 'vi_results': [('KTVU', 0.99), ('Fox Broadcasting Company', 0.99)], 'ocr_text': [('AT&T', 0.9)]}, 'output': {'final': [\"Baker's\", 'Fox']}}), (36, {'inputs': {'gemini_results': [('Paramount+', 1), (\"RUPAUL'S DRAG RACE ALL STARS\", 1), ('BIG BROTHER', 1), ('THE CHALLENGE', 1), ('SURVIVOR', 1), ('ARE YOU THE ONE?', 1), ('INK MASTER', 1), ('QUEEN OF THE UNIVERSE', 1), ('BAR RESCUE', 1)], 'vi_results': [], 'ocr_text': [('Paramount+', 0.9), (\"RUPAUL'S DRAG RACE ALL STARS\", 0.8), ('BIG BROTHER', 0.8), ('THE CHALLENGE', 0.7), ('SURVIVOR', 0.6), ('ARE YOU THE ONE?', 0.5), ('INK MASTER', 0.4), ('QUEEN OF THE UNIVERSE', 0.4), ('BAR RESCUE', 0.3)]}, 'output': {'final': ['INK MASTER', \"RUPAUL'S DRAG RACE ALL STARS\", 'ARE YOU THE ONE?', 'Paramount+', 'QUEEN OF THE UNIVERSE', 'BIG BROTHER', 'SURVIVOR', 'THE CHALLENGE', 'BAR RESCUE']}})]\n",
      "Epoch 22/100, Loss: 4, Weights: [0.18976321 0.3027922  0.50744458] min_loss_Weights: [0.19840362 0.30517768 0.4964187 ] ads: [(6, {'inputs': {'gemini_results': [('Nectar', 1), ('Sealy', 1), ('Casper', 1), ('Serta', 1), ('Stearns & Foster', 1), ('SmartLife', 1), ('King Koil', 1)], 'vi_results': [('Raymour & Flanigan', 0.99), ('Sealy Corporation', 0.99)], 'ocr_text': [('Nectar', 0.9), ('Sealy', 0.8), ('Casper', 0.7), ('Serta', 0.6), ('Stearns & Foster', 0.5), ('SmartLife', 0.4), ('King Koil', 0.3)]}, 'output': {'final': ['SmartLife', 'Casper', 'Serta', 'King Koil', 'Stearns & Foster', 'Nectar', 'Sealy']}}), (26, {'inputs': {'gemini_results': [(\"Baker's\", 1), ('Fox', 1)], 'vi_results': [('KTVU', 0.99), ('Fox Broadcasting Company', 0.99)], 'ocr_text': [('AT&T', 0.9)]}, 'output': {'final': [\"Baker's\", 'Fox']}}), (36, {'inputs': {'gemini_results': [('Paramount+', 1), (\"RUPAUL'S DRAG RACE ALL STARS\", 1), ('BIG BROTHER', 1), ('THE CHALLENGE', 1), ('SURVIVOR', 1), ('ARE YOU THE ONE?', 1), ('INK MASTER', 1), ('QUEEN OF THE UNIVERSE', 1), ('BAR RESCUE', 1)], 'vi_results': [], 'ocr_text': [('Paramount+', 0.9), (\"RUPAUL'S DRAG RACE ALL STARS\", 0.8), ('BIG BROTHER', 0.8), ('THE CHALLENGE', 0.7), ('SURVIVOR', 0.6), ('ARE YOU THE ONE?', 0.5), ('INK MASTER', 0.4), ('QUEEN OF THE UNIVERSE', 0.4), ('BAR RESCUE', 0.3)]}, 'output': {'final': ['INK MASTER', \"RUPAUL'S DRAG RACE ALL STARS\", 'ARE YOU THE ONE?', 'Paramount+', 'QUEEN OF THE UNIVERSE', 'BIG BROTHER', 'SURVIVOR', 'THE CHALLENGE', 'BAR RESCUE']}})]\n",
      "Epoch 23/100, Loss: 3, Weights: [0.19976321 0.3027922  0.49744458] min_loss_Weights: [0.19840362 0.30517768 0.4964187 ] ads: [(6, {'inputs': {'gemini_results': [('Nectar', 1), ('Sealy', 1), ('Casper', 1), ('Serta', 1), ('Stearns & Foster', 1), ('SmartLife', 1), ('King Koil', 1)], 'vi_results': [('Raymour & Flanigan', 0.99), ('Sealy Corporation', 0.99)], 'ocr_text': [('Nectar', 0.9), ('Sealy', 0.8), ('Casper', 0.7), ('Serta', 0.6), ('Stearns & Foster', 0.5), ('SmartLife', 0.4), ('King Koil', 0.3)]}, 'output': {'final': ['SmartLife', 'Casper', 'Serta', 'King Koil', 'Stearns & Foster', 'Nectar', 'Sealy']}}), (26, {'inputs': {'gemini_results': [(\"Baker's\", 1), ('Fox', 1)], 'vi_results': [('KTVU', 0.99), ('Fox Broadcasting Company', 0.99)], 'ocr_text': [('AT&T', 0.9)]}, 'output': {'final': [\"Baker's\", 'Fox']}}), (36, {'inputs': {'gemini_results': [('Paramount+', 1), (\"RUPAUL'S DRAG RACE ALL STARS\", 1), ('BIG BROTHER', 1), ('THE CHALLENGE', 1), ('SURVIVOR', 1), ('ARE YOU THE ONE?', 1), ('INK MASTER', 1), ('QUEEN OF THE UNIVERSE', 1), ('BAR RESCUE', 1)], 'vi_results': [], 'ocr_text': [('Paramount+', 0.9), (\"RUPAUL'S DRAG RACE ALL STARS\", 0.8), ('BIG BROTHER', 0.8), ('THE CHALLENGE', 0.7), ('SURVIVOR', 0.6), ('ARE YOU THE ONE?', 0.5), ('INK MASTER', 0.4), ('QUEEN OF THE UNIVERSE', 0.4), ('BAR RESCUE', 0.3)]}, 'output': {'final': ['INK MASTER', \"RUPAUL'S DRAG RACE ALL STARS\", 'ARE YOU THE ONE?', 'Paramount+', 'QUEEN OF THE UNIVERSE', 'BIG BROTHER', 'SURVIVOR', 'THE CHALLENGE', 'BAR RESCUE']}})]\n",
      "Epoch 24/100, Loss: 5, Weights: [0.19363593 0.28856347 0.51780059] min_loss_Weights: [0.19840362 0.30517768 0.4964187 ] ads: [(6, {'inputs': {'gemini_results': [('Nectar', 1), ('Sealy', 1), ('Casper', 1), ('Serta', 1), ('Stearns & Foster', 1), ('SmartLife', 1), ('King Koil', 1)], 'vi_results': [('Raymour & Flanigan', 0.99), ('Sealy Corporation', 0.99)], 'ocr_text': [('Nectar', 0.9), ('Sealy', 0.8), ('Casper', 0.7), ('Serta', 0.6), ('Stearns & Foster', 0.5), ('SmartLife', 0.4), ('King Koil', 0.3)]}, 'output': {'final': ['SmartLife', 'Casper', 'Serta', 'King Koil', 'Stearns & Foster', 'Nectar', 'Sealy']}}), (26, {'inputs': {'gemini_results': [(\"Baker's\", 1), ('Fox', 1)], 'vi_results': [('KTVU', 0.99), ('Fox Broadcasting Company', 0.99)], 'ocr_text': [('AT&T', 0.9)]}, 'output': {'final': [\"Baker's\", 'Fox']}}), (36, {'inputs': {'gemini_results': [('Paramount+', 1), (\"RUPAUL'S DRAG RACE ALL STARS\", 1), ('BIG BROTHER', 1), ('THE CHALLENGE', 1), ('SURVIVOR', 1), ('ARE YOU THE ONE?', 1), ('INK MASTER', 1), ('QUEEN OF THE UNIVERSE', 1), ('BAR RESCUE', 1)], 'vi_results': [], 'ocr_text': [('Paramount+', 0.9), (\"RUPAUL'S DRAG RACE ALL STARS\", 0.8), ('BIG BROTHER', 0.8), ('THE CHALLENGE', 0.7), ('SURVIVOR', 0.6), ('ARE YOU THE ONE?', 0.5), ('INK MASTER', 0.4), ('QUEEN OF THE UNIVERSE', 0.4), ('BAR RESCUE', 0.3)]}, 'output': {'final': ['INK MASTER', \"RUPAUL'S DRAG RACE ALL STARS\", 'ARE YOU THE ONE?', 'Paramount+', 'QUEEN OF THE UNIVERSE', 'BIG BROTHER', 'SURVIVOR', 'THE CHALLENGE', 'BAR RESCUE']}})]\n",
      "Epoch 25/100, Loss: 4, Weights: [0.19363593 0.29856347 0.50780059] min_loss_Weights: [0.19840362 0.30517768 0.4964187 ] ads: [(6, {'inputs': {'gemini_results': [('Nectar', 1), ('Sealy', 1), ('Casper', 1), ('Serta', 1), ('Stearns & Foster', 1), ('SmartLife', 1), ('King Koil', 1)], 'vi_results': [('Raymour & Flanigan', 0.99), ('Sealy Corporation', 0.99)], 'ocr_text': [('Nectar', 0.9), ('Sealy', 0.8), ('Casper', 0.7), ('Serta', 0.6), ('Stearns & Foster', 0.5), ('SmartLife', 0.4), ('King Koil', 0.3)]}, 'output': {'final': ['SmartLife', 'Casper', 'Serta', 'King Koil', 'Stearns & Foster', 'Nectar', 'Sealy']}}), (26, {'inputs': {'gemini_results': [(\"Baker's\", 1), ('Fox', 1)], 'vi_results': [('KTVU', 0.99), ('Fox Broadcasting Company', 0.99)], 'ocr_text': [('AT&T', 0.9)]}, 'output': {'final': [\"Baker's\", 'Fox']}}), (36, {'inputs': {'gemini_results': [('Paramount+', 1), (\"RUPAUL'S DRAG RACE ALL STARS\", 1), ('BIG BROTHER', 1), ('THE CHALLENGE', 1), ('SURVIVOR', 1), ('ARE YOU THE ONE?', 1), ('INK MASTER', 1), ('QUEEN OF THE UNIVERSE', 1), ('BAR RESCUE', 1)], 'vi_results': [], 'ocr_text': [('Paramount+', 0.9), (\"RUPAUL'S DRAG RACE ALL STARS\", 0.8), ('BIG BROTHER', 0.8), ('THE CHALLENGE', 0.7), ('SURVIVOR', 0.6), ('ARE YOU THE ONE?', 0.5), ('INK MASTER', 0.4), ('QUEEN OF THE UNIVERSE', 0.4), ('BAR RESCUE', 0.3)]}, 'output': {'final': ['INK MASTER', \"RUPAUL'S DRAG RACE ALL STARS\", 'ARE YOU THE ONE?', 'Paramount+', 'QUEEN OF THE UNIVERSE', 'BIG BROTHER', 'SURVIVOR', 'THE CHALLENGE', 'BAR RESCUE']}})]\n",
      "Epoch 26/100, Loss: 3, Weights: [0.20363593 0.29856347 0.49780059] min_loss_Weights: [0.19840362 0.30517768 0.4964187 ] ads: [(6, {'inputs': {'gemini_results': [('Nectar', 1), ('Sealy', 1), ('Casper', 1), ('Serta', 1), ('Stearns & Foster', 1), ('SmartLife', 1), ('King Koil', 1)], 'vi_results': [('Raymour & Flanigan', 0.99), ('Sealy Corporation', 0.99)], 'ocr_text': [('Nectar', 0.9), ('Sealy', 0.8), ('Casper', 0.7), ('Serta', 0.6), ('Stearns & Foster', 0.5), ('SmartLife', 0.4), ('King Koil', 0.3)]}, 'output': {'final': ['SmartLife', 'Casper', 'Serta', 'King Koil', 'Stearns & Foster', 'Nectar', 'Sealy']}}), (26, {'inputs': {'gemini_results': [(\"Baker's\", 1), ('Fox', 1)], 'vi_results': [('KTVU', 0.99), ('Fox Broadcasting Company', 0.99)], 'ocr_text': [('AT&T', 0.9)]}, 'output': {'final': [\"Baker's\", 'Fox']}}), (36, {'inputs': {'gemini_results': [('Paramount+', 1), (\"RUPAUL'S DRAG RACE ALL STARS\", 1), ('BIG BROTHER', 1), ('THE CHALLENGE', 1), ('SURVIVOR', 1), ('ARE YOU THE ONE?', 1), ('INK MASTER', 1), ('QUEEN OF THE UNIVERSE', 1), ('BAR RESCUE', 1)], 'vi_results': [], 'ocr_text': [('Paramount+', 0.9), (\"RUPAUL'S DRAG RACE ALL STARS\", 0.8), ('BIG BROTHER', 0.8), ('THE CHALLENGE', 0.7), ('SURVIVOR', 0.6), ('ARE YOU THE ONE?', 0.5), ('INK MASTER', 0.4), ('QUEEN OF THE UNIVERSE', 0.4), ('BAR RESCUE', 0.3)]}, 'output': {'final': ['INK MASTER', \"RUPAUL'S DRAG RACE ALL STARS\", 'ARE YOU THE ONE?', 'Paramount+', 'QUEEN OF THE UNIVERSE', 'BIG BROTHER', 'SURVIVOR', 'THE CHALLENGE', 'BAR RESCUE']}})]\n",
      "Epoch 27/100, Loss: 6, Weights: [0.1873836  0.29445252 0.51816387] min_loss_Weights: [0.19840362 0.30517768 0.4964187 ] ads: [(6, {'inputs': {'gemini_results': [('Nectar', 1), ('Sealy', 1), ('Casper', 1), ('Serta', 1), ('Stearns & Foster', 1), ('SmartLife', 1), ('King Koil', 1)], 'vi_results': [('Raymour & Flanigan', 0.99), ('Sealy Corporation', 0.99)], 'ocr_text': [('Nectar', 0.9), ('Sealy', 0.8), ('Casper', 0.7), ('Serta', 0.6), ('Stearns & Foster', 0.5), ('SmartLife', 0.4), ('King Koil', 0.3)]}, 'output': {'final': ['SmartLife', 'Casper', 'Serta', 'King Koil', 'Stearns & Foster', 'Nectar', 'Sealy']}}), (26, {'inputs': {'gemini_results': [(\"Baker's\", 1), ('Fox', 1)], 'vi_results': [('KTVU', 0.99), ('Fox Broadcasting Company', 0.99)], 'ocr_text': [('AT&T', 0.9)]}, 'output': {'final': [\"Baker's\", 'Fox']}}), (36, {'inputs': {'gemini_results': [('Paramount+', 1), (\"RUPAUL'S DRAG RACE ALL STARS\", 1), ('BIG BROTHER', 1), ('THE CHALLENGE', 1), ('SURVIVOR', 1), ('ARE YOU THE ONE?', 1), ('INK MASTER', 1), ('QUEEN OF THE UNIVERSE', 1), ('BAR RESCUE', 1)], 'vi_results': [], 'ocr_text': [('Paramount+', 0.9), (\"RUPAUL'S DRAG RACE ALL STARS\", 0.8), ('BIG BROTHER', 0.8), ('THE CHALLENGE', 0.7), ('SURVIVOR', 0.6), ('ARE YOU THE ONE?', 0.5), ('INK MASTER', 0.4), ('QUEEN OF THE UNIVERSE', 0.4), ('BAR RESCUE', 0.3)]}, 'output': {'final': ['INK MASTER', \"RUPAUL'S DRAG RACE ALL STARS\", 'ARE YOU THE ONE?', 'Paramount+', 'QUEEN OF THE UNIVERSE', 'BIG BROTHER', 'SURVIVOR', 'THE CHALLENGE', 'BAR RESCUE']}})]\n",
      "Epoch 28/100, Loss: 3, Weights: [0.1973836  0.29445252 0.50816387] min_loss_Weights: [0.19840362 0.30517768 0.4964187 ] ads: [(6, {'inputs': {'gemini_results': [('Nectar', 1), ('Sealy', 1), ('Casper', 1), ('Serta', 1), ('Stearns & Foster', 1), ('SmartLife', 1), ('King Koil', 1)], 'vi_results': [('Raymour & Flanigan', 0.99), ('Sealy Corporation', 0.99)], 'ocr_text': [('Nectar', 0.9), ('Sealy', 0.8), ('Casper', 0.7), ('Serta', 0.6), ('Stearns & Foster', 0.5), ('SmartLife', 0.4), ('King Koil', 0.3)]}, 'output': {'final': ['SmartLife', 'Casper', 'Serta', 'King Koil', 'Stearns & Foster', 'Nectar', 'Sealy']}}), (26, {'inputs': {'gemini_results': [(\"Baker's\", 1), ('Fox', 1)], 'vi_results': [('KTVU', 0.99), ('Fox Broadcasting Company', 0.99)], 'ocr_text': [('AT&T', 0.9)]}, 'output': {'final': [\"Baker's\", 'Fox']}}), (36, {'inputs': {'gemini_results': [('Paramount+', 1), (\"RUPAUL'S DRAG RACE ALL STARS\", 1), ('BIG BROTHER', 1), ('THE CHALLENGE', 1), ('SURVIVOR', 1), ('ARE YOU THE ONE?', 1), ('INK MASTER', 1), ('QUEEN OF THE UNIVERSE', 1), ('BAR RESCUE', 1)], 'vi_results': [], 'ocr_text': [('Paramount+', 0.9), (\"RUPAUL'S DRAG RACE ALL STARS\", 0.8), ('BIG BROTHER', 0.8), ('THE CHALLENGE', 0.7), ('SURVIVOR', 0.6), ('ARE YOU THE ONE?', 0.5), ('INK MASTER', 0.4), ('QUEEN OF THE UNIVERSE', 0.4), ('BAR RESCUE', 0.3)]}, 'output': {'final': ['INK MASTER', \"RUPAUL'S DRAG RACE ALL STARS\", 'ARE YOU THE ONE?', 'Paramount+', 'QUEEN OF THE UNIVERSE', 'BIG BROTHER', 'SURVIVOR', 'THE CHALLENGE', 'BAR RESCUE']}})]\n",
      "Epoch 29/100, Loss: 4, Weights: [0.1973836  0.30445252 0.49816387] min_loss_Weights: [0.19840362 0.30517768 0.4964187 ] ads: [(6, {'inputs': {'gemini_results': [('Nectar', 1), ('Sealy', 1), ('Casper', 1), ('Serta', 1), ('Stearns & Foster', 1), ('SmartLife', 1), ('King Koil', 1)], 'vi_results': [('Raymour & Flanigan', 0.99), ('Sealy Corporation', 0.99)], 'ocr_text': [('Nectar', 0.9), ('Sealy', 0.8), ('Casper', 0.7), ('Serta', 0.6), ('Stearns & Foster', 0.5), ('SmartLife', 0.4), ('King Koil', 0.3)]}, 'output': {'final': ['SmartLife', 'Casper', 'Serta', 'King Koil', 'Stearns & Foster', 'Nectar', 'Sealy']}}), (26, {'inputs': {'gemini_results': [(\"Baker's\", 1), ('Fox', 1)], 'vi_results': [('KTVU', 0.99), ('Fox Broadcasting Company', 0.99)], 'ocr_text': [('AT&T', 0.9)]}, 'output': {'final': [\"Baker's\", 'Fox']}}), (36, {'inputs': {'gemini_results': [('Paramount+', 1), (\"RUPAUL'S DRAG RACE ALL STARS\", 1), ('BIG BROTHER', 1), ('THE CHALLENGE', 1), ('SURVIVOR', 1), ('ARE YOU THE ONE?', 1), ('INK MASTER', 1), ('QUEEN OF THE UNIVERSE', 1), ('BAR RESCUE', 1)], 'vi_results': [], 'ocr_text': [('Paramount+', 0.9), (\"RUPAUL'S DRAG RACE ALL STARS\", 0.8), ('BIG BROTHER', 0.8), ('THE CHALLENGE', 0.7), ('SURVIVOR', 0.6), ('ARE YOU THE ONE?', 0.5), ('INK MASTER', 0.4), ('QUEEN OF THE UNIVERSE', 0.4), ('BAR RESCUE', 0.3)]}, 'output': {'final': ['INK MASTER', \"RUPAUL'S DRAG RACE ALL STARS\", 'ARE YOU THE ONE?', 'Paramount+', 'QUEEN OF THE UNIVERSE', 'BIG BROTHER', 'SURVIVOR', 'THE CHALLENGE', 'BAR RESCUE']}})]\n",
      "Epoch 30/100, Loss: 5, Weights: [0.19120776 0.29025768 0.51853456] min_loss_Weights: [0.19840362 0.30517768 0.4964187 ] ads: [(6, {'inputs': {'gemini_results': [('Nectar', 1), ('Sealy', 1), ('Casper', 1), ('Serta', 1), ('Stearns & Foster', 1), ('SmartLife', 1), ('King Koil', 1)], 'vi_results': [('Raymour & Flanigan', 0.99), ('Sealy Corporation', 0.99)], 'ocr_text': [('Nectar', 0.9), ('Sealy', 0.8), ('Casper', 0.7), ('Serta', 0.6), ('Stearns & Foster', 0.5), ('SmartLife', 0.4), ('King Koil', 0.3)]}, 'output': {'final': ['SmartLife', 'Casper', 'Serta', 'King Koil', 'Stearns & Foster', 'Nectar', 'Sealy']}}), (26, {'inputs': {'gemini_results': [(\"Baker's\", 1), ('Fox', 1)], 'vi_results': [('KTVU', 0.99), ('Fox Broadcasting Company', 0.99)], 'ocr_text': [('AT&T', 0.9)]}, 'output': {'final': [\"Baker's\", 'Fox']}}), (36, {'inputs': {'gemini_results': [('Paramount+', 1), (\"RUPAUL'S DRAG RACE ALL STARS\", 1), ('BIG BROTHER', 1), ('THE CHALLENGE', 1), ('SURVIVOR', 1), ('ARE YOU THE ONE?', 1), ('INK MASTER', 1), ('QUEEN OF THE UNIVERSE', 1), ('BAR RESCUE', 1)], 'vi_results': [], 'ocr_text': [('Paramount+', 0.9), (\"RUPAUL'S DRAG RACE ALL STARS\", 0.8), ('BIG BROTHER', 0.8), ('THE CHALLENGE', 0.7), ('SURVIVOR', 0.6), ('ARE YOU THE ONE?', 0.5), ('INK MASTER', 0.4), ('QUEEN OF THE UNIVERSE', 0.4), ('BAR RESCUE', 0.3)]}, 'output': {'final': ['INK MASTER', \"RUPAUL'S DRAG RACE ALL STARS\", 'ARE YOU THE ONE?', 'Paramount+', 'QUEEN OF THE UNIVERSE', 'BIG BROTHER', 'SURVIVOR', 'THE CHALLENGE', 'BAR RESCUE']}})]\n",
      "Epoch 31/100, Loss: 4, Weights: [0.19120776 0.30025768 0.50853456] min_loss_Weights: [0.19840362 0.30517768 0.4964187 ] ads: [(6, {'inputs': {'gemini_results': [('Nectar', 1), ('Sealy', 1), ('Casper', 1), ('Serta', 1), ('Stearns & Foster', 1), ('SmartLife', 1), ('King Koil', 1)], 'vi_results': [('Raymour & Flanigan', 0.99), ('Sealy Corporation', 0.99)], 'ocr_text': [('Nectar', 0.9), ('Sealy', 0.8), ('Casper', 0.7), ('Serta', 0.6), ('Stearns & Foster', 0.5), ('SmartLife', 0.4), ('King Koil', 0.3)]}, 'output': {'final': ['SmartLife', 'Casper', 'Serta', 'King Koil', 'Stearns & Foster', 'Nectar', 'Sealy']}}), (26, {'inputs': {'gemini_results': [(\"Baker's\", 1), ('Fox', 1)], 'vi_results': [('KTVU', 0.99), ('Fox Broadcasting Company', 0.99)], 'ocr_text': [('AT&T', 0.9)]}, 'output': {'final': [\"Baker's\", 'Fox']}}), (36, {'inputs': {'gemini_results': [('Paramount+', 1), (\"RUPAUL'S DRAG RACE ALL STARS\", 1), ('BIG BROTHER', 1), ('THE CHALLENGE', 1), ('SURVIVOR', 1), ('ARE YOU THE ONE?', 1), ('INK MASTER', 1), ('QUEEN OF THE UNIVERSE', 1), ('BAR RESCUE', 1)], 'vi_results': [], 'ocr_text': [('Paramount+', 0.9), (\"RUPAUL'S DRAG RACE ALL STARS\", 0.8), ('BIG BROTHER', 0.8), ('THE CHALLENGE', 0.7), ('SURVIVOR', 0.6), ('ARE YOU THE ONE?', 0.5), ('INK MASTER', 0.4), ('QUEEN OF THE UNIVERSE', 0.4), ('BAR RESCUE', 0.3)]}, 'output': {'final': ['INK MASTER', \"RUPAUL'S DRAG RACE ALL STARS\", 'ARE YOU THE ONE?', 'Paramount+', 'QUEEN OF THE UNIVERSE', 'BIG BROTHER', 'SURVIVOR', 'THE CHALLENGE', 'BAR RESCUE']}})]\n",
      "Epoch 32/100, Loss: 3, Weights: [0.20120776 0.30025768 0.49853456] min_loss_Weights: [0.19840362 0.30517768 0.4964187 ] ads: [(6, {'inputs': {'gemini_results': [('Nectar', 1), ('Sealy', 1), ('Casper', 1), ('Serta', 1), ('Stearns & Foster', 1), ('SmartLife', 1), ('King Koil', 1)], 'vi_results': [('Raymour & Flanigan', 0.99), ('Sealy Corporation', 0.99)], 'ocr_text': [('Nectar', 0.9), ('Sealy', 0.8), ('Casper', 0.7), ('Serta', 0.6), ('Stearns & Foster', 0.5), ('SmartLife', 0.4), ('King Koil', 0.3)]}, 'output': {'final': ['SmartLife', 'Casper', 'Serta', 'King Koil', 'Stearns & Foster', 'Nectar', 'Sealy']}}), (26, {'inputs': {'gemini_results': [(\"Baker's\", 1), ('Fox', 1)], 'vi_results': [('KTVU', 0.99), ('Fox Broadcasting Company', 0.99)], 'ocr_text': [('AT&T', 0.9)]}, 'output': {'final': [\"Baker's\", 'Fox']}}), (36, {'inputs': {'gemini_results': [('Paramount+', 1), (\"RUPAUL'S DRAG RACE ALL STARS\", 1), ('BIG BROTHER', 1), ('THE CHALLENGE', 1), ('SURVIVOR', 1), ('ARE YOU THE ONE?', 1), ('INK MASTER', 1), ('QUEEN OF THE UNIVERSE', 1), ('BAR RESCUE', 1)], 'vi_results': [], 'ocr_text': [('Paramount+', 0.9), (\"RUPAUL'S DRAG RACE ALL STARS\", 0.8), ('BIG BROTHER', 0.8), ('THE CHALLENGE', 0.7), ('SURVIVOR', 0.6), ('ARE YOU THE ONE?', 0.5), ('INK MASTER', 0.4), ('QUEEN OF THE UNIVERSE', 0.4), ('BAR RESCUE', 0.3)]}, 'output': {'final': ['INK MASTER', \"RUPAUL'S DRAG RACE ALL STARS\", 'ARE YOU THE ONE?', 'Paramount+', 'QUEEN OF THE UNIVERSE', 'BIG BROTHER', 'SURVIVOR', 'THE CHALLENGE', 'BAR RESCUE']}})]\n",
      "Epoch 33/100, Loss: 4, Weights: [0.20120776 0.31025768 0.48853456] min_loss_Weights: [0.19840362 0.30517768 0.4964187 ] ads: [(6, {'inputs': {'gemini_results': [('Nectar', 1), ('Sealy', 1), ('Casper', 1), ('Serta', 1), ('Stearns & Foster', 1), ('SmartLife', 1), ('King Koil', 1)], 'vi_results': [('Raymour & Flanigan', 0.99), ('Sealy Corporation', 0.99)], 'ocr_text': [('Nectar', 0.9), ('Sealy', 0.8), ('Casper', 0.7), ('Serta', 0.6), ('Stearns & Foster', 0.5), ('SmartLife', 0.4), ('King Koil', 0.3)]}, 'output': {'final': ['SmartLife', 'Casper', 'Serta', 'King Koil', 'Stearns & Foster', 'Nectar', 'Sealy']}}), (26, {'inputs': {'gemini_results': [(\"Baker's\", 1), ('Fox', 1)], 'vi_results': [('KTVU', 0.99), ('Fox Broadcasting Company', 0.99)], 'ocr_text': [('AT&T', 0.9)]}, 'output': {'final': [\"Baker's\", 'Fox']}}), (36, {'inputs': {'gemini_results': [('Paramount+', 1), (\"RUPAUL'S DRAG RACE ALL STARS\", 1), ('BIG BROTHER', 1), ('THE CHALLENGE', 1), ('SURVIVOR', 1), ('ARE YOU THE ONE?', 1), ('INK MASTER', 1), ('QUEEN OF THE UNIVERSE', 1), ('BAR RESCUE', 1)], 'vi_results': [], 'ocr_text': [('Paramount+', 0.9), (\"RUPAUL'S DRAG RACE ALL STARS\", 0.8), ('BIG BROTHER', 0.8), ('THE CHALLENGE', 0.7), ('SURVIVOR', 0.6), ('ARE YOU THE ONE?', 0.5), ('INK MASTER', 0.4), ('QUEEN OF THE UNIVERSE', 0.4), ('BAR RESCUE', 0.3)]}, 'output': {'final': ['INK MASTER', \"RUPAUL'S DRAG RACE ALL STARS\", 'ARE YOU THE ONE?', 'Paramount+', 'QUEEN OF THE UNIVERSE', 'BIG BROTHER', 'SURVIVOR', 'THE CHALLENGE', 'BAR RESCUE']}})]\n",
      "Epoch 34/100, Loss: 5, Weights: [0.19510996 0.2961813  0.50870874] min_loss_Weights: [0.19840362 0.30517768 0.4964187 ] ads: [(6, {'inputs': {'gemini_results': [('Nectar', 1), ('Sealy', 1), ('Casper', 1), ('Serta', 1), ('Stearns & Foster', 1), ('SmartLife', 1), ('King Koil', 1)], 'vi_results': [('Raymour & Flanigan', 0.99), ('Sealy Corporation', 0.99)], 'ocr_text': [('Nectar', 0.9), ('Sealy', 0.8), ('Casper', 0.7), ('Serta', 0.6), ('Stearns & Foster', 0.5), ('SmartLife', 0.4), ('King Koil', 0.3)]}, 'output': {'final': ['SmartLife', 'Casper', 'Serta', 'King Koil', 'Stearns & Foster', 'Nectar', 'Sealy']}}), (26, {'inputs': {'gemini_results': [(\"Baker's\", 1), ('Fox', 1)], 'vi_results': [('KTVU', 0.99), ('Fox Broadcasting Company', 0.99)], 'ocr_text': [('AT&T', 0.9)]}, 'output': {'final': [\"Baker's\", 'Fox']}}), (36, {'inputs': {'gemini_results': [('Paramount+', 1), (\"RUPAUL'S DRAG RACE ALL STARS\", 1), ('BIG BROTHER', 1), ('THE CHALLENGE', 1), ('SURVIVOR', 1), ('ARE YOU THE ONE?', 1), ('INK MASTER', 1), ('QUEEN OF THE UNIVERSE', 1), ('BAR RESCUE', 1)], 'vi_results': [], 'ocr_text': [('Paramount+', 0.9), (\"RUPAUL'S DRAG RACE ALL STARS\", 0.8), ('BIG BROTHER', 0.8), ('THE CHALLENGE', 0.7), ('SURVIVOR', 0.6), ('ARE YOU THE ONE?', 0.5), ('INK MASTER', 0.4), ('QUEEN OF THE UNIVERSE', 0.4), ('BAR RESCUE', 0.3)]}, 'output': {'final': ['INK MASTER', \"RUPAUL'S DRAG RACE ALL STARS\", 'ARE YOU THE ONE?', 'Paramount+', 'QUEEN OF THE UNIVERSE', 'BIG BROTHER', 'SURVIVOR', 'THE CHALLENGE', 'BAR RESCUE']}})]\n",
      "Epoch 35/100, Loss: 4, Weights: [0.19510996 0.3061813  0.49870874] min_loss_Weights: [0.19840362 0.30517768 0.4964187 ] ads: [(6, {'inputs': {'gemini_results': [('Nectar', 1), ('Sealy', 1), ('Casper', 1), ('Serta', 1), ('Stearns & Foster', 1), ('SmartLife', 1), ('King Koil', 1)], 'vi_results': [('Raymour & Flanigan', 0.99), ('Sealy Corporation', 0.99)], 'ocr_text': [('Nectar', 0.9), ('Sealy', 0.8), ('Casper', 0.7), ('Serta', 0.6), ('Stearns & Foster', 0.5), ('SmartLife', 0.4), ('King Koil', 0.3)]}, 'output': {'final': ['SmartLife', 'Casper', 'Serta', 'King Koil', 'Stearns & Foster', 'Nectar', 'Sealy']}}), (26, {'inputs': {'gemini_results': [(\"Baker's\", 1), ('Fox', 1)], 'vi_results': [('KTVU', 0.99), ('Fox Broadcasting Company', 0.99)], 'ocr_text': [('AT&T', 0.9)]}, 'output': {'final': [\"Baker's\", 'Fox']}}), (36, {'inputs': {'gemini_results': [('Paramount+', 1), (\"RUPAUL'S DRAG RACE ALL STARS\", 1), ('BIG BROTHER', 1), ('THE CHALLENGE', 1), ('SURVIVOR', 1), ('ARE YOU THE ONE?', 1), ('INK MASTER', 1), ('QUEEN OF THE UNIVERSE', 1), ('BAR RESCUE', 1)], 'vi_results': [], 'ocr_text': [('Paramount+', 0.9), (\"RUPAUL'S DRAG RACE ALL STARS\", 0.8), ('BIG BROTHER', 0.8), ('THE CHALLENGE', 0.7), ('SURVIVOR', 0.6), ('ARE YOU THE ONE?', 0.5), ('INK MASTER', 0.4), ('QUEEN OF THE UNIVERSE', 0.4), ('BAR RESCUE', 0.3)]}, 'output': {'final': ['INK MASTER', \"RUPAUL'S DRAG RACE ALL STARS\", 'ARE YOU THE ONE?', 'Paramount+', 'QUEEN OF THE UNIVERSE', 'BIG BROTHER', 'SURVIVOR', 'THE CHALLENGE', 'BAR RESCUE']}})]\n",
      "Epoch 36/100, Loss: 3, Weights: [0.20510996 0.3061813  0.48870874] min_loss_Weights: [0.19840362 0.30517768 0.4964187 ] ads: [(6, {'inputs': {'gemini_results': [('Nectar', 1), ('Sealy', 1), ('Casper', 1), ('Serta', 1), ('Stearns & Foster', 1), ('SmartLife', 1), ('King Koil', 1)], 'vi_results': [('Raymour & Flanigan', 0.99), ('Sealy Corporation', 0.99)], 'ocr_text': [('Nectar', 0.9), ('Sealy', 0.8), ('Casper', 0.7), ('Serta', 0.6), ('Stearns & Foster', 0.5), ('SmartLife', 0.4), ('King Koil', 0.3)]}, 'output': {'final': ['SmartLife', 'Casper', 'Serta', 'King Koil', 'Stearns & Foster', 'Nectar', 'Sealy']}}), (26, {'inputs': {'gemini_results': [(\"Baker's\", 1), ('Fox', 1)], 'vi_results': [('KTVU', 0.99), ('Fox Broadcasting Company', 0.99)], 'ocr_text': [('AT&T', 0.9)]}, 'output': {'final': [\"Baker's\", 'Fox']}}), (36, {'inputs': {'gemini_results': [('Paramount+', 1), (\"RUPAUL'S DRAG RACE ALL STARS\", 1), ('BIG BROTHER', 1), ('THE CHALLENGE', 1), ('SURVIVOR', 1), ('ARE YOU THE ONE?', 1), ('INK MASTER', 1), ('QUEEN OF THE UNIVERSE', 1), ('BAR RESCUE', 1)], 'vi_results': [], 'ocr_text': [('Paramount+', 0.9), (\"RUPAUL'S DRAG RACE ALL STARS\", 0.8), ('BIG BROTHER', 0.8), ('THE CHALLENGE', 0.7), ('SURVIVOR', 0.6), ('ARE YOU THE ONE?', 0.5), ('INK MASTER', 0.4), ('QUEEN OF THE UNIVERSE', 0.4), ('BAR RESCUE', 0.3)]}, 'output': {'final': ['INK MASTER', \"RUPAUL'S DRAG RACE ALL STARS\", 'ARE YOU THE ONE?', 'Paramount+', 'QUEEN OF THE UNIVERSE', 'BIG BROTHER', 'SURVIVOR', 'THE CHALLENGE', 'BAR RESCUE']}})]\n",
      "Epoch 37/100, Loss: 5, Weights: [0.19909179 0.29202174 0.50888647] min_loss_Weights: [0.19840362 0.30517768 0.4964187 ] ads: [(6, {'inputs': {'gemini_results': [('Nectar', 1), ('Sealy', 1), ('Casper', 1), ('Serta', 1), ('Stearns & Foster', 1), ('SmartLife', 1), ('King Koil', 1)], 'vi_results': [('Raymour & Flanigan', 0.99), ('Sealy Corporation', 0.99)], 'ocr_text': [('Nectar', 0.9), ('Sealy', 0.8), ('Casper', 0.7), ('Serta', 0.6), ('Stearns & Foster', 0.5), ('SmartLife', 0.4), ('King Koil', 0.3)]}, 'output': {'final': ['SmartLife', 'Casper', 'Serta', 'King Koil', 'Stearns & Foster', 'Nectar', 'Sealy']}}), (26, {'inputs': {'gemini_results': [(\"Baker's\", 1), ('Fox', 1)], 'vi_results': [('KTVU', 0.99), ('Fox Broadcasting Company', 0.99)], 'ocr_text': [('AT&T', 0.9)]}, 'output': {'final': [\"Baker's\", 'Fox']}}), (36, {'inputs': {'gemini_results': [('Paramount+', 1), (\"RUPAUL'S DRAG RACE ALL STARS\", 1), ('BIG BROTHER', 1), ('THE CHALLENGE', 1), ('SURVIVOR', 1), ('ARE YOU THE ONE?', 1), ('INK MASTER', 1), ('QUEEN OF THE UNIVERSE', 1), ('BAR RESCUE', 1)], 'vi_results': [], 'ocr_text': [('Paramount+', 0.9), (\"RUPAUL'S DRAG RACE ALL STARS\", 0.8), ('BIG BROTHER', 0.8), ('THE CHALLENGE', 0.7), ('SURVIVOR', 0.6), ('ARE YOU THE ONE?', 0.5), ('INK MASTER', 0.4), ('QUEEN OF THE UNIVERSE', 0.4), ('BAR RESCUE', 0.3)]}, 'output': {'final': ['INK MASTER', \"RUPAUL'S DRAG RACE ALL STARS\", 'ARE YOU THE ONE?', 'Paramount+', 'QUEEN OF THE UNIVERSE', 'BIG BROTHER', 'SURVIVOR', 'THE CHALLENGE', 'BAR RESCUE']}})]\n",
      "Epoch 38/100, Loss: 4, Weights: [0.19909179 0.30202174 0.49888647] min_loss_Weights: [0.19840362 0.30517768 0.4964187 ] ads: [(6, {'inputs': {'gemini_results': [('Nectar', 1), ('Sealy', 1), ('Casper', 1), ('Serta', 1), ('Stearns & Foster', 1), ('SmartLife', 1), ('King Koil', 1)], 'vi_results': [('Raymour & Flanigan', 0.99), ('Sealy Corporation', 0.99)], 'ocr_text': [('Nectar', 0.9), ('Sealy', 0.8), ('Casper', 0.7), ('Serta', 0.6), ('Stearns & Foster', 0.5), ('SmartLife', 0.4), ('King Koil', 0.3)]}, 'output': {'final': ['SmartLife', 'Casper', 'Serta', 'King Koil', 'Stearns & Foster', 'Nectar', 'Sealy']}}), (26, {'inputs': {'gemini_results': [(\"Baker's\", 1), ('Fox', 1)], 'vi_results': [('KTVU', 0.99), ('Fox Broadcasting Company', 0.99)], 'ocr_text': [('AT&T', 0.9)]}, 'output': {'final': [\"Baker's\", 'Fox']}}), (36, {'inputs': {'gemini_results': [('Paramount+', 1), (\"RUPAUL'S DRAG RACE ALL STARS\", 1), ('BIG BROTHER', 1), ('THE CHALLENGE', 1), ('SURVIVOR', 1), ('ARE YOU THE ONE?', 1), ('INK MASTER', 1), ('QUEEN OF THE UNIVERSE', 1), ('BAR RESCUE', 1)], 'vi_results': [], 'ocr_text': [('Paramount+', 0.9), (\"RUPAUL'S DRAG RACE ALL STARS\", 0.8), ('BIG BROTHER', 0.8), ('THE CHALLENGE', 0.7), ('SURVIVOR', 0.6), ('ARE YOU THE ONE?', 0.5), ('INK MASTER', 0.4), ('QUEEN OF THE UNIVERSE', 0.4), ('BAR RESCUE', 0.3)]}, 'output': {'final': ['INK MASTER', \"RUPAUL'S DRAG RACE ALL STARS\", 'ARE YOU THE ONE?', 'Paramount+', 'QUEEN OF THE UNIVERSE', 'BIG BROTHER', 'SURVIVOR', 'THE CHALLENGE', 'BAR RESCUE']}})]\n",
      "Epoch 39/100, Loss: 3, Weights: [0.20909179 0.30202174 0.48888647] min_loss_Weights: [0.19840362 0.30517768 0.4964187 ] ads: [(6, {'inputs': {'gemini_results': [('Nectar', 1), ('Sealy', 1), ('Casper', 1), ('Serta', 1), ('Stearns & Foster', 1), ('SmartLife', 1), ('King Koil', 1)], 'vi_results': [('Raymour & Flanigan', 0.99), ('Sealy Corporation', 0.99)], 'ocr_text': [('Nectar', 0.9), ('Sealy', 0.8), ('Casper', 0.7), ('Serta', 0.6), ('Stearns & Foster', 0.5), ('SmartLife', 0.4), ('King Koil', 0.3)]}, 'output': {'final': ['SmartLife', 'Casper', 'Serta', 'King Koil', 'Stearns & Foster', 'Nectar', 'Sealy']}}), (26, {'inputs': {'gemini_results': [(\"Baker's\", 1), ('Fox', 1)], 'vi_results': [('KTVU', 0.99), ('Fox Broadcasting Company', 0.99)], 'ocr_text': [('AT&T', 0.9)]}, 'output': {'final': [\"Baker's\", 'Fox']}}), (36, {'inputs': {'gemini_results': [('Paramount+', 1), (\"RUPAUL'S DRAG RACE ALL STARS\", 1), ('BIG BROTHER', 1), ('THE CHALLENGE', 1), ('SURVIVOR', 1), ('ARE YOU THE ONE?', 1), ('INK MASTER', 1), ('QUEEN OF THE UNIVERSE', 1), ('BAR RESCUE', 1)], 'vi_results': [], 'ocr_text': [('Paramount+', 0.9), (\"RUPAUL'S DRAG RACE ALL STARS\", 0.8), ('BIG BROTHER', 0.8), ('THE CHALLENGE', 0.7), ('SURVIVOR', 0.6), ('ARE YOU THE ONE?', 0.5), ('INK MASTER', 0.4), ('QUEEN OF THE UNIVERSE', 0.4), ('BAR RESCUE', 0.3)]}, 'output': {'final': ['INK MASTER', \"RUPAUL'S DRAG RACE ALL STARS\", 'ARE YOU THE ONE?', 'Paramount+', 'QUEEN OF THE UNIVERSE', 'BIG BROTHER', 'SURVIVOR', 'THE CHALLENGE', 'BAR RESCUE']}})]\n",
      "Epoch 40/100, Loss: 6, Weights: [0.19295081 0.29798137 0.50906782] min_loss_Weights: [0.19840362 0.30517768 0.4964187 ] ads: [(6, {'inputs': {'gemini_results': [('Nectar', 1), ('Sealy', 1), ('Casper', 1), ('Serta', 1), ('Stearns & Foster', 1), ('SmartLife', 1), ('King Koil', 1)], 'vi_results': [('Raymour & Flanigan', 0.99), ('Sealy Corporation', 0.99)], 'ocr_text': [('Nectar', 0.9), ('Sealy', 0.8), ('Casper', 0.7), ('Serta', 0.6), ('Stearns & Foster', 0.5), ('SmartLife', 0.4), ('King Koil', 0.3)]}, 'output': {'final': ['SmartLife', 'Casper', 'Serta', 'King Koil', 'Stearns & Foster', 'Nectar', 'Sealy']}}), (26, {'inputs': {'gemini_results': [(\"Baker's\", 1), ('Fox', 1)], 'vi_results': [('KTVU', 0.99), ('Fox Broadcasting Company', 0.99)], 'ocr_text': [('AT&T', 0.9)]}, 'output': {'final': [\"Baker's\", 'Fox']}}), (36, {'inputs': {'gemini_results': [('Paramount+', 1), (\"RUPAUL'S DRAG RACE ALL STARS\", 1), ('BIG BROTHER', 1), ('THE CHALLENGE', 1), ('SURVIVOR', 1), ('ARE YOU THE ONE?', 1), ('INK MASTER', 1), ('QUEEN OF THE UNIVERSE', 1), ('BAR RESCUE', 1)], 'vi_results': [], 'ocr_text': [('Paramount+', 0.9), (\"RUPAUL'S DRAG RACE ALL STARS\", 0.8), ('BIG BROTHER', 0.8), ('THE CHALLENGE', 0.7), ('SURVIVOR', 0.6), ('ARE YOU THE ONE?', 0.5), ('INK MASTER', 0.4), ('QUEEN OF THE UNIVERSE', 0.4), ('BAR RESCUE', 0.3)]}, 'output': {'final': ['INK MASTER', \"RUPAUL'S DRAG RACE ALL STARS\", 'ARE YOU THE ONE?', 'Paramount+', 'QUEEN OF THE UNIVERSE', 'BIG BROTHER', 'SURVIVOR', 'THE CHALLENGE', 'BAR RESCUE']}})]\n",
      "Epoch 41/100, Loss: 3, Weights: [0.20295081 0.29798137 0.49906782] min_loss_Weights: [0.19840362 0.30517768 0.4964187 ] ads: [(6, {'inputs': {'gemini_results': [('Nectar', 1), ('Sealy', 1), ('Casper', 1), ('Serta', 1), ('Stearns & Foster', 1), ('SmartLife', 1), ('King Koil', 1)], 'vi_results': [('Raymour & Flanigan', 0.99), ('Sealy Corporation', 0.99)], 'ocr_text': [('Nectar', 0.9), ('Sealy', 0.8), ('Casper', 0.7), ('Serta', 0.6), ('Stearns & Foster', 0.5), ('SmartLife', 0.4), ('King Koil', 0.3)]}, 'output': {'final': ['SmartLife', 'Casper', 'Serta', 'King Koil', 'Stearns & Foster', 'Nectar', 'Sealy']}}), (26, {'inputs': {'gemini_results': [(\"Baker's\", 1), ('Fox', 1)], 'vi_results': [('KTVU', 0.99), ('Fox Broadcasting Company', 0.99)], 'ocr_text': [('AT&T', 0.9)]}, 'output': {'final': [\"Baker's\", 'Fox']}}), (36, {'inputs': {'gemini_results': [('Paramount+', 1), (\"RUPAUL'S DRAG RACE ALL STARS\", 1), ('BIG BROTHER', 1), ('THE CHALLENGE', 1), ('SURVIVOR', 1), ('ARE YOU THE ONE?', 1), ('INK MASTER', 1), ('QUEEN OF THE UNIVERSE', 1), ('BAR RESCUE', 1)], 'vi_results': [], 'ocr_text': [('Paramount+', 0.9), (\"RUPAUL'S DRAG RACE ALL STARS\", 0.8), ('BIG BROTHER', 0.8), ('THE CHALLENGE', 0.7), ('SURVIVOR', 0.6), ('ARE YOU THE ONE?', 0.5), ('INK MASTER', 0.4), ('QUEEN OF THE UNIVERSE', 0.4), ('BAR RESCUE', 0.3)]}, 'output': {'final': ['INK MASTER', \"RUPAUL'S DRAG RACE ALL STARS\", 'ARE YOU THE ONE?', 'Paramount+', 'QUEEN OF THE UNIVERSE', 'BIG BROTHER', 'SURVIVOR', 'THE CHALLENGE', 'BAR RESCUE']}})]\n",
      "Epoch 42/100, Loss: 4, Weights: [0.20295081 0.30798137 0.48906782] min_loss_Weights: [0.19840362 0.30517768 0.4964187 ] ads: [(6, {'inputs': {'gemini_results': [('Nectar', 1), ('Sealy', 1), ('Casper', 1), ('Serta', 1), ('Stearns & Foster', 1), ('SmartLife', 1), ('King Koil', 1)], 'vi_results': [('Raymour & Flanigan', 0.99), ('Sealy Corporation', 0.99)], 'ocr_text': [('Nectar', 0.9), ('Sealy', 0.8), ('Casper', 0.7), ('Serta', 0.6), ('Stearns & Foster', 0.5), ('SmartLife', 0.4), ('King Koil', 0.3)]}, 'output': {'final': ['SmartLife', 'Casper', 'Serta', 'King Koil', 'Stearns & Foster', 'Nectar', 'Sealy']}}), (26, {'inputs': {'gemini_results': [(\"Baker's\", 1), ('Fox', 1)], 'vi_results': [('KTVU', 0.99), ('Fox Broadcasting Company', 0.99)], 'ocr_text': [('AT&T', 0.9)]}, 'output': {'final': [\"Baker's\", 'Fox']}}), (36, {'inputs': {'gemini_results': [('Paramount+', 1), (\"RUPAUL'S DRAG RACE ALL STARS\", 1), ('BIG BROTHER', 1), ('THE CHALLENGE', 1), ('SURVIVOR', 1), ('ARE YOU THE ONE?', 1), ('INK MASTER', 1), ('QUEEN OF THE UNIVERSE', 1), ('BAR RESCUE', 1)], 'vi_results': [], 'ocr_text': [('Paramount+', 0.9), (\"RUPAUL'S DRAG RACE ALL STARS\", 0.8), ('BIG BROTHER', 0.8), ('THE CHALLENGE', 0.7), ('SURVIVOR', 0.6), ('ARE YOU THE ONE?', 0.5), ('INK MASTER', 0.4), ('QUEEN OF THE UNIVERSE', 0.4), ('BAR RESCUE', 0.3)]}, 'output': {'final': ['INK MASTER', \"RUPAUL'S DRAG RACE ALL STARS\", 'ARE YOU THE ONE?', 'Paramount+', 'QUEEN OF THE UNIVERSE', 'BIG BROTHER', 'SURVIVOR', 'THE CHALLENGE', 'BAR RESCUE']}})]\n",
      "Epoch 43/100, Loss: 5, Weights: [0.19688858 0.29385854 0.50925288] min_loss_Weights: [0.19840362 0.30517768 0.4964187 ] ads: [(6, {'inputs': {'gemini_results': [('Nectar', 1), ('Sealy', 1), ('Casper', 1), ('Serta', 1), ('Stearns & Foster', 1), ('SmartLife', 1), ('King Koil', 1)], 'vi_results': [('Raymour & Flanigan', 0.99), ('Sealy Corporation', 0.99)], 'ocr_text': [('Nectar', 0.9), ('Sealy', 0.8), ('Casper', 0.7), ('Serta', 0.6), ('Stearns & Foster', 0.5), ('SmartLife', 0.4), ('King Koil', 0.3)]}, 'output': {'final': ['SmartLife', 'Casper', 'Serta', 'King Koil', 'Stearns & Foster', 'Nectar', 'Sealy']}}), (26, {'inputs': {'gemini_results': [(\"Baker's\", 1), ('Fox', 1)], 'vi_results': [('KTVU', 0.99), ('Fox Broadcasting Company', 0.99)], 'ocr_text': [('AT&T', 0.9)]}, 'output': {'final': [\"Baker's\", 'Fox']}}), (36, {'inputs': {'gemini_results': [('Paramount+', 1), (\"RUPAUL'S DRAG RACE ALL STARS\", 1), ('BIG BROTHER', 1), ('THE CHALLENGE', 1), ('SURVIVOR', 1), ('ARE YOU THE ONE?', 1), ('INK MASTER', 1), ('QUEEN OF THE UNIVERSE', 1), ('BAR RESCUE', 1)], 'vi_results': [], 'ocr_text': [('Paramount+', 0.9), (\"RUPAUL'S DRAG RACE ALL STARS\", 0.8), ('BIG BROTHER', 0.8), ('THE CHALLENGE', 0.7), ('SURVIVOR', 0.6), ('ARE YOU THE ONE?', 0.5), ('INK MASTER', 0.4), ('QUEEN OF THE UNIVERSE', 0.4), ('BAR RESCUE', 0.3)]}, 'output': {'final': ['INK MASTER', \"RUPAUL'S DRAG RACE ALL STARS\", 'ARE YOU THE ONE?', 'Paramount+', 'QUEEN OF THE UNIVERSE', 'BIG BROTHER', 'SURVIVOR', 'THE CHALLENGE', 'BAR RESCUE']}})]\n",
      "Epoch 44/100, Loss: 4, Weights: [0.19688858 0.30385854 0.49925288] min_loss_Weights: [0.19840362 0.30517768 0.4964187 ] ads: [(6, {'inputs': {'gemini_results': [('Nectar', 1), ('Sealy', 1), ('Casper', 1), ('Serta', 1), ('Stearns & Foster', 1), ('SmartLife', 1), ('King Koil', 1)], 'vi_results': [('Raymour & Flanigan', 0.99), ('Sealy Corporation', 0.99)], 'ocr_text': [('Nectar', 0.9), ('Sealy', 0.8), ('Casper', 0.7), ('Serta', 0.6), ('Stearns & Foster', 0.5), ('SmartLife', 0.4), ('King Koil', 0.3)]}, 'output': {'final': ['SmartLife', 'Casper', 'Serta', 'King Koil', 'Stearns & Foster', 'Nectar', 'Sealy']}}), (26, {'inputs': {'gemini_results': [(\"Baker's\", 1), ('Fox', 1)], 'vi_results': [('KTVU', 0.99), ('Fox Broadcasting Company', 0.99)], 'ocr_text': [('AT&T', 0.9)]}, 'output': {'final': [\"Baker's\", 'Fox']}}), (36, {'inputs': {'gemini_results': [('Paramount+', 1), (\"RUPAUL'S DRAG RACE ALL STARS\", 1), ('BIG BROTHER', 1), ('THE CHALLENGE', 1), ('SURVIVOR', 1), ('ARE YOU THE ONE?', 1), ('INK MASTER', 1), ('QUEEN OF THE UNIVERSE', 1), ('BAR RESCUE', 1)], 'vi_results': [], 'ocr_text': [('Paramount+', 0.9), (\"RUPAUL'S DRAG RACE ALL STARS\", 0.8), ('BIG BROTHER', 0.8), ('THE CHALLENGE', 0.7), ('SURVIVOR', 0.6), ('ARE YOU THE ONE?', 0.5), ('INK MASTER', 0.4), ('QUEEN OF THE UNIVERSE', 0.4), ('BAR RESCUE', 0.3)]}, 'output': {'final': ['INK MASTER', \"RUPAUL'S DRAG RACE ALL STARS\", 'ARE YOU THE ONE?', 'Paramount+', 'QUEEN OF THE UNIVERSE', 'BIG BROTHER', 'SURVIVOR', 'THE CHALLENGE', 'BAR RESCUE']}})]\n",
      "Epoch 45/100, Loss: 3, Weights: [0.20688858 0.30385854 0.48925288] min_loss_Weights: [0.19840362 0.30517768 0.4964187 ] ads: [(6, {'inputs': {'gemini_results': [('Nectar', 1), ('Sealy', 1), ('Casper', 1), ('Serta', 1), ('Stearns & Foster', 1), ('SmartLife', 1), ('King Koil', 1)], 'vi_results': [('Raymour & Flanigan', 0.99), ('Sealy Corporation', 0.99)], 'ocr_text': [('Nectar', 0.9), ('Sealy', 0.8), ('Casper', 0.7), ('Serta', 0.6), ('Stearns & Foster', 0.5), ('SmartLife', 0.4), ('King Koil', 0.3)]}, 'output': {'final': ['SmartLife', 'Casper', 'Serta', 'King Koil', 'Stearns & Foster', 'Nectar', 'Sealy']}}), (26, {'inputs': {'gemini_results': [(\"Baker's\", 1), ('Fox', 1)], 'vi_results': [('KTVU', 0.99), ('Fox Broadcasting Company', 0.99)], 'ocr_text': [('AT&T', 0.9)]}, 'output': {'final': [\"Baker's\", 'Fox']}}), (36, {'inputs': {'gemini_results': [('Paramount+', 1), (\"RUPAUL'S DRAG RACE ALL STARS\", 1), ('BIG BROTHER', 1), ('THE CHALLENGE', 1), ('SURVIVOR', 1), ('ARE YOU THE ONE?', 1), ('INK MASTER', 1), ('QUEEN OF THE UNIVERSE', 1), ('BAR RESCUE', 1)], 'vi_results': [], 'ocr_text': [('Paramount+', 0.9), (\"RUPAUL'S DRAG RACE ALL STARS\", 0.8), ('BIG BROTHER', 0.8), ('THE CHALLENGE', 0.7), ('SURVIVOR', 0.6), ('ARE YOU THE ONE?', 0.5), ('INK MASTER', 0.4), ('QUEEN OF THE UNIVERSE', 0.4), ('BAR RESCUE', 0.3)]}, 'output': {'final': ['INK MASTER', \"RUPAUL'S DRAG RACE ALL STARS\", 'ARE YOU THE ONE?', 'Paramount+', 'QUEEN OF THE UNIVERSE', 'BIG BROTHER', 'SURVIVOR', 'THE CHALLENGE', 'BAR RESCUE']}})]\n",
      "Epoch 46/100, Loss: 6, Weights: [0.19070264 0.29985565 0.50944172] min_loss_Weights: [0.19840362 0.30517768 0.4964187 ] ads: [(6, {'inputs': {'gemini_results': [('Nectar', 1), ('Sealy', 1), ('Casper', 1), ('Serta', 1), ('Stearns & Foster', 1), ('SmartLife', 1), ('King Koil', 1)], 'vi_results': [('Raymour & Flanigan', 0.99), ('Sealy Corporation', 0.99)], 'ocr_text': [('Nectar', 0.9), ('Sealy', 0.8), ('Casper', 0.7), ('Serta', 0.6), ('Stearns & Foster', 0.5), ('SmartLife', 0.4), ('King Koil', 0.3)]}, 'output': {'final': ['SmartLife', 'Casper', 'Serta', 'King Koil', 'Stearns & Foster', 'Nectar', 'Sealy']}}), (26, {'inputs': {'gemini_results': [(\"Baker's\", 1), ('Fox', 1)], 'vi_results': [('KTVU', 0.99), ('Fox Broadcasting Company', 0.99)], 'ocr_text': [('AT&T', 0.9)]}, 'output': {'final': [\"Baker's\", 'Fox']}}), (36, {'inputs': {'gemini_results': [('Paramount+', 1), (\"RUPAUL'S DRAG RACE ALL STARS\", 1), ('BIG BROTHER', 1), ('THE CHALLENGE', 1), ('SURVIVOR', 1), ('ARE YOU THE ONE?', 1), ('INK MASTER', 1), ('QUEEN OF THE UNIVERSE', 1), ('BAR RESCUE', 1)], 'vi_results': [], 'ocr_text': [('Paramount+', 0.9), (\"RUPAUL'S DRAG RACE ALL STARS\", 0.8), ('BIG BROTHER', 0.8), ('THE CHALLENGE', 0.7), ('SURVIVOR', 0.6), ('ARE YOU THE ONE?', 0.5), ('INK MASTER', 0.4), ('QUEEN OF THE UNIVERSE', 0.4), ('BAR RESCUE', 0.3)]}, 'output': {'final': ['INK MASTER', \"RUPAUL'S DRAG RACE ALL STARS\", 'ARE YOU THE ONE?', 'Paramount+', 'QUEEN OF THE UNIVERSE', 'BIG BROTHER', 'SURVIVOR', 'THE CHALLENGE', 'BAR RESCUE']}})]\n",
      "Epoch 47/100, Loss: 3, Weights: [0.20070264 0.29985565 0.49944172] min_loss_Weights: [0.19840362 0.30517768 0.4964187 ] ads: [(6, {'inputs': {'gemini_results': [('Nectar', 1), ('Sealy', 1), ('Casper', 1), ('Serta', 1), ('Stearns & Foster', 1), ('SmartLife', 1), ('King Koil', 1)], 'vi_results': [('Raymour & Flanigan', 0.99), ('Sealy Corporation', 0.99)], 'ocr_text': [('Nectar', 0.9), ('Sealy', 0.8), ('Casper', 0.7), ('Serta', 0.6), ('Stearns & Foster', 0.5), ('SmartLife', 0.4), ('King Koil', 0.3)]}, 'output': {'final': ['SmartLife', 'Casper', 'Serta', 'King Koil', 'Stearns & Foster', 'Nectar', 'Sealy']}}), (26, {'inputs': {'gemini_results': [(\"Baker's\", 1), ('Fox', 1)], 'vi_results': [('KTVU', 0.99), ('Fox Broadcasting Company', 0.99)], 'ocr_text': [('AT&T', 0.9)]}, 'output': {'final': [\"Baker's\", 'Fox']}}), (36, {'inputs': {'gemini_results': [('Paramount+', 1), (\"RUPAUL'S DRAG RACE ALL STARS\", 1), ('BIG BROTHER', 1), ('THE CHALLENGE', 1), ('SURVIVOR', 1), ('ARE YOU THE ONE?', 1), ('INK MASTER', 1), ('QUEEN OF THE UNIVERSE', 1), ('BAR RESCUE', 1)], 'vi_results': [], 'ocr_text': [('Paramount+', 0.9), (\"RUPAUL'S DRAG RACE ALL STARS\", 0.8), ('BIG BROTHER', 0.8), ('THE CHALLENGE', 0.7), ('SURVIVOR', 0.6), ('ARE YOU THE ONE?', 0.5), ('INK MASTER', 0.4), ('QUEEN OF THE UNIVERSE', 0.4), ('BAR RESCUE', 0.3)]}, 'output': {'final': ['INK MASTER', \"RUPAUL'S DRAG RACE ALL STARS\", 'ARE YOU THE ONE?', 'Paramount+', 'QUEEN OF THE UNIVERSE', 'BIG BROTHER', 'SURVIVOR', 'THE CHALLENGE', 'BAR RESCUE']}})]\n",
      "Epoch 48/100, Loss: 4, Weights: [0.20070264 0.30985565 0.48944172] min_loss_Weights: [0.19840362 0.30517768 0.4964187 ] ads: [(6, {'inputs': {'gemini_results': [('Nectar', 1), ('Sealy', 1), ('Casper', 1), ('Serta', 1), ('Stearns & Foster', 1), ('SmartLife', 1), ('King Koil', 1)], 'vi_results': [('Raymour & Flanigan', 0.99), ('Sealy Corporation', 0.99)], 'ocr_text': [('Nectar', 0.9), ('Sealy', 0.8), ('Casper', 0.7), ('Serta', 0.6), ('Stearns & Foster', 0.5), ('SmartLife', 0.4), ('King Koil', 0.3)]}, 'output': {'final': ['SmartLife', 'Casper', 'Serta', 'King Koil', 'Stearns & Foster', 'Nectar', 'Sealy']}}), (26, {'inputs': {'gemini_results': [(\"Baker's\", 1), ('Fox', 1)], 'vi_results': [('KTVU', 0.99), ('Fox Broadcasting Company', 0.99)], 'ocr_text': [('AT&T', 0.9)]}, 'output': {'final': [\"Baker's\", 'Fox']}}), (36, {'inputs': {'gemini_results': [('Paramount+', 1), (\"RUPAUL'S DRAG RACE ALL STARS\", 1), ('BIG BROTHER', 1), ('THE CHALLENGE', 1), ('SURVIVOR', 1), ('ARE YOU THE ONE?', 1), ('INK MASTER', 1), ('QUEEN OF THE UNIVERSE', 1), ('BAR RESCUE', 1)], 'vi_results': [], 'ocr_text': [('Paramount+', 0.9), (\"RUPAUL'S DRAG RACE ALL STARS\", 0.8), ('BIG BROTHER', 0.8), ('THE CHALLENGE', 0.7), ('SURVIVOR', 0.6), ('ARE YOU THE ONE?', 0.5), ('INK MASTER', 0.4), ('QUEEN OF THE UNIVERSE', 0.4), ('BAR RESCUE', 0.3)]}, 'output': {'final': ['INK MASTER', \"RUPAUL'S DRAG RACE ALL STARS\", 'ARE YOU THE ONE?', 'Paramount+', 'QUEEN OF THE UNIVERSE', 'BIG BROTHER', 'SURVIVOR', 'THE CHALLENGE', 'BAR RESCUE']}})]\n",
      "Epoch 49/100, Loss: 5, Weights: [0.19459453 0.29577107 0.5096344 ] min_loss_Weights: [0.19840362 0.30517768 0.4964187 ] ads: [(6, {'inputs': {'gemini_results': [('Nectar', 1), ('Sealy', 1), ('Casper', 1), ('Serta', 1), ('Stearns & Foster', 1), ('SmartLife', 1), ('King Koil', 1)], 'vi_results': [('Raymour & Flanigan', 0.99), ('Sealy Corporation', 0.99)], 'ocr_text': [('Nectar', 0.9), ('Sealy', 0.8), ('Casper', 0.7), ('Serta', 0.6), ('Stearns & Foster', 0.5), ('SmartLife', 0.4), ('King Koil', 0.3)]}, 'output': {'final': ['SmartLife', 'Casper', 'Serta', 'King Koil', 'Stearns & Foster', 'Nectar', 'Sealy']}}), (26, {'inputs': {'gemini_results': [(\"Baker's\", 1), ('Fox', 1)], 'vi_results': [('KTVU', 0.99), ('Fox Broadcasting Company', 0.99)], 'ocr_text': [('AT&T', 0.9)]}, 'output': {'final': [\"Baker's\", 'Fox']}}), (36, {'inputs': {'gemini_results': [('Paramount+', 1), (\"RUPAUL'S DRAG RACE ALL STARS\", 1), ('BIG BROTHER', 1), ('THE CHALLENGE', 1), ('SURVIVOR', 1), ('ARE YOU THE ONE?', 1), ('INK MASTER', 1), ('QUEEN OF THE UNIVERSE', 1), ('BAR RESCUE', 1)], 'vi_results': [], 'ocr_text': [('Paramount+', 0.9), (\"RUPAUL'S DRAG RACE ALL STARS\", 0.8), ('BIG BROTHER', 0.8), ('THE CHALLENGE', 0.7), ('SURVIVOR', 0.6), ('ARE YOU THE ONE?', 0.5), ('INK MASTER', 0.4), ('QUEEN OF THE UNIVERSE', 0.4), ('BAR RESCUE', 0.3)]}, 'output': {'final': ['INK MASTER', \"RUPAUL'S DRAG RACE ALL STARS\", 'ARE YOU THE ONE?', 'Paramount+', 'QUEEN OF THE UNIVERSE', 'BIG BROTHER', 'SURVIVOR', 'THE CHALLENGE', 'BAR RESCUE']}})]\n",
      "Epoch 50/100, Loss: 4, Weights: [0.19459453 0.30577107 0.4996344 ] min_loss_Weights: [0.19840362 0.30517768 0.4964187 ] ads: [(6, {'inputs': {'gemini_results': [('Nectar', 1), ('Sealy', 1), ('Casper', 1), ('Serta', 1), ('Stearns & Foster', 1), ('SmartLife', 1), ('King Koil', 1)], 'vi_results': [('Raymour & Flanigan', 0.99), ('Sealy Corporation', 0.99)], 'ocr_text': [('Nectar', 0.9), ('Sealy', 0.8), ('Casper', 0.7), ('Serta', 0.6), ('Stearns & Foster', 0.5), ('SmartLife', 0.4), ('King Koil', 0.3)]}, 'output': {'final': ['SmartLife', 'Casper', 'Serta', 'King Koil', 'Stearns & Foster', 'Nectar', 'Sealy']}}), (26, {'inputs': {'gemini_results': [(\"Baker's\", 1), ('Fox', 1)], 'vi_results': [('KTVU', 0.99), ('Fox Broadcasting Company', 0.99)], 'ocr_text': [('AT&T', 0.9)]}, 'output': {'final': [\"Baker's\", 'Fox']}}), (36, {'inputs': {'gemini_results': [('Paramount+', 1), (\"RUPAUL'S DRAG RACE ALL STARS\", 1), ('BIG BROTHER', 1), ('THE CHALLENGE', 1), ('SURVIVOR', 1), ('ARE YOU THE ONE?', 1), ('INK MASTER', 1), ('QUEEN OF THE UNIVERSE', 1), ('BAR RESCUE', 1)], 'vi_results': [], 'ocr_text': [('Paramount+', 0.9), (\"RUPAUL'S DRAG RACE ALL STARS\", 0.8), ('BIG BROTHER', 0.8), ('THE CHALLENGE', 0.7), ('SURVIVOR', 0.6), ('ARE YOU THE ONE?', 0.5), ('INK MASTER', 0.4), ('QUEEN OF THE UNIVERSE', 0.4), ('BAR RESCUE', 0.3)]}, 'output': {'final': ['INK MASTER', \"RUPAUL'S DRAG RACE ALL STARS\", 'ARE YOU THE ONE?', 'Paramount+', 'QUEEN OF THE UNIVERSE', 'BIG BROTHER', 'SURVIVOR', 'THE CHALLENGE', 'BAR RESCUE']}})]\n",
      "Epoch 51/100, Loss: 3, Weights: [0.20459453 0.30577107 0.4896344 ] min_loss_Weights: [0.19840362 0.30517768 0.4964187 ] ads: [(6, {'inputs': {'gemini_results': [('Nectar', 1), ('Sealy', 1), ('Casper', 1), ('Serta', 1), ('Stearns & Foster', 1), ('SmartLife', 1), ('King Koil', 1)], 'vi_results': [('Raymour & Flanigan', 0.99), ('Sealy Corporation', 0.99)], 'ocr_text': [('Nectar', 0.9), ('Sealy', 0.8), ('Casper', 0.7), ('Serta', 0.6), ('Stearns & Foster', 0.5), ('SmartLife', 0.4), ('King Koil', 0.3)]}, 'output': {'final': ['SmartLife', 'Casper', 'Serta', 'King Koil', 'Stearns & Foster', 'Nectar', 'Sealy']}}), (26, {'inputs': {'gemini_results': [(\"Baker's\", 1), ('Fox', 1)], 'vi_results': [('KTVU', 0.99), ('Fox Broadcasting Company', 0.99)], 'ocr_text': [('AT&T', 0.9)]}, 'output': {'final': [\"Baker's\", 'Fox']}}), (36, {'inputs': {'gemini_results': [('Paramount+', 1), (\"RUPAUL'S DRAG RACE ALL STARS\", 1), ('BIG BROTHER', 1), ('THE CHALLENGE', 1), ('SURVIVOR', 1), ('ARE YOU THE ONE?', 1), ('INK MASTER', 1), ('QUEEN OF THE UNIVERSE', 1), ('BAR RESCUE', 1)], 'vi_results': [], 'ocr_text': [('Paramount+', 0.9), (\"RUPAUL'S DRAG RACE ALL STARS\", 0.8), ('BIG BROTHER', 0.8), ('THE CHALLENGE', 0.7), ('SURVIVOR', 0.6), ('ARE YOU THE ONE?', 0.5), ('INK MASTER', 0.4), ('QUEEN OF THE UNIVERSE', 0.4), ('BAR RESCUE', 0.3)]}, 'output': {'final': ['INK MASTER', \"RUPAUL'S DRAG RACE ALL STARS\", 'ARE YOU THE ONE?', 'Paramount+', 'QUEEN OF THE UNIVERSE', 'BIG BROTHER', 'SURVIVOR', 'THE CHALLENGE', 'BAR RESCUE']}})]\n",
      "Epoch 52/100, Loss: 5, Weights: [0.19856584 0.29160313 0.50983102] min_loss_Weights: [0.19840362 0.30517768 0.4964187 ] ads: [(6, {'inputs': {'gemini_results': [('Nectar', 1), ('Sealy', 1), ('Casper', 1), ('Serta', 1), ('Stearns & Foster', 1), ('SmartLife', 1), ('King Koil', 1)], 'vi_results': [('Raymour & Flanigan', 0.99), ('Sealy Corporation', 0.99)], 'ocr_text': [('Nectar', 0.9), ('Sealy', 0.8), ('Casper', 0.7), ('Serta', 0.6), ('Stearns & Foster', 0.5), ('SmartLife', 0.4), ('King Koil', 0.3)]}, 'output': {'final': ['SmartLife', 'Casper', 'Serta', 'King Koil', 'Stearns & Foster', 'Nectar', 'Sealy']}}), (26, {'inputs': {'gemini_results': [(\"Baker's\", 1), ('Fox', 1)], 'vi_results': [('KTVU', 0.99), ('Fox Broadcasting Company', 0.99)], 'ocr_text': [('AT&T', 0.9)]}, 'output': {'final': [\"Baker's\", 'Fox']}}), (36, {'inputs': {'gemini_results': [('Paramount+', 1), (\"RUPAUL'S DRAG RACE ALL STARS\", 1), ('BIG BROTHER', 1), ('THE CHALLENGE', 1), ('SURVIVOR', 1), ('ARE YOU THE ONE?', 1), ('INK MASTER', 1), ('QUEEN OF THE UNIVERSE', 1), ('BAR RESCUE', 1)], 'vi_results': [], 'ocr_text': [('Paramount+', 0.9), (\"RUPAUL'S DRAG RACE ALL STARS\", 0.8), ('BIG BROTHER', 0.8), ('THE CHALLENGE', 0.7), ('SURVIVOR', 0.6), ('ARE YOU THE ONE?', 0.5), ('INK MASTER', 0.4), ('QUEEN OF THE UNIVERSE', 0.4), ('BAR RESCUE', 0.3)]}, 'output': {'final': ['INK MASTER', \"RUPAUL'S DRAG RACE ALL STARS\", 'ARE YOU THE ONE?', 'Paramount+', 'QUEEN OF THE UNIVERSE', 'BIG BROTHER', 'SURVIVOR', 'THE CHALLENGE', 'BAR RESCUE']}})]\n",
      "Epoch 53/100, Loss: 4, Weights: [0.19856584 0.30160313 0.49983102] min_loss_Weights: [0.19840362 0.30517768 0.4964187 ] ads: [(6, {'inputs': {'gemini_results': [('Nectar', 1), ('Sealy', 1), ('Casper', 1), ('Serta', 1), ('Stearns & Foster', 1), ('SmartLife', 1), ('King Koil', 1)], 'vi_results': [('Raymour & Flanigan', 0.99), ('Sealy Corporation', 0.99)], 'ocr_text': [('Nectar', 0.9), ('Sealy', 0.8), ('Casper', 0.7), ('Serta', 0.6), ('Stearns & Foster', 0.5), ('SmartLife', 0.4), ('King Koil', 0.3)]}, 'output': {'final': ['SmartLife', 'Casper', 'Serta', 'King Koil', 'Stearns & Foster', 'Nectar', 'Sealy']}}), (26, {'inputs': {'gemini_results': [(\"Baker's\", 1), ('Fox', 1)], 'vi_results': [('KTVU', 0.99), ('Fox Broadcasting Company', 0.99)], 'ocr_text': [('AT&T', 0.9)]}, 'output': {'final': [\"Baker's\", 'Fox']}}), (36, {'inputs': {'gemini_results': [('Paramount+', 1), (\"RUPAUL'S DRAG RACE ALL STARS\", 1), ('BIG BROTHER', 1), ('THE CHALLENGE', 1), ('SURVIVOR', 1), ('ARE YOU THE ONE?', 1), ('INK MASTER', 1), ('QUEEN OF THE UNIVERSE', 1), ('BAR RESCUE', 1)], 'vi_results': [], 'ocr_text': [('Paramount+', 0.9), (\"RUPAUL'S DRAG RACE ALL STARS\", 0.8), ('BIG BROTHER', 0.8), ('THE CHALLENGE', 0.7), ('SURVIVOR', 0.6), ('ARE YOU THE ONE?', 0.5), ('INK MASTER', 0.4), ('QUEEN OF THE UNIVERSE', 0.4), ('BAR RESCUE', 0.3)]}, 'output': {'final': ['INK MASTER', \"RUPAUL'S DRAG RACE ALL STARS\", 'ARE YOU THE ONE?', 'Paramount+', 'QUEEN OF THE UNIVERSE', 'BIG BROTHER', 'SURVIVOR', 'THE CHALLENGE', 'BAR RESCUE']}})]\n",
      "Epoch 54/100, Loss: 3, Weights: [0.20856584 0.30160313 0.48983102] min_loss_Weights: [0.19840362 0.30517768 0.4964187 ] ads: [(6, {'inputs': {'gemini_results': [('Nectar', 1), ('Sealy', 1), ('Casper', 1), ('Serta', 1), ('Stearns & Foster', 1), ('SmartLife', 1), ('King Koil', 1)], 'vi_results': [('Raymour & Flanigan', 0.99), ('Sealy Corporation', 0.99)], 'ocr_text': [('Nectar', 0.9), ('Sealy', 0.8), ('Casper', 0.7), ('Serta', 0.6), ('Stearns & Foster', 0.5), ('SmartLife', 0.4), ('King Koil', 0.3)]}, 'output': {'final': ['SmartLife', 'Casper', 'Serta', 'King Koil', 'Stearns & Foster', 'Nectar', 'Sealy']}}), (26, {'inputs': {'gemini_results': [(\"Baker's\", 1), ('Fox', 1)], 'vi_results': [('KTVU', 0.99), ('Fox Broadcasting Company', 0.99)], 'ocr_text': [('AT&T', 0.9)]}, 'output': {'final': [\"Baker's\", 'Fox']}}), (36, {'inputs': {'gemini_results': [('Paramount+', 1), (\"RUPAUL'S DRAG RACE ALL STARS\", 1), ('BIG BROTHER', 1), ('THE CHALLENGE', 1), ('SURVIVOR', 1), ('ARE YOU THE ONE?', 1), ('INK MASTER', 1), ('QUEEN OF THE UNIVERSE', 1), ('BAR RESCUE', 1)], 'vi_results': [], 'ocr_text': [('Paramount+', 0.9), (\"RUPAUL'S DRAG RACE ALL STARS\", 0.8), ('BIG BROTHER', 0.8), ('THE CHALLENGE', 0.7), ('SURVIVOR', 0.6), ('ARE YOU THE ONE?', 0.5), ('INK MASTER', 0.4), ('QUEEN OF THE UNIVERSE', 0.4), ('BAR RESCUE', 0.3)]}, 'output': {'final': ['INK MASTER', \"RUPAUL'S DRAG RACE ALL STARS\", 'ARE YOU THE ONE?', 'Paramount+', 'QUEEN OF THE UNIVERSE', 'BIG BROTHER', 'SURVIVOR', 'THE CHALLENGE', 'BAR RESCUE']}})]\n",
      "Epoch 55/100, Loss: 6, Weights: [0.19241413 0.29755422 0.51003166] min_loss_Weights: [0.19840362 0.30517768 0.4964187 ] ads: [(6, {'inputs': {'gemini_results': [('Nectar', 1), ('Sealy', 1), ('Casper', 1), ('Serta', 1), ('Stearns & Foster', 1), ('SmartLife', 1), ('King Koil', 1)], 'vi_results': [('Raymour & Flanigan', 0.99), ('Sealy Corporation', 0.99)], 'ocr_text': [('Nectar', 0.9), ('Sealy', 0.8), ('Casper', 0.7), ('Serta', 0.6), ('Stearns & Foster', 0.5), ('SmartLife', 0.4), ('King Koil', 0.3)]}, 'output': {'final': ['SmartLife', 'Casper', 'Serta', 'King Koil', 'Stearns & Foster', 'Nectar', 'Sealy']}}), (26, {'inputs': {'gemini_results': [(\"Baker's\", 1), ('Fox', 1)], 'vi_results': [('KTVU', 0.99), ('Fox Broadcasting Company', 0.99)], 'ocr_text': [('AT&T', 0.9)]}, 'output': {'final': [\"Baker's\", 'Fox']}}), (36, {'inputs': {'gemini_results': [('Paramount+', 1), (\"RUPAUL'S DRAG RACE ALL STARS\", 1), ('BIG BROTHER', 1), ('THE CHALLENGE', 1), ('SURVIVOR', 1), ('ARE YOU THE ONE?', 1), ('INK MASTER', 1), ('QUEEN OF THE UNIVERSE', 1), ('BAR RESCUE', 1)], 'vi_results': [], 'ocr_text': [('Paramount+', 0.9), (\"RUPAUL'S DRAG RACE ALL STARS\", 0.8), ('BIG BROTHER', 0.8), ('THE CHALLENGE', 0.7), ('SURVIVOR', 0.6), ('ARE YOU THE ONE?', 0.5), ('INK MASTER', 0.4), ('QUEEN OF THE UNIVERSE', 0.4), ('BAR RESCUE', 0.3)]}, 'output': {'final': ['INK MASTER', \"RUPAUL'S DRAG RACE ALL STARS\", 'ARE YOU THE ONE?', 'Paramount+', 'QUEEN OF THE UNIVERSE', 'BIG BROTHER', 'SURVIVOR', 'THE CHALLENGE', 'BAR RESCUE']}})]\n",
      "Epoch 56/100, Loss: 3, Weights: [0.20241413 0.29755422 0.50003166] min_loss_Weights: [0.19840362 0.30517768 0.4964187 ] ads: [(6, {'inputs': {'gemini_results': [('Nectar', 1), ('Sealy', 1), ('Casper', 1), ('Serta', 1), ('Stearns & Foster', 1), ('SmartLife', 1), ('King Koil', 1)], 'vi_results': [('Raymour & Flanigan', 0.99), ('Sealy Corporation', 0.99)], 'ocr_text': [('Nectar', 0.9), ('Sealy', 0.8), ('Casper', 0.7), ('Serta', 0.6), ('Stearns & Foster', 0.5), ('SmartLife', 0.4), ('King Koil', 0.3)]}, 'output': {'final': ['SmartLife', 'Casper', 'Serta', 'King Koil', 'Stearns & Foster', 'Nectar', 'Sealy']}}), (26, {'inputs': {'gemini_results': [(\"Baker's\", 1), ('Fox', 1)], 'vi_results': [('KTVU', 0.99), ('Fox Broadcasting Company', 0.99)], 'ocr_text': [('AT&T', 0.9)]}, 'output': {'final': [\"Baker's\", 'Fox']}}), (36, {'inputs': {'gemini_results': [('Paramount+', 1), (\"RUPAUL'S DRAG RACE ALL STARS\", 1), ('BIG BROTHER', 1), ('THE CHALLENGE', 1), ('SURVIVOR', 1), ('ARE YOU THE ONE?', 1), ('INK MASTER', 1), ('QUEEN OF THE UNIVERSE', 1), ('BAR RESCUE', 1)], 'vi_results': [], 'ocr_text': [('Paramount+', 0.9), (\"RUPAUL'S DRAG RACE ALL STARS\", 0.8), ('BIG BROTHER', 0.8), ('THE CHALLENGE', 0.7), ('SURVIVOR', 0.6), ('ARE YOU THE ONE?', 0.5), ('INK MASTER', 0.4), ('QUEEN OF THE UNIVERSE', 0.4), ('BAR RESCUE', 0.3)]}, 'output': {'final': ['INK MASTER', \"RUPAUL'S DRAG RACE ALL STARS\", 'ARE YOU THE ONE?', 'Paramount+', 'QUEEN OF THE UNIVERSE', 'BIG BROTHER', 'SURVIVOR', 'THE CHALLENGE', 'BAR RESCUE']}})]\n",
      "Epoch 57/100, Loss: 4, Weights: [0.20241413 0.30755422 0.49003166] min_loss_Weights: [0.19840362 0.30517768 0.4964187 ] ads: [(6, {'inputs': {'gemini_results': [('Nectar', 1), ('Sealy', 1), ('Casper', 1), ('Serta', 1), ('Stearns & Foster', 1), ('SmartLife', 1), ('King Koil', 1)], 'vi_results': [('Raymour & Flanigan', 0.99), ('Sealy Corporation', 0.99)], 'ocr_text': [('Nectar', 0.9), ('Sealy', 0.8), ('Casper', 0.7), ('Serta', 0.6), ('Stearns & Foster', 0.5), ('SmartLife', 0.4), ('King Koil', 0.3)]}, 'output': {'final': ['SmartLife', 'Casper', 'Serta', 'King Koil', 'Stearns & Foster', 'Nectar', 'Sealy']}}), (26, {'inputs': {'gemini_results': [(\"Baker's\", 1), ('Fox', 1)], 'vi_results': [('KTVU', 0.99), ('Fox Broadcasting Company', 0.99)], 'ocr_text': [('AT&T', 0.9)]}, 'output': {'final': [\"Baker's\", 'Fox']}}), (36, {'inputs': {'gemini_results': [('Paramount+', 1), (\"RUPAUL'S DRAG RACE ALL STARS\", 1), ('BIG BROTHER', 1), ('THE CHALLENGE', 1), ('SURVIVOR', 1), ('ARE YOU THE ONE?', 1), ('INK MASTER', 1), ('QUEEN OF THE UNIVERSE', 1), ('BAR RESCUE', 1)], 'vi_results': [], 'ocr_text': [('Paramount+', 0.9), (\"RUPAUL'S DRAG RACE ALL STARS\", 0.8), ('BIG BROTHER', 0.8), ('THE CHALLENGE', 0.7), ('SURVIVOR', 0.6), ('ARE YOU THE ONE?', 0.5), ('INK MASTER', 0.4), ('QUEEN OF THE UNIVERSE', 0.4), ('BAR RESCUE', 0.3)]}, 'output': {'final': ['INK MASTER', \"RUPAUL'S DRAG RACE ALL STARS\", 'ARE YOU THE ONE?', 'Paramount+', 'QUEEN OF THE UNIVERSE', 'BIG BROTHER', 'SURVIVOR', 'THE CHALLENGE', 'BAR RESCUE']}})]\n",
      "Epoch 58/100, Loss: 5, Weights: [0.19634094 0.29342267 0.51023638] min_loss_Weights: [0.19840362 0.30517768 0.4964187 ] ads: [(6, {'inputs': {'gemini_results': [('Nectar', 1), ('Sealy', 1), ('Casper', 1), ('Serta', 1), ('Stearns & Foster', 1), ('SmartLife', 1), ('King Koil', 1)], 'vi_results': [('Raymour & Flanigan', 0.99), ('Sealy Corporation', 0.99)], 'ocr_text': [('Nectar', 0.9), ('Sealy', 0.8), ('Casper', 0.7), ('Serta', 0.6), ('Stearns & Foster', 0.5), ('SmartLife', 0.4), ('King Koil', 0.3)]}, 'output': {'final': ['SmartLife', 'Casper', 'Serta', 'King Koil', 'Stearns & Foster', 'Nectar', 'Sealy']}}), (26, {'inputs': {'gemini_results': [(\"Baker's\", 1), ('Fox', 1)], 'vi_results': [('KTVU', 0.99), ('Fox Broadcasting Company', 0.99)], 'ocr_text': [('AT&T', 0.9)]}, 'output': {'final': [\"Baker's\", 'Fox']}}), (36, {'inputs': {'gemini_results': [('Paramount+', 1), (\"RUPAUL'S DRAG RACE ALL STARS\", 1), ('BIG BROTHER', 1), ('THE CHALLENGE', 1), ('SURVIVOR', 1), ('ARE YOU THE ONE?', 1), ('INK MASTER', 1), ('QUEEN OF THE UNIVERSE', 1), ('BAR RESCUE', 1)], 'vi_results': [], 'ocr_text': [('Paramount+', 0.9), (\"RUPAUL'S DRAG RACE ALL STARS\", 0.8), ('BIG BROTHER', 0.8), ('THE CHALLENGE', 0.7), ('SURVIVOR', 0.6), ('ARE YOU THE ONE?', 0.5), ('INK MASTER', 0.4), ('QUEEN OF THE UNIVERSE', 0.4), ('BAR RESCUE', 0.3)]}, 'output': {'final': ['INK MASTER', \"RUPAUL'S DRAG RACE ALL STARS\", 'ARE YOU THE ONE?', 'Paramount+', 'QUEEN OF THE UNIVERSE', 'BIG BROTHER', 'SURVIVOR', 'THE CHALLENGE', 'BAR RESCUE']}})]\n",
      "Epoch 59/100, Loss: 4, Weights: [0.19634094 0.30342267 0.50023638] min_loss_Weights: [0.19840362 0.30517768 0.4964187 ] ads: [(6, {'inputs': {'gemini_results': [('Nectar', 1), ('Sealy', 1), ('Casper', 1), ('Serta', 1), ('Stearns & Foster', 1), ('SmartLife', 1), ('King Koil', 1)], 'vi_results': [('Raymour & Flanigan', 0.99), ('Sealy Corporation', 0.99)], 'ocr_text': [('Nectar', 0.9), ('Sealy', 0.8), ('Casper', 0.7), ('Serta', 0.6), ('Stearns & Foster', 0.5), ('SmartLife', 0.4), ('King Koil', 0.3)]}, 'output': {'final': ['SmartLife', 'Casper', 'Serta', 'King Koil', 'Stearns & Foster', 'Nectar', 'Sealy']}}), (26, {'inputs': {'gemini_results': [(\"Baker's\", 1), ('Fox', 1)], 'vi_results': [('KTVU', 0.99), ('Fox Broadcasting Company', 0.99)], 'ocr_text': [('AT&T', 0.9)]}, 'output': {'final': [\"Baker's\", 'Fox']}}), (36, {'inputs': {'gemini_results': [('Paramount+', 1), (\"RUPAUL'S DRAG RACE ALL STARS\", 1), ('BIG BROTHER', 1), ('THE CHALLENGE', 1), ('SURVIVOR', 1), ('ARE YOU THE ONE?', 1), ('INK MASTER', 1), ('QUEEN OF THE UNIVERSE', 1), ('BAR RESCUE', 1)], 'vi_results': [], 'ocr_text': [('Paramount+', 0.9), (\"RUPAUL'S DRAG RACE ALL STARS\", 0.8), ('BIG BROTHER', 0.8), ('THE CHALLENGE', 0.7), ('SURVIVOR', 0.6), ('ARE YOU THE ONE?', 0.5), ('INK MASTER', 0.4), ('QUEEN OF THE UNIVERSE', 0.4), ('BAR RESCUE', 0.3)]}, 'output': {'final': ['INK MASTER', \"RUPAUL'S DRAG RACE ALL STARS\", 'ARE YOU THE ONE?', 'Paramount+', 'QUEEN OF THE UNIVERSE', 'BIG BROTHER', 'SURVIVOR', 'THE CHALLENGE', 'BAR RESCUE']}})]\n",
      "Epoch 60/100, Loss: 3, Weights: [0.20634094 0.30342267 0.49023638] min_loss_Weights: [0.19840362 0.30517768 0.4964187 ] ads: [(6, {'inputs': {'gemini_results': [('Nectar', 1), ('Sealy', 1), ('Casper', 1), ('Serta', 1), ('Stearns & Foster', 1), ('SmartLife', 1), ('King Koil', 1)], 'vi_results': [('Raymour & Flanigan', 0.99), ('Sealy Corporation', 0.99)], 'ocr_text': [('Nectar', 0.9), ('Sealy', 0.8), ('Casper', 0.7), ('Serta', 0.6), ('Stearns & Foster', 0.5), ('SmartLife', 0.4), ('King Koil', 0.3)]}, 'output': {'final': ['SmartLife', 'Casper', 'Serta', 'King Koil', 'Stearns & Foster', 'Nectar', 'Sealy']}}), (26, {'inputs': {'gemini_results': [(\"Baker's\", 1), ('Fox', 1)], 'vi_results': [('KTVU', 0.99), ('Fox Broadcasting Company', 0.99)], 'ocr_text': [('AT&T', 0.9)]}, 'output': {'final': [\"Baker's\", 'Fox']}}), (36, {'inputs': {'gemini_results': [('Paramount+', 1), (\"RUPAUL'S DRAG RACE ALL STARS\", 1), ('BIG BROTHER', 1), ('THE CHALLENGE', 1), ('SURVIVOR', 1), ('ARE YOU THE ONE?', 1), ('INK MASTER', 1), ('QUEEN OF THE UNIVERSE', 1), ('BAR RESCUE', 1)], 'vi_results': [], 'ocr_text': [('Paramount+', 0.9), (\"RUPAUL'S DRAG RACE ALL STARS\", 0.8), ('BIG BROTHER', 0.8), ('THE CHALLENGE', 0.7), ('SURVIVOR', 0.6), ('ARE YOU THE ONE?', 0.5), ('INK MASTER', 0.4), ('QUEEN OF THE UNIVERSE', 0.4), ('BAR RESCUE', 0.3)]}, 'output': {'final': ['INK MASTER', \"RUPAUL'S DRAG RACE ALL STARS\", 'ARE YOU THE ONE?', 'Paramount+', 'QUEEN OF THE UNIVERSE', 'BIG BROTHER', 'SURVIVOR', 'THE CHALLENGE', 'BAR RESCUE']}})]\n",
      "Epoch 61/100, Loss: 6, Weights: [0.19014382 0.29941089 0.51044529] min_loss_Weights: [0.19840362 0.30517768 0.4964187 ] ads: [(6, {'inputs': {'gemini_results': [('Nectar', 1), ('Sealy', 1), ('Casper', 1), ('Serta', 1), ('Stearns & Foster', 1), ('SmartLife', 1), ('King Koil', 1)], 'vi_results': [('Raymour & Flanigan', 0.99), ('Sealy Corporation', 0.99)], 'ocr_text': [('Nectar', 0.9), ('Sealy', 0.8), ('Casper', 0.7), ('Serta', 0.6), ('Stearns & Foster', 0.5), ('SmartLife', 0.4), ('King Koil', 0.3)]}, 'output': {'final': ['SmartLife', 'Casper', 'Serta', 'King Koil', 'Stearns & Foster', 'Nectar', 'Sealy']}}), (26, {'inputs': {'gemini_results': [(\"Baker's\", 1), ('Fox', 1)], 'vi_results': [('KTVU', 0.99), ('Fox Broadcasting Company', 0.99)], 'ocr_text': [('AT&T', 0.9)]}, 'output': {'final': [\"Baker's\", 'Fox']}}), (36, {'inputs': {'gemini_results': [('Paramount+', 1), (\"RUPAUL'S DRAG RACE ALL STARS\", 1), ('BIG BROTHER', 1), ('THE CHALLENGE', 1), ('SURVIVOR', 1), ('ARE YOU THE ONE?', 1), ('INK MASTER', 1), ('QUEEN OF THE UNIVERSE', 1), ('BAR RESCUE', 1)], 'vi_results': [], 'ocr_text': [('Paramount+', 0.9), (\"RUPAUL'S DRAG RACE ALL STARS\", 0.8), ('BIG BROTHER', 0.8), ('THE CHALLENGE', 0.7), ('SURVIVOR', 0.6), ('ARE YOU THE ONE?', 0.5), ('INK MASTER', 0.4), ('QUEEN OF THE UNIVERSE', 0.4), ('BAR RESCUE', 0.3)]}, 'output': {'final': ['INK MASTER', \"RUPAUL'S DRAG RACE ALL STARS\", 'ARE YOU THE ONE?', 'Paramount+', 'QUEEN OF THE UNIVERSE', 'BIG BROTHER', 'SURVIVOR', 'THE CHALLENGE', 'BAR RESCUE']}})]\n",
      "Epoch 62/100, Loss: 3, Weights: [0.20014382 0.29941089 0.50044529] min_loss_Weights: [0.19840362 0.30517768 0.4964187 ] ads: [(6, {'inputs': {'gemini_results': [('Nectar', 1), ('Sealy', 1), ('Casper', 1), ('Serta', 1), ('Stearns & Foster', 1), ('SmartLife', 1), ('King Koil', 1)], 'vi_results': [('Raymour & Flanigan', 0.99), ('Sealy Corporation', 0.99)], 'ocr_text': [('Nectar', 0.9), ('Sealy', 0.8), ('Casper', 0.7), ('Serta', 0.6), ('Stearns & Foster', 0.5), ('SmartLife', 0.4), ('King Koil', 0.3)]}, 'output': {'final': ['SmartLife', 'Casper', 'Serta', 'King Koil', 'Stearns & Foster', 'Nectar', 'Sealy']}}), (26, {'inputs': {'gemini_results': [(\"Baker's\", 1), ('Fox', 1)], 'vi_results': [('KTVU', 0.99), ('Fox Broadcasting Company', 0.99)], 'ocr_text': [('AT&T', 0.9)]}, 'output': {'final': [\"Baker's\", 'Fox']}}), (36, {'inputs': {'gemini_results': [('Paramount+', 1), (\"RUPAUL'S DRAG RACE ALL STARS\", 1), ('BIG BROTHER', 1), ('THE CHALLENGE', 1), ('SURVIVOR', 1), ('ARE YOU THE ONE?', 1), ('INK MASTER', 1), ('QUEEN OF THE UNIVERSE', 1), ('BAR RESCUE', 1)], 'vi_results': [], 'ocr_text': [('Paramount+', 0.9), (\"RUPAUL'S DRAG RACE ALL STARS\", 0.8), ('BIG BROTHER', 0.8), ('THE CHALLENGE', 0.7), ('SURVIVOR', 0.6), ('ARE YOU THE ONE?', 0.5), ('INK MASTER', 0.4), ('QUEEN OF THE UNIVERSE', 0.4), ('BAR RESCUE', 0.3)]}, 'output': {'final': ['INK MASTER', \"RUPAUL'S DRAG RACE ALL STARS\", 'ARE YOU THE ONE?', 'Paramount+', 'QUEEN OF THE UNIVERSE', 'BIG BROTHER', 'SURVIVOR', 'THE CHALLENGE', 'BAR RESCUE']}})]\n",
      "Epoch 63/100, Loss: 4, Weights: [0.20014382 0.30941089 0.49044529] min_loss_Weights: [0.19840362 0.30517768 0.4964187 ] ads: [(6, {'inputs': {'gemini_results': [('Nectar', 1), ('Sealy', 1), ('Casper', 1), ('Serta', 1), ('Stearns & Foster', 1), ('SmartLife', 1), ('King Koil', 1)], 'vi_results': [('Raymour & Flanigan', 0.99), ('Sealy Corporation', 0.99)], 'ocr_text': [('Nectar', 0.9), ('Sealy', 0.8), ('Casper', 0.7), ('Serta', 0.6), ('Stearns & Foster', 0.5), ('SmartLife', 0.4), ('King Koil', 0.3)]}, 'output': {'final': ['SmartLife', 'Casper', 'Serta', 'King Koil', 'Stearns & Foster', 'Nectar', 'Sealy']}}), (26, {'inputs': {'gemini_results': [(\"Baker's\", 1), ('Fox', 1)], 'vi_results': [('KTVU', 0.99), ('Fox Broadcasting Company', 0.99)], 'ocr_text': [('AT&T', 0.9)]}, 'output': {'final': [\"Baker's\", 'Fox']}}), (36, {'inputs': {'gemini_results': [('Paramount+', 1), (\"RUPAUL'S DRAG RACE ALL STARS\", 1), ('BIG BROTHER', 1), ('THE CHALLENGE', 1), ('SURVIVOR', 1), ('ARE YOU THE ONE?', 1), ('INK MASTER', 1), ('QUEEN OF THE UNIVERSE', 1), ('BAR RESCUE', 1)], 'vi_results': [], 'ocr_text': [('Paramount+', 0.9), (\"RUPAUL'S DRAG RACE ALL STARS\", 0.8), ('BIG BROTHER', 0.8), ('THE CHALLENGE', 0.7), ('SURVIVOR', 0.6), ('ARE YOU THE ONE?', 0.5), ('INK MASTER', 0.4), ('QUEEN OF THE UNIVERSE', 0.4), ('BAR RESCUE', 0.3)]}, 'output': {'final': ['INK MASTER', \"RUPAUL'S DRAG RACE ALL STARS\", 'ARE YOU THE ONE?', 'Paramount+', 'QUEEN OF THE UNIVERSE', 'BIG BROTHER', 'SURVIVOR', 'THE CHALLENGE', 'BAR RESCUE']}})]\n",
      "Epoch 64/100, Loss: 5, Weights: [0.19402431 0.29531723 0.51065846] min_loss_Weights: [0.19840362 0.30517768 0.4964187 ] ads: [(6, {'inputs': {'gemini_results': [('Nectar', 1), ('Sealy', 1), ('Casper', 1), ('Serta', 1), ('Stearns & Foster', 1), ('SmartLife', 1), ('King Koil', 1)], 'vi_results': [('Raymour & Flanigan', 0.99), ('Sealy Corporation', 0.99)], 'ocr_text': [('Nectar', 0.9), ('Sealy', 0.8), ('Casper', 0.7), ('Serta', 0.6), ('Stearns & Foster', 0.5), ('SmartLife', 0.4), ('King Koil', 0.3)]}, 'output': {'final': ['SmartLife', 'Casper', 'Serta', 'King Koil', 'Stearns & Foster', 'Nectar', 'Sealy']}}), (26, {'inputs': {'gemini_results': [(\"Baker's\", 1), ('Fox', 1)], 'vi_results': [('KTVU', 0.99), ('Fox Broadcasting Company', 0.99)], 'ocr_text': [('AT&T', 0.9)]}, 'output': {'final': [\"Baker's\", 'Fox']}}), (36, {'inputs': {'gemini_results': [('Paramount+', 1), (\"RUPAUL'S DRAG RACE ALL STARS\", 1), ('BIG BROTHER', 1), ('THE CHALLENGE', 1), ('SURVIVOR', 1), ('ARE YOU THE ONE?', 1), ('INK MASTER', 1), ('QUEEN OF THE UNIVERSE', 1), ('BAR RESCUE', 1)], 'vi_results': [], 'ocr_text': [('Paramount+', 0.9), (\"RUPAUL'S DRAG RACE ALL STARS\", 0.8), ('BIG BROTHER', 0.8), ('THE CHALLENGE', 0.7), ('SURVIVOR', 0.6), ('ARE YOU THE ONE?', 0.5), ('INK MASTER', 0.4), ('QUEEN OF THE UNIVERSE', 0.4), ('BAR RESCUE', 0.3)]}, 'output': {'final': ['INK MASTER', \"RUPAUL'S DRAG RACE ALL STARS\", 'ARE YOU THE ONE?', 'Paramount+', 'QUEEN OF THE UNIVERSE', 'BIG BROTHER', 'SURVIVOR', 'THE CHALLENGE', 'BAR RESCUE']}})]\n",
      "Epoch 65/100, Loss: 4, Weights: [0.19402431 0.30531723 0.50065846] min_loss_Weights: [0.19840362 0.30517768 0.4964187 ] ads: [(6, {'inputs': {'gemini_results': [('Nectar', 1), ('Sealy', 1), ('Casper', 1), ('Serta', 1), ('Stearns & Foster', 1), ('SmartLife', 1), ('King Koil', 1)], 'vi_results': [('Raymour & Flanigan', 0.99), ('Sealy Corporation', 0.99)], 'ocr_text': [('Nectar', 0.9), ('Sealy', 0.8), ('Casper', 0.7), ('Serta', 0.6), ('Stearns & Foster', 0.5), ('SmartLife', 0.4), ('King Koil', 0.3)]}, 'output': {'final': ['SmartLife', 'Casper', 'Serta', 'King Koil', 'Stearns & Foster', 'Nectar', 'Sealy']}}), (26, {'inputs': {'gemini_results': [(\"Baker's\", 1), ('Fox', 1)], 'vi_results': [('KTVU', 0.99), ('Fox Broadcasting Company', 0.99)], 'ocr_text': [('AT&T', 0.9)]}, 'output': {'final': [\"Baker's\", 'Fox']}}), (36, {'inputs': {'gemini_results': [('Paramount+', 1), (\"RUPAUL'S DRAG RACE ALL STARS\", 1), ('BIG BROTHER', 1), ('THE CHALLENGE', 1), ('SURVIVOR', 1), ('ARE YOU THE ONE?', 1), ('INK MASTER', 1), ('QUEEN OF THE UNIVERSE', 1), ('BAR RESCUE', 1)], 'vi_results': [], 'ocr_text': [('Paramount+', 0.9), (\"RUPAUL'S DRAG RACE ALL STARS\", 0.8), ('BIG BROTHER', 0.8), ('THE CHALLENGE', 0.7), ('SURVIVOR', 0.6), ('ARE YOU THE ONE?', 0.5), ('INK MASTER', 0.4), ('QUEEN OF THE UNIVERSE', 0.4), ('BAR RESCUE', 0.3)]}, 'output': {'final': ['INK MASTER', \"RUPAUL'S DRAG RACE ALL STARS\", 'ARE YOU THE ONE?', 'Paramount+', 'QUEEN OF THE UNIVERSE', 'BIG BROTHER', 'SURVIVOR', 'THE CHALLENGE', 'BAR RESCUE']}})]\n",
      "Epoch 66/100, Loss: 3, Weights: [0.20402431 0.30531723 0.49065846] min_loss_Weights: [0.19840362 0.30517768 0.4964187 ] ads: [(6, {'inputs': {'gemini_results': [('Nectar', 1), ('Sealy', 1), ('Casper', 1), ('Serta', 1), ('Stearns & Foster', 1), ('SmartLife', 1), ('King Koil', 1)], 'vi_results': [('Raymour & Flanigan', 0.99), ('Sealy Corporation', 0.99)], 'ocr_text': [('Nectar', 0.9), ('Sealy', 0.8), ('Casper', 0.7), ('Serta', 0.6), ('Stearns & Foster', 0.5), ('SmartLife', 0.4), ('King Koil', 0.3)]}, 'output': {'final': ['SmartLife', 'Casper', 'Serta', 'King Koil', 'Stearns & Foster', 'Nectar', 'Sealy']}}), (26, {'inputs': {'gemini_results': [(\"Baker's\", 1), ('Fox', 1)], 'vi_results': [('KTVU', 0.99), ('Fox Broadcasting Company', 0.99)], 'ocr_text': [('AT&T', 0.9)]}, 'output': {'final': [\"Baker's\", 'Fox']}}), (36, {'inputs': {'gemini_results': [('Paramount+', 1), (\"RUPAUL'S DRAG RACE ALL STARS\", 1), ('BIG BROTHER', 1), ('THE CHALLENGE', 1), ('SURVIVOR', 1), ('ARE YOU THE ONE?', 1), ('INK MASTER', 1), ('QUEEN OF THE UNIVERSE', 1), ('BAR RESCUE', 1)], 'vi_results': [], 'ocr_text': [('Paramount+', 0.9), (\"RUPAUL'S DRAG RACE ALL STARS\", 0.8), ('BIG BROTHER', 0.8), ('THE CHALLENGE', 0.7), ('SURVIVOR', 0.6), ('ARE YOU THE ONE?', 0.5), ('INK MASTER', 0.4), ('QUEEN OF THE UNIVERSE', 0.4), ('BAR RESCUE', 0.3)]}, 'output': {'final': ['INK MASTER', \"RUPAUL'S DRAG RACE ALL STARS\", 'ARE YOU THE ONE?', 'Paramount+', 'QUEEN OF THE UNIVERSE', 'BIG BROTHER', 'SURVIVOR', 'THE CHALLENGE', 'BAR RESCUE']}})]\n",
      "Epoch 67/100, Loss: 5, Weights: [0.19798399 0.29114003 0.51087598] min_loss_Weights: [0.19840362 0.30517768 0.4964187 ] ads: [(6, {'inputs': {'gemini_results': [('Nectar', 1), ('Sealy', 1), ('Casper', 1), ('Serta', 1), ('Stearns & Foster', 1), ('SmartLife', 1), ('King Koil', 1)], 'vi_results': [('Raymour & Flanigan', 0.99), ('Sealy Corporation', 0.99)], 'ocr_text': [('Nectar', 0.9), ('Sealy', 0.8), ('Casper', 0.7), ('Serta', 0.6), ('Stearns & Foster', 0.5), ('SmartLife', 0.4), ('King Koil', 0.3)]}, 'output': {'final': ['SmartLife', 'Casper', 'Serta', 'King Koil', 'Stearns & Foster', 'Nectar', 'Sealy']}}), (26, {'inputs': {'gemini_results': [(\"Baker's\", 1), ('Fox', 1)], 'vi_results': [('KTVU', 0.99), ('Fox Broadcasting Company', 0.99)], 'ocr_text': [('AT&T', 0.9)]}, 'output': {'final': [\"Baker's\", 'Fox']}}), (36, {'inputs': {'gemini_results': [('Paramount+', 1), (\"RUPAUL'S DRAG RACE ALL STARS\", 1), ('BIG BROTHER', 1), ('THE CHALLENGE', 1), ('SURVIVOR', 1), ('ARE YOU THE ONE?', 1), ('INK MASTER', 1), ('QUEEN OF THE UNIVERSE', 1), ('BAR RESCUE', 1)], 'vi_results': [], 'ocr_text': [('Paramount+', 0.9), (\"RUPAUL'S DRAG RACE ALL STARS\", 0.8), ('BIG BROTHER', 0.8), ('THE CHALLENGE', 0.7), ('SURVIVOR', 0.6), ('ARE YOU THE ONE?', 0.5), ('INK MASTER', 0.4), ('QUEEN OF THE UNIVERSE', 0.4), ('BAR RESCUE', 0.3)]}, 'output': {'final': ['INK MASTER', \"RUPAUL'S DRAG RACE ALL STARS\", 'ARE YOU THE ONE?', 'Paramount+', 'QUEEN OF THE UNIVERSE', 'BIG BROTHER', 'SURVIVOR', 'THE CHALLENGE', 'BAR RESCUE']}})]\n",
      "Epoch 68/100, Loss: 4, Weights: [0.19798399 0.30114003 0.50087598] min_loss_Weights: [0.19840362 0.30517768 0.4964187 ] ads: [(6, {'inputs': {'gemini_results': [('Nectar', 1), ('Sealy', 1), ('Casper', 1), ('Serta', 1), ('Stearns & Foster', 1), ('SmartLife', 1), ('King Koil', 1)], 'vi_results': [('Raymour & Flanigan', 0.99), ('Sealy Corporation', 0.99)], 'ocr_text': [('Nectar', 0.9), ('Sealy', 0.8), ('Casper', 0.7), ('Serta', 0.6), ('Stearns & Foster', 0.5), ('SmartLife', 0.4), ('King Koil', 0.3)]}, 'output': {'final': ['SmartLife', 'Casper', 'Serta', 'King Koil', 'Stearns & Foster', 'Nectar', 'Sealy']}}), (26, {'inputs': {'gemini_results': [(\"Baker's\", 1), ('Fox', 1)], 'vi_results': [('KTVU', 0.99), ('Fox Broadcasting Company', 0.99)], 'ocr_text': [('AT&T', 0.9)]}, 'output': {'final': [\"Baker's\", 'Fox']}}), (36, {'inputs': {'gemini_results': [('Paramount+', 1), (\"RUPAUL'S DRAG RACE ALL STARS\", 1), ('BIG BROTHER', 1), ('THE CHALLENGE', 1), ('SURVIVOR', 1), ('ARE YOU THE ONE?', 1), ('INK MASTER', 1), ('QUEEN OF THE UNIVERSE', 1), ('BAR RESCUE', 1)], 'vi_results': [], 'ocr_text': [('Paramount+', 0.9), (\"RUPAUL'S DRAG RACE ALL STARS\", 0.8), ('BIG BROTHER', 0.8), ('THE CHALLENGE', 0.7), ('SURVIVOR', 0.6), ('ARE YOU THE ONE?', 0.5), ('INK MASTER', 0.4), ('QUEEN OF THE UNIVERSE', 0.4), ('BAR RESCUE', 0.3)]}, 'output': {'final': ['INK MASTER', \"RUPAUL'S DRAG RACE ALL STARS\", 'ARE YOU THE ONE?', 'Paramount+', 'QUEEN OF THE UNIVERSE', 'BIG BROTHER', 'SURVIVOR', 'THE CHALLENGE', 'BAR RESCUE']}})]\n",
      "Epoch 69/100, Loss: 4, Weights: [0.19798399 0.31114003 0.49087598] min_loss_Weights: [0.19840362 0.30517768 0.4964187 ] ads: [(6, {'inputs': {'gemini_results': [('Nectar', 1), ('Sealy', 1), ('Casper', 1), ('Serta', 1), ('Stearns & Foster', 1), ('SmartLife', 1), ('King Koil', 1)], 'vi_results': [('Raymour & Flanigan', 0.99), ('Sealy Corporation', 0.99)], 'ocr_text': [('Nectar', 0.9), ('Sealy', 0.8), ('Casper', 0.7), ('Serta', 0.6), ('Stearns & Foster', 0.5), ('SmartLife', 0.4), ('King Koil', 0.3)]}, 'output': {'final': ['SmartLife', 'Casper', 'Serta', 'King Koil', 'Stearns & Foster', 'Nectar', 'Sealy']}}), (26, {'inputs': {'gemini_results': [(\"Baker's\", 1), ('Fox', 1)], 'vi_results': [('KTVU', 0.99), ('Fox Broadcasting Company', 0.99)], 'ocr_text': [('AT&T', 0.9)]}, 'output': {'final': [\"Baker's\", 'Fox']}}), (36, {'inputs': {'gemini_results': [('Paramount+', 1), (\"RUPAUL'S DRAG RACE ALL STARS\", 1), ('BIG BROTHER', 1), ('THE CHALLENGE', 1), ('SURVIVOR', 1), ('ARE YOU THE ONE?', 1), ('INK MASTER', 1), ('QUEEN OF THE UNIVERSE', 1), ('BAR RESCUE', 1)], 'vi_results': [], 'ocr_text': [('Paramount+', 0.9), (\"RUPAUL'S DRAG RACE ALL STARS\", 0.8), ('BIG BROTHER', 0.8), ('THE CHALLENGE', 0.7), ('SURVIVOR', 0.6), ('ARE YOU THE ONE?', 0.5), ('INK MASTER', 0.4), ('QUEEN OF THE UNIVERSE', 0.4), ('BAR RESCUE', 0.3)]}, 'output': {'final': ['INK MASTER', \"RUPAUL'S DRAG RACE ALL STARS\", 'ARE YOU THE ONE?', 'Paramount+', 'QUEEN OF THE UNIVERSE', 'BIG BROTHER', 'SURVIVOR', 'THE CHALLENGE', 'BAR RESCUE']}})]\n",
      "Epoch 70/100, Loss: 5, Weights: [0.19182039 0.29708167 0.51109794] min_loss_Weights: [0.19840362 0.30517768 0.4964187 ] ads: [(6, {'inputs': {'gemini_results': [('Nectar', 1), ('Sealy', 1), ('Casper', 1), ('Serta', 1), ('Stearns & Foster', 1), ('SmartLife', 1), ('King Koil', 1)], 'vi_results': [('Raymour & Flanigan', 0.99), ('Sealy Corporation', 0.99)], 'ocr_text': [('Nectar', 0.9), ('Sealy', 0.8), ('Casper', 0.7), ('Serta', 0.6), ('Stearns & Foster', 0.5), ('SmartLife', 0.4), ('King Koil', 0.3)]}, 'output': {'final': ['SmartLife', 'Casper', 'Serta', 'King Koil', 'Stearns & Foster', 'Nectar', 'Sealy']}}), (26, {'inputs': {'gemini_results': [(\"Baker's\", 1), ('Fox', 1)], 'vi_results': [('KTVU', 0.99), ('Fox Broadcasting Company', 0.99)], 'ocr_text': [('AT&T', 0.9)]}, 'output': {'final': [\"Baker's\", 'Fox']}}), (36, {'inputs': {'gemini_results': [('Paramount+', 1), (\"RUPAUL'S DRAG RACE ALL STARS\", 1), ('BIG BROTHER', 1), ('THE CHALLENGE', 1), ('SURVIVOR', 1), ('ARE YOU THE ONE?', 1), ('INK MASTER', 1), ('QUEEN OF THE UNIVERSE', 1), ('BAR RESCUE', 1)], 'vi_results': [], 'ocr_text': [('Paramount+', 0.9), (\"RUPAUL'S DRAG RACE ALL STARS\", 0.8), ('BIG BROTHER', 0.8), ('THE CHALLENGE', 0.7), ('SURVIVOR', 0.6), ('ARE YOU THE ONE?', 0.5), ('INK MASTER', 0.4), ('QUEEN OF THE UNIVERSE', 0.4), ('BAR RESCUE', 0.3)]}, 'output': {'final': ['INK MASTER', \"RUPAUL'S DRAG RACE ALL STARS\", 'ARE YOU THE ONE?', 'Paramount+', 'QUEEN OF THE UNIVERSE', 'BIG BROTHER', 'SURVIVOR', 'THE CHALLENGE', 'BAR RESCUE']}})]\n",
      "Epoch 71/100, Loss: 3, Weights: [0.20182039 0.29708167 0.50109794] min_loss_Weights: [0.19840362 0.30517768 0.4964187 ] ads: [(6, {'inputs': {'gemini_results': [('Nectar', 1), ('Sealy', 1), ('Casper', 1), ('Serta', 1), ('Stearns & Foster', 1), ('SmartLife', 1), ('King Koil', 1)], 'vi_results': [('Raymour & Flanigan', 0.99), ('Sealy Corporation', 0.99)], 'ocr_text': [('Nectar', 0.9), ('Sealy', 0.8), ('Casper', 0.7), ('Serta', 0.6), ('Stearns & Foster', 0.5), ('SmartLife', 0.4), ('King Koil', 0.3)]}, 'output': {'final': ['SmartLife', 'Casper', 'Serta', 'King Koil', 'Stearns & Foster', 'Nectar', 'Sealy']}}), (26, {'inputs': {'gemini_results': [(\"Baker's\", 1), ('Fox', 1)], 'vi_results': [('KTVU', 0.99), ('Fox Broadcasting Company', 0.99)], 'ocr_text': [('AT&T', 0.9)]}, 'output': {'final': [\"Baker's\", 'Fox']}}), (36, {'inputs': {'gemini_results': [('Paramount+', 1), (\"RUPAUL'S DRAG RACE ALL STARS\", 1), ('BIG BROTHER', 1), ('THE CHALLENGE', 1), ('SURVIVOR', 1), ('ARE YOU THE ONE?', 1), ('INK MASTER', 1), ('QUEEN OF THE UNIVERSE', 1), ('BAR RESCUE', 1)], 'vi_results': [], 'ocr_text': [('Paramount+', 0.9), (\"RUPAUL'S DRAG RACE ALL STARS\", 0.8), ('BIG BROTHER', 0.8), ('THE CHALLENGE', 0.7), ('SURVIVOR', 0.6), ('ARE YOU THE ONE?', 0.5), ('INK MASTER', 0.4), ('QUEEN OF THE UNIVERSE', 0.4), ('BAR RESCUE', 0.3)]}, 'output': {'final': ['INK MASTER', \"RUPAUL'S DRAG RACE ALL STARS\", 'ARE YOU THE ONE?', 'Paramount+', 'QUEEN OF THE UNIVERSE', 'BIG BROTHER', 'SURVIVOR', 'THE CHALLENGE', 'BAR RESCUE']}})]\n",
      "Epoch 72/100, Loss: 4, Weights: [0.20182039 0.30708167 0.49109794] min_loss_Weights: [0.19840362 0.30517768 0.4964187 ] ads: [(6, {'inputs': {'gemini_results': [('Nectar', 1), ('Sealy', 1), ('Casper', 1), ('Serta', 1), ('Stearns & Foster', 1), ('SmartLife', 1), ('King Koil', 1)], 'vi_results': [('Raymour & Flanigan', 0.99), ('Sealy Corporation', 0.99)], 'ocr_text': [('Nectar', 0.9), ('Sealy', 0.8), ('Casper', 0.7), ('Serta', 0.6), ('Stearns & Foster', 0.5), ('SmartLife', 0.4), ('King Koil', 0.3)]}, 'output': {'final': ['SmartLife', 'Casper', 'Serta', 'King Koil', 'Stearns & Foster', 'Nectar', 'Sealy']}}), (26, {'inputs': {'gemini_results': [(\"Baker's\", 1), ('Fox', 1)], 'vi_results': [('KTVU', 0.99), ('Fox Broadcasting Company', 0.99)], 'ocr_text': [('AT&T', 0.9)]}, 'output': {'final': [\"Baker's\", 'Fox']}}), (36, {'inputs': {'gemini_results': [('Paramount+', 1), (\"RUPAUL'S DRAG RACE ALL STARS\", 1), ('BIG BROTHER', 1), ('THE CHALLENGE', 1), ('SURVIVOR', 1), ('ARE YOU THE ONE?', 1), ('INK MASTER', 1), ('QUEEN OF THE UNIVERSE', 1), ('BAR RESCUE', 1)], 'vi_results': [], 'ocr_text': [('Paramount+', 0.9), (\"RUPAUL'S DRAG RACE ALL STARS\", 0.8), ('BIG BROTHER', 0.8), ('THE CHALLENGE', 0.7), ('SURVIVOR', 0.6), ('ARE YOU THE ONE?', 0.5), ('INK MASTER', 0.4), ('QUEEN OF THE UNIVERSE', 0.4), ('BAR RESCUE', 0.3)]}, 'output': {'final': ['INK MASTER', \"RUPAUL'S DRAG RACE ALL STARS\", 'ARE YOU THE ONE?', 'Paramount+', 'QUEEN OF THE UNIVERSE', 'BIG BROTHER', 'SURVIVOR', 'THE CHALLENGE', 'BAR RESCUE']}})]\n",
      "Epoch 73/100, Loss: 5, Weights: [0.1957351  0.29294048 0.51132443] min_loss_Weights: [0.19840362 0.30517768 0.4964187 ] ads: [(6, {'inputs': {'gemini_results': [('Nectar', 1), ('Sealy', 1), ('Casper', 1), ('Serta', 1), ('Stearns & Foster', 1), ('SmartLife', 1), ('King Koil', 1)], 'vi_results': [('Raymour & Flanigan', 0.99), ('Sealy Corporation', 0.99)], 'ocr_text': [('Nectar', 0.9), ('Sealy', 0.8), ('Casper', 0.7), ('Serta', 0.6), ('Stearns & Foster', 0.5), ('SmartLife', 0.4), ('King Koil', 0.3)]}, 'output': {'final': ['SmartLife', 'Casper', 'Serta', 'King Koil', 'Stearns & Foster', 'Nectar', 'Sealy']}}), (26, {'inputs': {'gemini_results': [(\"Baker's\", 1), ('Fox', 1)], 'vi_results': [('KTVU', 0.99), ('Fox Broadcasting Company', 0.99)], 'ocr_text': [('AT&T', 0.9)]}, 'output': {'final': [\"Baker's\", 'Fox']}}), (36, {'inputs': {'gemini_results': [('Paramount+', 1), (\"RUPAUL'S DRAG RACE ALL STARS\", 1), ('BIG BROTHER', 1), ('THE CHALLENGE', 1), ('SURVIVOR', 1), ('ARE YOU THE ONE?', 1), ('INK MASTER', 1), ('QUEEN OF THE UNIVERSE', 1), ('BAR RESCUE', 1)], 'vi_results': [], 'ocr_text': [('Paramount+', 0.9), (\"RUPAUL'S DRAG RACE ALL STARS\", 0.8), ('BIG BROTHER', 0.8), ('THE CHALLENGE', 0.7), ('SURVIVOR', 0.6), ('ARE YOU THE ONE?', 0.5), ('INK MASTER', 0.4), ('QUEEN OF THE UNIVERSE', 0.4), ('BAR RESCUE', 0.3)]}, 'output': {'final': ['INK MASTER', \"RUPAUL'S DRAG RACE ALL STARS\", 'ARE YOU THE ONE?', 'Paramount+', 'QUEEN OF THE UNIVERSE', 'BIG BROTHER', 'SURVIVOR', 'THE CHALLENGE', 'BAR RESCUE']}})]\n",
      "Epoch 74/100, Loss: 4, Weights: [0.1957351  0.30294048 0.50132443] min_loss_Weights: [0.19840362 0.30517768 0.4964187 ] ads: [(6, {'inputs': {'gemini_results': [('Nectar', 1), ('Sealy', 1), ('Casper', 1), ('Serta', 1), ('Stearns & Foster', 1), ('SmartLife', 1), ('King Koil', 1)], 'vi_results': [('Raymour & Flanigan', 0.99), ('Sealy Corporation', 0.99)], 'ocr_text': [('Nectar', 0.9), ('Sealy', 0.8), ('Casper', 0.7), ('Serta', 0.6), ('Stearns & Foster', 0.5), ('SmartLife', 0.4), ('King Koil', 0.3)]}, 'output': {'final': ['SmartLife', 'Casper', 'Serta', 'King Koil', 'Stearns & Foster', 'Nectar', 'Sealy']}}), (26, {'inputs': {'gemini_results': [(\"Baker's\", 1), ('Fox', 1)], 'vi_results': [('KTVU', 0.99), ('Fox Broadcasting Company', 0.99)], 'ocr_text': [('AT&T', 0.9)]}, 'output': {'final': [\"Baker's\", 'Fox']}}), (36, {'inputs': {'gemini_results': [('Paramount+', 1), (\"RUPAUL'S DRAG RACE ALL STARS\", 1), ('BIG BROTHER', 1), ('THE CHALLENGE', 1), ('SURVIVOR', 1), ('ARE YOU THE ONE?', 1), ('INK MASTER', 1), ('QUEEN OF THE UNIVERSE', 1), ('BAR RESCUE', 1)], 'vi_results': [], 'ocr_text': [('Paramount+', 0.9), (\"RUPAUL'S DRAG RACE ALL STARS\", 0.8), ('BIG BROTHER', 0.8), ('THE CHALLENGE', 0.7), ('SURVIVOR', 0.6), ('ARE YOU THE ONE?', 0.5), ('INK MASTER', 0.4), ('QUEEN OF THE UNIVERSE', 0.4), ('BAR RESCUE', 0.3)]}, 'output': {'final': ['INK MASTER', \"RUPAUL'S DRAG RACE ALL STARS\", 'ARE YOU THE ONE?', 'Paramount+', 'QUEEN OF THE UNIVERSE', 'BIG BROTHER', 'SURVIVOR', 'THE CHALLENGE', 'BAR RESCUE']}})]\n",
      "Epoch 75/100, Loss: 3, Weights: [0.2057351  0.30294048 0.49132443] min_loss_Weights: [0.19840362 0.30517768 0.4964187 ] ads: [(6, {'inputs': {'gemini_results': [('Nectar', 1), ('Sealy', 1), ('Casper', 1), ('Serta', 1), ('Stearns & Foster', 1), ('SmartLife', 1), ('King Koil', 1)], 'vi_results': [('Raymour & Flanigan', 0.99), ('Sealy Corporation', 0.99)], 'ocr_text': [('Nectar', 0.9), ('Sealy', 0.8), ('Casper', 0.7), ('Serta', 0.6), ('Stearns & Foster', 0.5), ('SmartLife', 0.4), ('King Koil', 0.3)]}, 'output': {'final': ['SmartLife', 'Casper', 'Serta', 'King Koil', 'Stearns & Foster', 'Nectar', 'Sealy']}}), (26, {'inputs': {'gemini_results': [(\"Baker's\", 1), ('Fox', 1)], 'vi_results': [('KTVU', 0.99), ('Fox Broadcasting Company', 0.99)], 'ocr_text': [('AT&T', 0.9)]}, 'output': {'final': [\"Baker's\", 'Fox']}}), (36, {'inputs': {'gemini_results': [('Paramount+', 1), (\"RUPAUL'S DRAG RACE ALL STARS\", 1), ('BIG BROTHER', 1), ('THE CHALLENGE', 1), ('SURVIVOR', 1), ('ARE YOU THE ONE?', 1), ('INK MASTER', 1), ('QUEEN OF THE UNIVERSE', 1), ('BAR RESCUE', 1)], 'vi_results': [], 'ocr_text': [('Paramount+', 0.9), (\"RUPAUL'S DRAG RACE ALL STARS\", 0.8), ('BIG BROTHER', 0.8), ('THE CHALLENGE', 0.7), ('SURVIVOR', 0.6), ('ARE YOU THE ONE?', 0.5), ('INK MASTER', 0.4), ('QUEEN OF THE UNIVERSE', 0.4), ('BAR RESCUE', 0.3)]}, 'output': {'final': ['INK MASTER', \"RUPAUL'S DRAG RACE ALL STARS\", 'ARE YOU THE ONE?', 'Paramount+', 'QUEEN OF THE UNIVERSE', 'BIG BROTHER', 'SURVIVOR', 'THE CHALLENGE', 'BAR RESCUE']}})]\n",
      "Epoch 76/100, Loss: 6, Weights: [0.18952561 0.29891885 0.51155554] min_loss_Weights: [0.19840362 0.30517768 0.4964187 ] ads: [(6, {'inputs': {'gemini_results': [('Nectar', 1), ('Sealy', 1), ('Casper', 1), ('Serta', 1), ('Stearns & Foster', 1), ('SmartLife', 1), ('King Koil', 1)], 'vi_results': [('Raymour & Flanigan', 0.99), ('Sealy Corporation', 0.99)], 'ocr_text': [('Nectar', 0.9), ('Sealy', 0.8), ('Casper', 0.7), ('Serta', 0.6), ('Stearns & Foster', 0.5), ('SmartLife', 0.4), ('King Koil', 0.3)]}, 'output': {'final': ['SmartLife', 'Casper', 'Serta', 'King Koil', 'Stearns & Foster', 'Nectar', 'Sealy']}}), (26, {'inputs': {'gemini_results': [(\"Baker's\", 1), ('Fox', 1)], 'vi_results': [('KTVU', 0.99), ('Fox Broadcasting Company', 0.99)], 'ocr_text': [('AT&T', 0.9)]}, 'output': {'final': [\"Baker's\", 'Fox']}}), (36, {'inputs': {'gemini_results': [('Paramount+', 1), (\"RUPAUL'S DRAG RACE ALL STARS\", 1), ('BIG BROTHER', 1), ('THE CHALLENGE', 1), ('SURVIVOR', 1), ('ARE YOU THE ONE?', 1), ('INK MASTER', 1), ('QUEEN OF THE UNIVERSE', 1), ('BAR RESCUE', 1)], 'vi_results': [], 'ocr_text': [('Paramount+', 0.9), (\"RUPAUL'S DRAG RACE ALL STARS\", 0.8), ('BIG BROTHER', 0.8), ('THE CHALLENGE', 0.7), ('SURVIVOR', 0.6), ('ARE YOU THE ONE?', 0.5), ('INK MASTER', 0.4), ('QUEEN OF THE UNIVERSE', 0.4), ('BAR RESCUE', 0.3)]}, 'output': {'final': ['INK MASTER', \"RUPAUL'S DRAG RACE ALL STARS\", 'ARE YOU THE ONE?', 'Paramount+', 'QUEEN OF THE UNIVERSE', 'BIG BROTHER', 'SURVIVOR', 'THE CHALLENGE', 'BAR RESCUE']}})]\n",
      "Epoch 77/100, Loss: 3, Weights: [0.19952561 0.29891885 0.50155554] min_loss_Weights: [0.19840362 0.30517768 0.4964187 ] ads: [(6, {'inputs': {'gemini_results': [('Nectar', 1), ('Sealy', 1), ('Casper', 1), ('Serta', 1), ('Stearns & Foster', 1), ('SmartLife', 1), ('King Koil', 1)], 'vi_results': [('Raymour & Flanigan', 0.99), ('Sealy Corporation', 0.99)], 'ocr_text': [('Nectar', 0.9), ('Sealy', 0.8), ('Casper', 0.7), ('Serta', 0.6), ('Stearns & Foster', 0.5), ('SmartLife', 0.4), ('King Koil', 0.3)]}, 'output': {'final': ['SmartLife', 'Casper', 'Serta', 'King Koil', 'Stearns & Foster', 'Nectar', 'Sealy']}}), (26, {'inputs': {'gemini_results': [(\"Baker's\", 1), ('Fox', 1)], 'vi_results': [('KTVU', 0.99), ('Fox Broadcasting Company', 0.99)], 'ocr_text': [('AT&T', 0.9)]}, 'output': {'final': [\"Baker's\", 'Fox']}}), (36, {'inputs': {'gemini_results': [('Paramount+', 1), (\"RUPAUL'S DRAG RACE ALL STARS\", 1), ('BIG BROTHER', 1), ('THE CHALLENGE', 1), ('SURVIVOR', 1), ('ARE YOU THE ONE?', 1), ('INK MASTER', 1), ('QUEEN OF THE UNIVERSE', 1), ('BAR RESCUE', 1)], 'vi_results': [], 'ocr_text': [('Paramount+', 0.9), (\"RUPAUL'S DRAG RACE ALL STARS\", 0.8), ('BIG BROTHER', 0.8), ('THE CHALLENGE', 0.7), ('SURVIVOR', 0.6), ('ARE YOU THE ONE?', 0.5), ('INK MASTER', 0.4), ('QUEEN OF THE UNIVERSE', 0.4), ('BAR RESCUE', 0.3)]}, 'output': {'final': ['INK MASTER', \"RUPAUL'S DRAG RACE ALL STARS\", 'ARE YOU THE ONE?', 'Paramount+', 'QUEEN OF THE UNIVERSE', 'BIG BROTHER', 'SURVIVOR', 'THE CHALLENGE', 'BAR RESCUE']}})]\n",
      "Epoch 78/100, Loss: 4, Weights: [0.19952561 0.30891885 0.49155554] min_loss_Weights: [0.19840362 0.30517768 0.4964187 ] ads: [(6, {'inputs': {'gemini_results': [('Nectar', 1), ('Sealy', 1), ('Casper', 1), ('Serta', 1), ('Stearns & Foster', 1), ('SmartLife', 1), ('King Koil', 1)], 'vi_results': [('Raymour & Flanigan', 0.99), ('Sealy Corporation', 0.99)], 'ocr_text': [('Nectar', 0.9), ('Sealy', 0.8), ('Casper', 0.7), ('Serta', 0.6), ('Stearns & Foster', 0.5), ('SmartLife', 0.4), ('King Koil', 0.3)]}, 'output': {'final': ['SmartLife', 'Casper', 'Serta', 'King Koil', 'Stearns & Foster', 'Nectar', 'Sealy']}}), (26, {'inputs': {'gemini_results': [(\"Baker's\", 1), ('Fox', 1)], 'vi_results': [('KTVU', 0.99), ('Fox Broadcasting Company', 0.99)], 'ocr_text': [('AT&T', 0.9)]}, 'output': {'final': [\"Baker's\", 'Fox']}}), (36, {'inputs': {'gemini_results': [('Paramount+', 1), (\"RUPAUL'S DRAG RACE ALL STARS\", 1), ('BIG BROTHER', 1), ('THE CHALLENGE', 1), ('SURVIVOR', 1), ('ARE YOU THE ONE?', 1), ('INK MASTER', 1), ('QUEEN OF THE UNIVERSE', 1), ('BAR RESCUE', 1)], 'vi_results': [], 'ocr_text': [('Paramount+', 0.9), (\"RUPAUL'S DRAG RACE ALL STARS\", 0.8), ('BIG BROTHER', 0.8), ('THE CHALLENGE', 0.7), ('SURVIVOR', 0.6), ('ARE YOU THE ONE?', 0.5), ('INK MASTER', 0.4), ('QUEEN OF THE UNIVERSE', 0.4), ('BAR RESCUE', 0.3)]}, 'output': {'final': ['INK MASTER', \"RUPAUL'S DRAG RACE ALL STARS\", 'ARE YOU THE ONE?', 'Paramount+', 'QUEEN OF THE UNIVERSE', 'BIG BROTHER', 'SURVIVOR', 'THE CHALLENGE', 'BAR RESCUE']}})]\n",
      "Epoch 79/100, Loss: 5, Weights: [0.19339348 0.29481516 0.51179136] min_loss_Weights: [0.19840362 0.30517768 0.4964187 ] ads: [(6, {'inputs': {'gemini_results': [('Nectar', 1), ('Sealy', 1), ('Casper', 1), ('Serta', 1), ('Stearns & Foster', 1), ('SmartLife', 1), ('King Koil', 1)], 'vi_results': [('Raymour & Flanigan', 0.99), ('Sealy Corporation', 0.99)], 'ocr_text': [('Nectar', 0.9), ('Sealy', 0.8), ('Casper', 0.7), ('Serta', 0.6), ('Stearns & Foster', 0.5), ('SmartLife', 0.4), ('King Koil', 0.3)]}, 'output': {'final': ['SmartLife', 'Casper', 'Serta', 'King Koil', 'Stearns & Foster', 'Nectar', 'Sealy']}}), (26, {'inputs': {'gemini_results': [(\"Baker's\", 1), ('Fox', 1)], 'vi_results': [('KTVU', 0.99), ('Fox Broadcasting Company', 0.99)], 'ocr_text': [('AT&T', 0.9)]}, 'output': {'final': [\"Baker's\", 'Fox']}}), (36, {'inputs': {'gemini_results': [('Paramount+', 1), (\"RUPAUL'S DRAG RACE ALL STARS\", 1), ('BIG BROTHER', 1), ('THE CHALLENGE', 1), ('SURVIVOR', 1), ('ARE YOU THE ONE?', 1), ('INK MASTER', 1), ('QUEEN OF THE UNIVERSE', 1), ('BAR RESCUE', 1)], 'vi_results': [], 'ocr_text': [('Paramount+', 0.9), (\"RUPAUL'S DRAG RACE ALL STARS\", 0.8), ('BIG BROTHER', 0.8), ('THE CHALLENGE', 0.7), ('SURVIVOR', 0.6), ('ARE YOU THE ONE?', 0.5), ('INK MASTER', 0.4), ('QUEEN OF THE UNIVERSE', 0.4), ('BAR RESCUE', 0.3)]}, 'output': {'final': ['INK MASTER', \"RUPAUL'S DRAG RACE ALL STARS\", 'ARE YOU THE ONE?', 'Paramount+', 'QUEEN OF THE UNIVERSE', 'BIG BROTHER', 'SURVIVOR', 'THE CHALLENGE', 'BAR RESCUE']}})]\n",
      "Epoch 80/100, Loss: 4, Weights: [0.19339348 0.30481516 0.50179136] min_loss_Weights: [0.19840362 0.30517768 0.4964187 ] ads: [(6, {'inputs': {'gemini_results': [('Nectar', 1), ('Sealy', 1), ('Casper', 1), ('Serta', 1), ('Stearns & Foster', 1), ('SmartLife', 1), ('King Koil', 1)], 'vi_results': [('Raymour & Flanigan', 0.99), ('Sealy Corporation', 0.99)], 'ocr_text': [('Nectar', 0.9), ('Sealy', 0.8), ('Casper', 0.7), ('Serta', 0.6), ('Stearns & Foster', 0.5), ('SmartLife', 0.4), ('King Koil', 0.3)]}, 'output': {'final': ['SmartLife', 'Casper', 'Serta', 'King Koil', 'Stearns & Foster', 'Nectar', 'Sealy']}}), (26, {'inputs': {'gemini_results': [(\"Baker's\", 1), ('Fox', 1)], 'vi_results': [('KTVU', 0.99), ('Fox Broadcasting Company', 0.99)], 'ocr_text': [('AT&T', 0.9)]}, 'output': {'final': [\"Baker's\", 'Fox']}}), (36, {'inputs': {'gemini_results': [('Paramount+', 1), (\"RUPAUL'S DRAG RACE ALL STARS\", 1), ('BIG BROTHER', 1), ('THE CHALLENGE', 1), ('SURVIVOR', 1), ('ARE YOU THE ONE?', 1), ('INK MASTER', 1), ('QUEEN OF THE UNIVERSE', 1), ('BAR RESCUE', 1)], 'vi_results': [], 'ocr_text': [('Paramount+', 0.9), (\"RUPAUL'S DRAG RACE ALL STARS\", 0.8), ('BIG BROTHER', 0.8), ('THE CHALLENGE', 0.7), ('SURVIVOR', 0.6), ('ARE YOU THE ONE?', 0.5), ('INK MASTER', 0.4), ('QUEEN OF THE UNIVERSE', 0.4), ('BAR RESCUE', 0.3)]}, 'output': {'final': ['INK MASTER', \"RUPAUL'S DRAG RACE ALL STARS\", 'ARE YOU THE ONE?', 'Paramount+', 'QUEEN OF THE UNIVERSE', 'BIG BROTHER', 'SURVIVOR', 'THE CHALLENGE', 'BAR RESCUE']}})]\n",
      "Epoch 81/100, Loss: 3, Weights: [0.20339348 0.30481516 0.49179136] min_loss_Weights: [0.19840362 0.30517768 0.4964187 ] ads: [(6, {'inputs': {'gemini_results': [('Nectar', 1), ('Sealy', 1), ('Casper', 1), ('Serta', 1), ('Stearns & Foster', 1), ('SmartLife', 1), ('King Koil', 1)], 'vi_results': [('Raymour & Flanigan', 0.99), ('Sealy Corporation', 0.99)], 'ocr_text': [('Nectar', 0.9), ('Sealy', 0.8), ('Casper', 0.7), ('Serta', 0.6), ('Stearns & Foster', 0.5), ('SmartLife', 0.4), ('King Koil', 0.3)]}, 'output': {'final': ['SmartLife', 'Casper', 'Serta', 'King Koil', 'Stearns & Foster', 'Nectar', 'Sealy']}}), (26, {'inputs': {'gemini_results': [(\"Baker's\", 1), ('Fox', 1)], 'vi_results': [('KTVU', 0.99), ('Fox Broadcasting Company', 0.99)], 'ocr_text': [('AT&T', 0.9)]}, 'output': {'final': [\"Baker's\", 'Fox']}}), (36, {'inputs': {'gemini_results': [('Paramount+', 1), (\"RUPAUL'S DRAG RACE ALL STARS\", 1), ('BIG BROTHER', 1), ('THE CHALLENGE', 1), ('SURVIVOR', 1), ('ARE YOU THE ONE?', 1), ('INK MASTER', 1), ('QUEEN OF THE UNIVERSE', 1), ('BAR RESCUE', 1)], 'vi_results': [], 'ocr_text': [('Paramount+', 0.9), (\"RUPAUL'S DRAG RACE ALL STARS\", 0.8), ('BIG BROTHER', 0.8), ('THE CHALLENGE', 0.7), ('SURVIVOR', 0.6), ('ARE YOU THE ONE?', 0.5), ('INK MASTER', 0.4), ('QUEEN OF THE UNIVERSE', 0.4), ('BAR RESCUE', 0.3)]}, 'output': {'final': ['INK MASTER', \"RUPAUL'S DRAG RACE ALL STARS\", 'ARE YOU THE ONE?', 'Paramount+', 'QUEEN OF THE UNIVERSE', 'BIG BROTHER', 'SURVIVOR', 'THE CHALLENGE', 'BAR RESCUE']}})]\n",
      "Epoch 82/100, Loss: 5, Weights: [0.19734028 0.29062771 0.512032  ] min_loss_Weights: [0.19840362 0.30517768 0.4964187 ] ads: [(6, {'inputs': {'gemini_results': [('Nectar', 1), ('Sealy', 1), ('Casper', 1), ('Serta', 1), ('Stearns & Foster', 1), ('SmartLife', 1), ('King Koil', 1)], 'vi_results': [('Raymour & Flanigan', 0.99), ('Sealy Corporation', 0.99)], 'ocr_text': [('Nectar', 0.9), ('Sealy', 0.8), ('Casper', 0.7), ('Serta', 0.6), ('Stearns & Foster', 0.5), ('SmartLife', 0.4), ('King Koil', 0.3)]}, 'output': {'final': ['SmartLife', 'Casper', 'Serta', 'King Koil', 'Stearns & Foster', 'Nectar', 'Sealy']}}), (26, {'inputs': {'gemini_results': [(\"Baker's\", 1), ('Fox', 1)], 'vi_results': [('KTVU', 0.99), ('Fox Broadcasting Company', 0.99)], 'ocr_text': [('AT&T', 0.9)]}, 'output': {'final': [\"Baker's\", 'Fox']}}), (36, {'inputs': {'gemini_results': [('Paramount+', 1), (\"RUPAUL'S DRAG RACE ALL STARS\", 1), ('BIG BROTHER', 1), ('THE CHALLENGE', 1), ('SURVIVOR', 1), ('ARE YOU THE ONE?', 1), ('INK MASTER', 1), ('QUEEN OF THE UNIVERSE', 1), ('BAR RESCUE', 1)], 'vi_results': [], 'ocr_text': [('Paramount+', 0.9), (\"RUPAUL'S DRAG RACE ALL STARS\", 0.8), ('BIG BROTHER', 0.8), ('THE CHALLENGE', 0.7), ('SURVIVOR', 0.6), ('ARE YOU THE ONE?', 0.5), ('INK MASTER', 0.4), ('QUEEN OF THE UNIVERSE', 0.4), ('BAR RESCUE', 0.3)]}, 'output': {'final': ['INK MASTER', \"RUPAUL'S DRAG RACE ALL STARS\", 'ARE YOU THE ONE?', 'Paramount+', 'QUEEN OF THE UNIVERSE', 'BIG BROTHER', 'SURVIVOR', 'THE CHALLENGE', 'BAR RESCUE']}})]\n",
      "Epoch 83/100, Loss: 4, Weights: [0.19734028 0.30062771 0.502032  ] min_loss_Weights: [0.19840362 0.30517768 0.4964187 ] ads: [(6, {'inputs': {'gemini_results': [('Nectar', 1), ('Sealy', 1), ('Casper', 1), ('Serta', 1), ('Stearns & Foster', 1), ('SmartLife', 1), ('King Koil', 1)], 'vi_results': [('Raymour & Flanigan', 0.99), ('Sealy Corporation', 0.99)], 'ocr_text': [('Nectar', 0.9), ('Sealy', 0.8), ('Casper', 0.7), ('Serta', 0.6), ('Stearns & Foster', 0.5), ('SmartLife', 0.4), ('King Koil', 0.3)]}, 'output': {'final': ['SmartLife', 'Casper', 'Serta', 'King Koil', 'Stearns & Foster', 'Nectar', 'Sealy']}}), (26, {'inputs': {'gemini_results': [(\"Baker's\", 1), ('Fox', 1)], 'vi_results': [('KTVU', 0.99), ('Fox Broadcasting Company', 0.99)], 'ocr_text': [('AT&T', 0.9)]}, 'output': {'final': [\"Baker's\", 'Fox']}}), (36, {'inputs': {'gemini_results': [('Paramount+', 1), (\"RUPAUL'S DRAG RACE ALL STARS\", 1), ('BIG BROTHER', 1), ('THE CHALLENGE', 1), ('SURVIVOR', 1), ('ARE YOU THE ONE?', 1), ('INK MASTER', 1), ('QUEEN OF THE UNIVERSE', 1), ('BAR RESCUE', 1)], 'vi_results': [], 'ocr_text': [('Paramount+', 0.9), (\"RUPAUL'S DRAG RACE ALL STARS\", 0.8), ('BIG BROTHER', 0.8), ('THE CHALLENGE', 0.7), ('SURVIVOR', 0.6), ('ARE YOU THE ONE?', 0.5), ('INK MASTER', 0.4), ('QUEEN OF THE UNIVERSE', 0.4), ('BAR RESCUE', 0.3)]}, 'output': {'final': ['INK MASTER', \"RUPAUL'S DRAG RACE ALL STARS\", 'ARE YOU THE ONE?', 'Paramount+', 'QUEEN OF THE UNIVERSE', 'BIG BROTHER', 'SURVIVOR', 'THE CHALLENGE', 'BAR RESCUE']}})]\n",
      "Epoch 84/100, Loss: 4, Weights: [0.19734028 0.31062771 0.492032  ] min_loss_Weights: [0.19840362 0.30517768 0.4964187 ] ads: [(6, {'inputs': {'gemini_results': [('Nectar', 1), ('Sealy', 1), ('Casper', 1), ('Serta', 1), ('Stearns & Foster', 1), ('SmartLife', 1), ('King Koil', 1)], 'vi_results': [('Raymour & Flanigan', 0.99), ('Sealy Corporation', 0.99)], 'ocr_text': [('Nectar', 0.9), ('Sealy', 0.8), ('Casper', 0.7), ('Serta', 0.6), ('Stearns & Foster', 0.5), ('SmartLife', 0.4), ('King Koil', 0.3)]}, 'output': {'final': ['SmartLife', 'Casper', 'Serta', 'King Koil', 'Stearns & Foster', 'Nectar', 'Sealy']}}), (26, {'inputs': {'gemini_results': [(\"Baker's\", 1), ('Fox', 1)], 'vi_results': [('KTVU', 0.99), ('Fox Broadcasting Company', 0.99)], 'ocr_text': [('AT&T', 0.9)]}, 'output': {'final': [\"Baker's\", 'Fox']}}), (36, {'inputs': {'gemini_results': [('Paramount+', 1), (\"RUPAUL'S DRAG RACE ALL STARS\", 1), ('BIG BROTHER', 1), ('THE CHALLENGE', 1), ('SURVIVOR', 1), ('ARE YOU THE ONE?', 1), ('INK MASTER', 1), ('QUEEN OF THE UNIVERSE', 1), ('BAR RESCUE', 1)], 'vi_results': [], 'ocr_text': [('Paramount+', 0.9), (\"RUPAUL'S DRAG RACE ALL STARS\", 0.8), ('BIG BROTHER', 0.8), ('THE CHALLENGE', 0.7), ('SURVIVOR', 0.6), ('ARE YOU THE ONE?', 0.5), ('INK MASTER', 0.4), ('QUEEN OF THE UNIVERSE', 0.4), ('BAR RESCUE', 0.3)]}, 'output': {'final': ['INK MASTER', \"RUPAUL'S DRAG RACE ALL STARS\", 'ARE YOU THE ONE?', 'Paramount+', 'QUEEN OF THE UNIVERSE', 'BIG BROTHER', 'SURVIVOR', 'THE CHALLENGE', 'BAR RESCUE']}})]\n",
      "Epoch 85/100, Loss: 5, Weights: [0.19116355 0.29655889 0.51227756] min_loss_Weights: [0.19840362 0.30517768 0.4964187 ] ads: [(6, {'inputs': {'gemini_results': [('Nectar', 1), ('Sealy', 1), ('Casper', 1), ('Serta', 1), ('Stearns & Foster', 1), ('SmartLife', 1), ('King Koil', 1)], 'vi_results': [('Raymour & Flanigan', 0.99), ('Sealy Corporation', 0.99)], 'ocr_text': [('Nectar', 0.9), ('Sealy', 0.8), ('Casper', 0.7), ('Serta', 0.6), ('Stearns & Foster', 0.5), ('SmartLife', 0.4), ('King Koil', 0.3)]}, 'output': {'final': ['SmartLife', 'Casper', 'Serta', 'King Koil', 'Stearns & Foster', 'Nectar', 'Sealy']}}), (26, {'inputs': {'gemini_results': [(\"Baker's\", 1), ('Fox', 1)], 'vi_results': [('KTVU', 0.99), ('Fox Broadcasting Company', 0.99)], 'ocr_text': [('AT&T', 0.9)]}, 'output': {'final': [\"Baker's\", 'Fox']}}), (36, {'inputs': {'gemini_results': [('Paramount+', 1), (\"RUPAUL'S DRAG RACE ALL STARS\", 1), ('BIG BROTHER', 1), ('THE CHALLENGE', 1), ('SURVIVOR', 1), ('ARE YOU THE ONE?', 1), ('INK MASTER', 1), ('QUEEN OF THE UNIVERSE', 1), ('BAR RESCUE', 1)], 'vi_results': [], 'ocr_text': [('Paramount+', 0.9), (\"RUPAUL'S DRAG RACE ALL STARS\", 0.8), ('BIG BROTHER', 0.8), ('THE CHALLENGE', 0.7), ('SURVIVOR', 0.6), ('ARE YOU THE ONE?', 0.5), ('INK MASTER', 0.4), ('QUEEN OF THE UNIVERSE', 0.4), ('BAR RESCUE', 0.3)]}, 'output': {'final': ['INK MASTER', \"RUPAUL'S DRAG RACE ALL STARS\", 'ARE YOU THE ONE?', 'Paramount+', 'QUEEN OF THE UNIVERSE', 'BIG BROTHER', 'SURVIVOR', 'THE CHALLENGE', 'BAR RESCUE']}})]\n",
      "Epoch 86/100, Loss: 4, Weights: [0.19116355 0.30655889 0.50227756] min_loss_Weights: [0.19840362 0.30517768 0.4964187 ] ads: [(6, {'inputs': {'gemini_results': [('Nectar', 1), ('Sealy', 1), ('Casper', 1), ('Serta', 1), ('Stearns & Foster', 1), ('SmartLife', 1), ('King Koil', 1)], 'vi_results': [('Raymour & Flanigan', 0.99), ('Sealy Corporation', 0.99)], 'ocr_text': [('Nectar', 0.9), ('Sealy', 0.8), ('Casper', 0.7), ('Serta', 0.6), ('Stearns & Foster', 0.5), ('SmartLife', 0.4), ('King Koil', 0.3)]}, 'output': {'final': ['SmartLife', 'Casper', 'Serta', 'King Koil', 'Stearns & Foster', 'Nectar', 'Sealy']}}), (26, {'inputs': {'gemini_results': [(\"Baker's\", 1), ('Fox', 1)], 'vi_results': [('KTVU', 0.99), ('Fox Broadcasting Company', 0.99)], 'ocr_text': [('AT&T', 0.9)]}, 'output': {'final': [\"Baker's\", 'Fox']}}), (36, {'inputs': {'gemini_results': [('Paramount+', 1), (\"RUPAUL'S DRAG RACE ALL STARS\", 1), ('BIG BROTHER', 1), ('THE CHALLENGE', 1), ('SURVIVOR', 1), ('ARE YOU THE ONE?', 1), ('INK MASTER', 1), ('QUEEN OF THE UNIVERSE', 1), ('BAR RESCUE', 1)], 'vi_results': [], 'ocr_text': [('Paramount+', 0.9), (\"RUPAUL'S DRAG RACE ALL STARS\", 0.8), ('BIG BROTHER', 0.8), ('THE CHALLENGE', 0.7), ('SURVIVOR', 0.6), ('ARE YOU THE ONE?', 0.5), ('INK MASTER', 0.4), ('QUEEN OF THE UNIVERSE', 0.4), ('BAR RESCUE', 0.3)]}, 'output': {'final': ['INK MASTER', \"RUPAUL'S DRAG RACE ALL STARS\", 'ARE YOU THE ONE?', 'Paramount+', 'QUEEN OF THE UNIVERSE', 'BIG BROTHER', 'SURVIVOR', 'THE CHALLENGE', 'BAR RESCUE']}})]\n",
      "Epoch 87/100, Loss: 3, Weights: [0.20116355 0.30655889 0.49227756] min_loss_Weights: [0.19840362 0.30517768 0.4964187 ] ads: [(6, {'inputs': {'gemini_results': [('Nectar', 1), ('Sealy', 1), ('Casper', 1), ('Serta', 1), ('Stearns & Foster', 1), ('SmartLife', 1), ('King Koil', 1)], 'vi_results': [('Raymour & Flanigan', 0.99), ('Sealy Corporation', 0.99)], 'ocr_text': [('Nectar', 0.9), ('Sealy', 0.8), ('Casper', 0.7), ('Serta', 0.6), ('Stearns & Foster', 0.5), ('SmartLife', 0.4), ('King Koil', 0.3)]}, 'output': {'final': ['SmartLife', 'Casper', 'Serta', 'King Koil', 'Stearns & Foster', 'Nectar', 'Sealy']}}), (26, {'inputs': {'gemini_results': [(\"Baker's\", 1), ('Fox', 1)], 'vi_results': [('KTVU', 0.99), ('Fox Broadcasting Company', 0.99)], 'ocr_text': [('AT&T', 0.9)]}, 'output': {'final': [\"Baker's\", 'Fox']}}), (36, {'inputs': {'gemini_results': [('Paramount+', 1), (\"RUPAUL'S DRAG RACE ALL STARS\", 1), ('BIG BROTHER', 1), ('THE CHALLENGE', 1), ('SURVIVOR', 1), ('ARE YOU THE ONE?', 1), ('INK MASTER', 1), ('QUEEN OF THE UNIVERSE', 1), ('BAR RESCUE', 1)], 'vi_results': [], 'ocr_text': [('Paramount+', 0.9), (\"RUPAUL'S DRAG RACE ALL STARS\", 0.8), ('BIG BROTHER', 0.8), ('THE CHALLENGE', 0.7), ('SURVIVOR', 0.6), ('ARE YOU THE ONE?', 0.5), ('INK MASTER', 0.4), ('QUEEN OF THE UNIVERSE', 0.4), ('BAR RESCUE', 0.3)]}, 'output': {'final': ['INK MASTER', \"RUPAUL'S DRAG RACE ALL STARS\", 'ARE YOU THE ONE?', 'Paramount+', 'QUEEN OF THE UNIVERSE', 'BIG BROTHER', 'SURVIVOR', 'THE CHALLENGE', 'BAR RESCUE']}})]\n",
      "Epoch 88/100, Loss: 5, Weights: [0.19506485 0.29240703 0.51252812] min_loss_Weights: [0.19840362 0.30517768 0.4964187 ] ads: [(6, {'inputs': {'gemini_results': [('Nectar', 1), ('Sealy', 1), ('Casper', 1), ('Serta', 1), ('Stearns & Foster', 1), ('SmartLife', 1), ('King Koil', 1)], 'vi_results': [('Raymour & Flanigan', 0.99), ('Sealy Corporation', 0.99)], 'ocr_text': [('Nectar', 0.9), ('Sealy', 0.8), ('Casper', 0.7), ('Serta', 0.6), ('Stearns & Foster', 0.5), ('SmartLife', 0.4), ('King Koil', 0.3)]}, 'output': {'final': ['SmartLife', 'Casper', 'Serta', 'King Koil', 'Stearns & Foster', 'Nectar', 'Sealy']}}), (26, {'inputs': {'gemini_results': [(\"Baker's\", 1), ('Fox', 1)], 'vi_results': [('KTVU', 0.99), ('Fox Broadcasting Company', 0.99)], 'ocr_text': [('AT&T', 0.9)]}, 'output': {'final': [\"Baker's\", 'Fox']}}), (36, {'inputs': {'gemini_results': [('Paramount+', 1), (\"RUPAUL'S DRAG RACE ALL STARS\", 1), ('BIG BROTHER', 1), ('THE CHALLENGE', 1), ('SURVIVOR', 1), ('ARE YOU THE ONE?', 1), ('INK MASTER', 1), ('QUEEN OF THE UNIVERSE', 1), ('BAR RESCUE', 1)], 'vi_results': [], 'ocr_text': [('Paramount+', 0.9), (\"RUPAUL'S DRAG RACE ALL STARS\", 0.8), ('BIG BROTHER', 0.8), ('THE CHALLENGE', 0.7), ('SURVIVOR', 0.6), ('ARE YOU THE ONE?', 0.5), ('INK MASTER', 0.4), ('QUEEN OF THE UNIVERSE', 0.4), ('BAR RESCUE', 0.3)]}, 'output': {'final': ['INK MASTER', \"RUPAUL'S DRAG RACE ALL STARS\", 'ARE YOU THE ONE?', 'Paramount+', 'QUEEN OF THE UNIVERSE', 'BIG BROTHER', 'SURVIVOR', 'THE CHALLENGE', 'BAR RESCUE']}})]\n",
      "Epoch 89/100, Loss: 4, Weights: [0.19506485 0.30240703 0.50252812] min_loss_Weights: [0.19840362 0.30517768 0.4964187 ] ads: [(6, {'inputs': {'gemini_results': [('Nectar', 1), ('Sealy', 1), ('Casper', 1), ('Serta', 1), ('Stearns & Foster', 1), ('SmartLife', 1), ('King Koil', 1)], 'vi_results': [('Raymour & Flanigan', 0.99), ('Sealy Corporation', 0.99)], 'ocr_text': [('Nectar', 0.9), ('Sealy', 0.8), ('Casper', 0.7), ('Serta', 0.6), ('Stearns & Foster', 0.5), ('SmartLife', 0.4), ('King Koil', 0.3)]}, 'output': {'final': ['SmartLife', 'Casper', 'Serta', 'King Koil', 'Stearns & Foster', 'Nectar', 'Sealy']}}), (26, {'inputs': {'gemini_results': [(\"Baker's\", 1), ('Fox', 1)], 'vi_results': [('KTVU', 0.99), ('Fox Broadcasting Company', 0.99)], 'ocr_text': [('AT&T', 0.9)]}, 'output': {'final': [\"Baker's\", 'Fox']}}), (36, {'inputs': {'gemini_results': [('Paramount+', 1), (\"RUPAUL'S DRAG RACE ALL STARS\", 1), ('BIG BROTHER', 1), ('THE CHALLENGE', 1), ('SURVIVOR', 1), ('ARE YOU THE ONE?', 1), ('INK MASTER', 1), ('QUEEN OF THE UNIVERSE', 1), ('BAR RESCUE', 1)], 'vi_results': [], 'ocr_text': [('Paramount+', 0.9), (\"RUPAUL'S DRAG RACE ALL STARS\", 0.8), ('BIG BROTHER', 0.8), ('THE CHALLENGE', 0.7), ('SURVIVOR', 0.6), ('ARE YOU THE ONE?', 0.5), ('INK MASTER', 0.4), ('QUEEN OF THE UNIVERSE', 0.4), ('BAR RESCUE', 0.3)]}, 'output': {'final': ['INK MASTER', \"RUPAUL'S DRAG RACE ALL STARS\", 'ARE YOU THE ONE?', 'Paramount+', 'QUEEN OF THE UNIVERSE', 'BIG BROTHER', 'SURVIVOR', 'THE CHALLENGE', 'BAR RESCUE']}})]\n",
      "Epoch 90/100, Loss: 3, Weights: [0.20506485 0.30240703 0.49252812] min_loss_Weights: [0.19840362 0.30517768 0.4964187 ] ads: [(6, {'inputs': {'gemini_results': [('Nectar', 1), ('Sealy', 1), ('Casper', 1), ('Serta', 1), ('Stearns & Foster', 1), ('SmartLife', 1), ('King Koil', 1)], 'vi_results': [('Raymour & Flanigan', 0.99), ('Sealy Corporation', 0.99)], 'ocr_text': [('Nectar', 0.9), ('Sealy', 0.8), ('Casper', 0.7), ('Serta', 0.6), ('Stearns & Foster', 0.5), ('SmartLife', 0.4), ('King Koil', 0.3)]}, 'output': {'final': ['SmartLife', 'Casper', 'Serta', 'King Koil', 'Stearns & Foster', 'Nectar', 'Sealy']}}), (26, {'inputs': {'gemini_results': [(\"Baker's\", 1), ('Fox', 1)], 'vi_results': [('KTVU', 0.99), ('Fox Broadcasting Company', 0.99)], 'ocr_text': [('AT&T', 0.9)]}, 'output': {'final': [\"Baker's\", 'Fox']}}), (36, {'inputs': {'gemini_results': [('Paramount+', 1), (\"RUPAUL'S DRAG RACE ALL STARS\", 1), ('BIG BROTHER', 1), ('THE CHALLENGE', 1), ('SURVIVOR', 1), ('ARE YOU THE ONE?', 1), ('INK MASTER', 1), ('QUEEN OF THE UNIVERSE', 1), ('BAR RESCUE', 1)], 'vi_results': [], 'ocr_text': [('Paramount+', 0.9), (\"RUPAUL'S DRAG RACE ALL STARS\", 0.8), ('BIG BROTHER', 0.8), ('THE CHALLENGE', 0.7), ('SURVIVOR', 0.6), ('ARE YOU THE ONE?', 0.5), ('INK MASTER', 0.4), ('QUEEN OF THE UNIVERSE', 0.4), ('BAR RESCUE', 0.3)]}, 'output': {'final': ['INK MASTER', \"RUPAUL'S DRAG RACE ALL STARS\", 'ARE YOU THE ONE?', 'Paramount+', 'QUEEN OF THE UNIVERSE', 'BIG BROTHER', 'SURVIVOR', 'THE CHALLENGE', 'BAR RESCUE']}})]\n",
      "Epoch 91/100, Loss: 6, Weights: [0.18884169 0.29837452 0.51278379] min_loss_Weights: [0.19840362 0.30517768 0.4964187 ] ads: [(6, {'inputs': {'gemini_results': [('Nectar', 1), ('Sealy', 1), ('Casper', 1), ('Serta', 1), ('Stearns & Foster', 1), ('SmartLife', 1), ('King Koil', 1)], 'vi_results': [('Raymour & Flanigan', 0.99), ('Sealy Corporation', 0.99)], 'ocr_text': [('Nectar', 0.9), ('Sealy', 0.8), ('Casper', 0.7), ('Serta', 0.6), ('Stearns & Foster', 0.5), ('SmartLife', 0.4), ('King Koil', 0.3)]}, 'output': {'final': ['SmartLife', 'Casper', 'Serta', 'King Koil', 'Stearns & Foster', 'Nectar', 'Sealy']}}), (26, {'inputs': {'gemini_results': [(\"Baker's\", 1), ('Fox', 1)], 'vi_results': [('KTVU', 0.99), ('Fox Broadcasting Company', 0.99)], 'ocr_text': [('AT&T', 0.9)]}, 'output': {'final': [\"Baker's\", 'Fox']}}), (36, {'inputs': {'gemini_results': [('Paramount+', 1), (\"RUPAUL'S DRAG RACE ALL STARS\", 1), ('BIG BROTHER', 1), ('THE CHALLENGE', 1), ('SURVIVOR', 1), ('ARE YOU THE ONE?', 1), ('INK MASTER', 1), ('QUEEN OF THE UNIVERSE', 1), ('BAR RESCUE', 1)], 'vi_results': [], 'ocr_text': [('Paramount+', 0.9), (\"RUPAUL'S DRAG RACE ALL STARS\", 0.8), ('BIG BROTHER', 0.8), ('THE CHALLENGE', 0.7), ('SURVIVOR', 0.6), ('ARE YOU THE ONE?', 0.5), ('INK MASTER', 0.4), ('QUEEN OF THE UNIVERSE', 0.4), ('BAR RESCUE', 0.3)]}, 'output': {'final': ['INK MASTER', \"RUPAUL'S DRAG RACE ALL STARS\", 'ARE YOU THE ONE?', 'Paramount+', 'QUEEN OF THE UNIVERSE', 'BIG BROTHER', 'SURVIVOR', 'THE CHALLENGE', 'BAR RESCUE']}})]\n",
      "Epoch 92/100, Loss: 3, Weights: [0.19884169 0.29837452 0.50278379] min_loss_Weights: [0.19840362 0.30517768 0.4964187 ] ads: [(6, {'inputs': {'gemini_results': [('Nectar', 1), ('Sealy', 1), ('Casper', 1), ('Serta', 1), ('Stearns & Foster', 1), ('SmartLife', 1), ('King Koil', 1)], 'vi_results': [('Raymour & Flanigan', 0.99), ('Sealy Corporation', 0.99)], 'ocr_text': [('Nectar', 0.9), ('Sealy', 0.8), ('Casper', 0.7), ('Serta', 0.6), ('Stearns & Foster', 0.5), ('SmartLife', 0.4), ('King Koil', 0.3)]}, 'output': {'final': ['SmartLife', 'Casper', 'Serta', 'King Koil', 'Stearns & Foster', 'Nectar', 'Sealy']}}), (26, {'inputs': {'gemini_results': [(\"Baker's\", 1), ('Fox', 1)], 'vi_results': [('KTVU', 0.99), ('Fox Broadcasting Company', 0.99)], 'ocr_text': [('AT&T', 0.9)]}, 'output': {'final': [\"Baker's\", 'Fox']}}), (36, {'inputs': {'gemini_results': [('Paramount+', 1), (\"RUPAUL'S DRAG RACE ALL STARS\", 1), ('BIG BROTHER', 1), ('THE CHALLENGE', 1), ('SURVIVOR', 1), ('ARE YOU THE ONE?', 1), ('INK MASTER', 1), ('QUEEN OF THE UNIVERSE', 1), ('BAR RESCUE', 1)], 'vi_results': [], 'ocr_text': [('Paramount+', 0.9), (\"RUPAUL'S DRAG RACE ALL STARS\", 0.8), ('BIG BROTHER', 0.8), ('THE CHALLENGE', 0.7), ('SURVIVOR', 0.6), ('ARE YOU THE ONE?', 0.5), ('INK MASTER', 0.4), ('QUEEN OF THE UNIVERSE', 0.4), ('BAR RESCUE', 0.3)]}, 'output': {'final': ['INK MASTER', \"RUPAUL'S DRAG RACE ALL STARS\", 'ARE YOU THE ONE?', 'Paramount+', 'QUEEN OF THE UNIVERSE', 'BIG BROTHER', 'SURVIVOR', 'THE CHALLENGE', 'BAR RESCUE']}})]\n",
      "Epoch 93/100, Loss: 4, Weights: [0.19884169 0.30837452 0.49278379] min_loss_Weights: [0.19840362 0.30517768 0.4964187 ] ads: [(6, {'inputs': {'gemini_results': [('Nectar', 1), ('Sealy', 1), ('Casper', 1), ('Serta', 1), ('Stearns & Foster', 1), ('SmartLife', 1), ('King Koil', 1)], 'vi_results': [('Raymour & Flanigan', 0.99), ('Sealy Corporation', 0.99)], 'ocr_text': [('Nectar', 0.9), ('Sealy', 0.8), ('Casper', 0.7), ('Serta', 0.6), ('Stearns & Foster', 0.5), ('SmartLife', 0.4), ('King Koil', 0.3)]}, 'output': {'final': ['SmartLife', 'Casper', 'Serta', 'King Koil', 'Stearns & Foster', 'Nectar', 'Sealy']}}), (26, {'inputs': {'gemini_results': [(\"Baker's\", 1), ('Fox', 1)], 'vi_results': [('KTVU', 0.99), ('Fox Broadcasting Company', 0.99)], 'ocr_text': [('AT&T', 0.9)]}, 'output': {'final': [\"Baker's\", 'Fox']}}), (36, {'inputs': {'gemini_results': [('Paramount+', 1), (\"RUPAUL'S DRAG RACE ALL STARS\", 1), ('BIG BROTHER', 1), ('THE CHALLENGE', 1), ('SURVIVOR', 1), ('ARE YOU THE ONE?', 1), ('INK MASTER', 1), ('QUEEN OF THE UNIVERSE', 1), ('BAR RESCUE', 1)], 'vi_results': [], 'ocr_text': [('Paramount+', 0.9), (\"RUPAUL'S DRAG RACE ALL STARS\", 0.8), ('BIG BROTHER', 0.8), ('THE CHALLENGE', 0.7), ('SURVIVOR', 0.6), ('ARE YOU THE ONE?', 0.5), ('INK MASTER', 0.4), ('QUEEN OF THE UNIVERSE', 0.4), ('BAR RESCUE', 0.3)]}, 'output': {'final': ['INK MASTER', \"RUPAUL'S DRAG RACE ALL STARS\", 'ARE YOU THE ONE?', 'Paramount+', 'QUEEN OF THE UNIVERSE', 'BIG BROTHER', 'SURVIVOR', 'THE CHALLENGE', 'BAR RESCUE']}})]\n",
      "Epoch 94/100, Loss: 5, Weights: [0.1926956  0.29425971 0.51304469] min_loss_Weights: [0.19840362 0.30517768 0.4964187 ] ads: [(6, {'inputs': {'gemini_results': [('Nectar', 1), ('Sealy', 1), ('Casper', 1), ('Serta', 1), ('Stearns & Foster', 1), ('SmartLife', 1), ('King Koil', 1)], 'vi_results': [('Raymour & Flanigan', 0.99), ('Sealy Corporation', 0.99)], 'ocr_text': [('Nectar', 0.9), ('Sealy', 0.8), ('Casper', 0.7), ('Serta', 0.6), ('Stearns & Foster', 0.5), ('SmartLife', 0.4), ('King Koil', 0.3)]}, 'output': {'final': ['SmartLife', 'Casper', 'Serta', 'King Koil', 'Stearns & Foster', 'Nectar', 'Sealy']}}), (26, {'inputs': {'gemini_results': [(\"Baker's\", 1), ('Fox', 1)], 'vi_results': [('KTVU', 0.99), ('Fox Broadcasting Company', 0.99)], 'ocr_text': [('AT&T', 0.9)]}, 'output': {'final': [\"Baker's\", 'Fox']}}), (36, {'inputs': {'gemini_results': [('Paramount+', 1), (\"RUPAUL'S DRAG RACE ALL STARS\", 1), ('BIG BROTHER', 1), ('THE CHALLENGE', 1), ('SURVIVOR', 1), ('ARE YOU THE ONE?', 1), ('INK MASTER', 1), ('QUEEN OF THE UNIVERSE', 1), ('BAR RESCUE', 1)], 'vi_results': [], 'ocr_text': [('Paramount+', 0.9), (\"RUPAUL'S DRAG RACE ALL STARS\", 0.8), ('BIG BROTHER', 0.8), ('THE CHALLENGE', 0.7), ('SURVIVOR', 0.6), ('ARE YOU THE ONE?', 0.5), ('INK MASTER', 0.4), ('QUEEN OF THE UNIVERSE', 0.4), ('BAR RESCUE', 0.3)]}, 'output': {'final': ['INK MASTER', \"RUPAUL'S DRAG RACE ALL STARS\", 'ARE YOU THE ONE?', 'Paramount+', 'QUEEN OF THE UNIVERSE', 'BIG BROTHER', 'SURVIVOR', 'THE CHALLENGE', 'BAR RESCUE']}})]\n",
      "Epoch 95/100, Loss: 4, Weights: [0.1926956  0.30425971 0.50304469] min_loss_Weights: [0.19840362 0.30517768 0.4964187 ] ads: [(6, {'inputs': {'gemini_results': [('Nectar', 1), ('Sealy', 1), ('Casper', 1), ('Serta', 1), ('Stearns & Foster', 1), ('SmartLife', 1), ('King Koil', 1)], 'vi_results': [('Raymour & Flanigan', 0.99), ('Sealy Corporation', 0.99)], 'ocr_text': [('Nectar', 0.9), ('Sealy', 0.8), ('Casper', 0.7), ('Serta', 0.6), ('Stearns & Foster', 0.5), ('SmartLife', 0.4), ('King Koil', 0.3)]}, 'output': {'final': ['SmartLife', 'Casper', 'Serta', 'King Koil', 'Stearns & Foster', 'Nectar', 'Sealy']}}), (26, {'inputs': {'gemini_results': [(\"Baker's\", 1), ('Fox', 1)], 'vi_results': [('KTVU', 0.99), ('Fox Broadcasting Company', 0.99)], 'ocr_text': [('AT&T', 0.9)]}, 'output': {'final': [\"Baker's\", 'Fox']}}), (36, {'inputs': {'gemini_results': [('Paramount+', 1), (\"RUPAUL'S DRAG RACE ALL STARS\", 1), ('BIG BROTHER', 1), ('THE CHALLENGE', 1), ('SURVIVOR', 1), ('ARE YOU THE ONE?', 1), ('INK MASTER', 1), ('QUEEN OF THE UNIVERSE', 1), ('BAR RESCUE', 1)], 'vi_results': [], 'ocr_text': [('Paramount+', 0.9), (\"RUPAUL'S DRAG RACE ALL STARS\", 0.8), ('BIG BROTHER', 0.8), ('THE CHALLENGE', 0.7), ('SURVIVOR', 0.6), ('ARE YOU THE ONE?', 0.5), ('INK MASTER', 0.4), ('QUEEN OF THE UNIVERSE', 0.4), ('BAR RESCUE', 0.3)]}, 'output': {'final': ['INK MASTER', \"RUPAUL'S DRAG RACE ALL STARS\", 'ARE YOU THE ONE?', 'Paramount+', 'QUEEN OF THE UNIVERSE', 'BIG BROTHER', 'SURVIVOR', 'THE CHALLENGE', 'BAR RESCUE']}})]\n",
      "Epoch 96/100, Loss: 3, Weights: [0.2026956  0.30425971 0.49304469] min_loss_Weights: [0.19840362 0.30517768 0.4964187 ] ads: [(6, {'inputs': {'gemini_results': [('Nectar', 1), ('Sealy', 1), ('Casper', 1), ('Serta', 1), ('Stearns & Foster', 1), ('SmartLife', 1), ('King Koil', 1)], 'vi_results': [('Raymour & Flanigan', 0.99), ('Sealy Corporation', 0.99)], 'ocr_text': [('Nectar', 0.9), ('Sealy', 0.8), ('Casper', 0.7), ('Serta', 0.6), ('Stearns & Foster', 0.5), ('SmartLife', 0.4), ('King Koil', 0.3)]}, 'output': {'final': ['SmartLife', 'Casper', 'Serta', 'King Koil', 'Stearns & Foster', 'Nectar', 'Sealy']}}), (26, {'inputs': {'gemini_results': [(\"Baker's\", 1), ('Fox', 1)], 'vi_results': [('KTVU', 0.99), ('Fox Broadcasting Company', 0.99)], 'ocr_text': [('AT&T', 0.9)]}, 'output': {'final': [\"Baker's\", 'Fox']}}), (36, {'inputs': {'gemini_results': [('Paramount+', 1), (\"RUPAUL'S DRAG RACE ALL STARS\", 1), ('BIG BROTHER', 1), ('THE CHALLENGE', 1), ('SURVIVOR', 1), ('ARE YOU THE ONE?', 1), ('INK MASTER', 1), ('QUEEN OF THE UNIVERSE', 1), ('BAR RESCUE', 1)], 'vi_results': [], 'ocr_text': [('Paramount+', 0.9), (\"RUPAUL'S DRAG RACE ALL STARS\", 0.8), ('BIG BROTHER', 0.8), ('THE CHALLENGE', 0.7), ('SURVIVOR', 0.6), ('ARE YOU THE ONE?', 0.5), ('INK MASTER', 0.4), ('QUEEN OF THE UNIVERSE', 0.4), ('BAR RESCUE', 0.3)]}, 'output': {'final': ['INK MASTER', \"RUPAUL'S DRAG RACE ALL STARS\", 'ARE YOU THE ONE?', 'Paramount+', 'QUEEN OF THE UNIVERSE', 'BIG BROTHER', 'SURVIVOR', 'THE CHALLENGE', 'BAR RESCUE']}})]\n",
      "Epoch 97/100, Loss: 6, Weights: [0.18642408 0.30026502 0.51331091] min_loss_Weights: [0.19840362 0.30517768 0.4964187 ] ads: [(6, {'inputs': {'gemini_results': [('Nectar', 1), ('Sealy', 1), ('Casper', 1), ('Serta', 1), ('Stearns & Foster', 1), ('SmartLife', 1), ('King Koil', 1)], 'vi_results': [('Raymour & Flanigan', 0.99), ('Sealy Corporation', 0.99)], 'ocr_text': [('Nectar', 0.9), ('Sealy', 0.8), ('Casper', 0.7), ('Serta', 0.6), ('Stearns & Foster', 0.5), ('SmartLife', 0.4), ('King Koil', 0.3)]}, 'output': {'final': ['SmartLife', 'Casper', 'Serta', 'King Koil', 'Stearns & Foster', 'Nectar', 'Sealy']}}), (26, {'inputs': {'gemini_results': [(\"Baker's\", 1), ('Fox', 1)], 'vi_results': [('KTVU', 0.99), ('Fox Broadcasting Company', 0.99)], 'ocr_text': [('AT&T', 0.9)]}, 'output': {'final': [\"Baker's\", 'Fox']}}), (36, {'inputs': {'gemini_results': [('Paramount+', 1), (\"RUPAUL'S DRAG RACE ALL STARS\", 1), ('BIG BROTHER', 1), ('THE CHALLENGE', 1), ('SURVIVOR', 1), ('ARE YOU THE ONE?', 1), ('INK MASTER', 1), ('QUEEN OF THE UNIVERSE', 1), ('BAR RESCUE', 1)], 'vi_results': [], 'ocr_text': [('Paramount+', 0.9), (\"RUPAUL'S DRAG RACE ALL STARS\", 0.8), ('BIG BROTHER', 0.8), ('THE CHALLENGE', 0.7), ('SURVIVOR', 0.6), ('ARE YOU THE ONE?', 0.5), ('INK MASTER', 0.4), ('QUEEN OF THE UNIVERSE', 0.4), ('BAR RESCUE', 0.3)]}, 'output': {'final': ['INK MASTER', \"RUPAUL'S DRAG RACE ALL STARS\", 'ARE YOU THE ONE?', 'Paramount+', 'QUEEN OF THE UNIVERSE', 'BIG BROTHER', 'SURVIVOR', 'THE CHALLENGE', 'BAR RESCUE']}})]\n",
      "Epoch 98/100, Loss: 3, Weights: [0.19642408 0.30026502 0.50331091] min_loss_Weights: [0.19840362 0.30517768 0.4964187 ] ads: [(6, {'inputs': {'gemini_results': [('Nectar', 1), ('Sealy', 1), ('Casper', 1), ('Serta', 1), ('Stearns & Foster', 1), ('SmartLife', 1), ('King Koil', 1)], 'vi_results': [('Raymour & Flanigan', 0.99), ('Sealy Corporation', 0.99)], 'ocr_text': [('Nectar', 0.9), ('Sealy', 0.8), ('Casper', 0.7), ('Serta', 0.6), ('Stearns & Foster', 0.5), ('SmartLife', 0.4), ('King Koil', 0.3)]}, 'output': {'final': ['SmartLife', 'Casper', 'Serta', 'King Koil', 'Stearns & Foster', 'Nectar', 'Sealy']}}), (26, {'inputs': {'gemini_results': [(\"Baker's\", 1), ('Fox', 1)], 'vi_results': [('KTVU', 0.99), ('Fox Broadcasting Company', 0.99)], 'ocr_text': [('AT&T', 0.9)]}, 'output': {'final': [\"Baker's\", 'Fox']}}), (36, {'inputs': {'gemini_results': [('Paramount+', 1), (\"RUPAUL'S DRAG RACE ALL STARS\", 1), ('BIG BROTHER', 1), ('THE CHALLENGE', 1), ('SURVIVOR', 1), ('ARE YOU THE ONE?', 1), ('INK MASTER', 1), ('QUEEN OF THE UNIVERSE', 1), ('BAR RESCUE', 1)], 'vi_results': [], 'ocr_text': [('Paramount+', 0.9), (\"RUPAUL'S DRAG RACE ALL STARS\", 0.8), ('BIG BROTHER', 0.8), ('THE CHALLENGE', 0.7), ('SURVIVOR', 0.6), ('ARE YOU THE ONE?', 0.5), ('INK MASTER', 0.4), ('QUEEN OF THE UNIVERSE', 0.4), ('BAR RESCUE', 0.3)]}, 'output': {'final': ['INK MASTER', \"RUPAUL'S DRAG RACE ALL STARS\", 'ARE YOU THE ONE?', 'Paramount+', 'QUEEN OF THE UNIVERSE', 'BIG BROTHER', 'SURVIVOR', 'THE CHALLENGE', 'BAR RESCUE']}})]\n",
      "Epoch 99/100, Loss: 3, Weights: [0.20642408 0.30026502 0.49331091] min_loss_Weights: [0.19840362 0.30517768 0.4964187 ] ads: [(6, {'inputs': {'gemini_results': [('Nectar', 1), ('Sealy', 1), ('Casper', 1), ('Serta', 1), ('Stearns & Foster', 1), ('SmartLife', 1), ('King Koil', 1)], 'vi_results': [('Raymour & Flanigan', 0.99), ('Sealy Corporation', 0.99)], 'ocr_text': [('Nectar', 0.9), ('Sealy', 0.8), ('Casper', 0.7), ('Serta', 0.6), ('Stearns & Foster', 0.5), ('SmartLife', 0.4), ('King Koil', 0.3)]}, 'output': {'final': ['SmartLife', 'Casper', 'Serta', 'King Koil', 'Stearns & Foster', 'Nectar', 'Sealy']}}), (26, {'inputs': {'gemini_results': [(\"Baker's\", 1), ('Fox', 1)], 'vi_results': [('KTVU', 0.99), ('Fox Broadcasting Company', 0.99)], 'ocr_text': [('AT&T', 0.9)]}, 'output': {'final': [\"Baker's\", 'Fox']}}), (36, {'inputs': {'gemini_results': [('Paramount+', 1), (\"RUPAUL'S DRAG RACE ALL STARS\", 1), ('BIG BROTHER', 1), ('THE CHALLENGE', 1), ('SURVIVOR', 1), ('ARE YOU THE ONE?', 1), ('INK MASTER', 1), ('QUEEN OF THE UNIVERSE', 1), ('BAR RESCUE', 1)], 'vi_results': [], 'ocr_text': [('Paramount+', 0.9), (\"RUPAUL'S DRAG RACE ALL STARS\", 0.8), ('BIG BROTHER', 0.8), ('THE CHALLENGE', 0.7), ('SURVIVOR', 0.6), ('ARE YOU THE ONE?', 0.5), ('INK MASTER', 0.4), ('QUEEN OF THE UNIVERSE', 0.4), ('BAR RESCUE', 0.3)]}, 'output': {'final': ['INK MASTER', \"RUPAUL'S DRAG RACE ALL STARS\", 'ARE YOU THE ONE?', 'Paramount+', 'QUEEN OF THE UNIVERSE', 'BIG BROTHER', 'SURVIVOR', 'THE CHALLENGE', 'BAR RESCUE']}})]\n",
      "Epoch 100/100, Loss: 6, Weights: [0.19022865 0.29618879 0.51358256] min_loss_Weights: [0.19840362 0.30517768 0.4964187 ] ads: [(6, {'inputs': {'gemini_results': [('Nectar', 1), ('Sealy', 1), ('Casper', 1), ('Serta', 1), ('Stearns & Foster', 1), ('SmartLife', 1), ('King Koil', 1)], 'vi_results': [('Raymour & Flanigan', 0.99), ('Sealy Corporation', 0.99)], 'ocr_text': [('Nectar', 0.9), ('Sealy', 0.8), ('Casper', 0.7), ('Serta', 0.6), ('Stearns & Foster', 0.5), ('SmartLife', 0.4), ('King Koil', 0.3)]}, 'output': {'final': ['SmartLife', 'Casper', 'Serta', 'King Koil', 'Stearns & Foster', 'Nectar', 'Sealy']}}), (26, {'inputs': {'gemini_results': [(\"Baker's\", 1), ('Fox', 1)], 'vi_results': [('KTVU', 0.99), ('Fox Broadcasting Company', 0.99)], 'ocr_text': [('AT&T', 0.9)]}, 'output': {'final': [\"Baker's\", 'Fox']}}), (36, {'inputs': {'gemini_results': [('Paramount+', 1), (\"RUPAUL'S DRAG RACE ALL STARS\", 1), ('BIG BROTHER', 1), ('THE CHALLENGE', 1), ('SURVIVOR', 1), ('ARE YOU THE ONE?', 1), ('INK MASTER', 1), ('QUEEN OF THE UNIVERSE', 1), ('BAR RESCUE', 1)], 'vi_results': [], 'ocr_text': [('Paramount+', 0.9), (\"RUPAUL'S DRAG RACE ALL STARS\", 0.8), ('BIG BROTHER', 0.8), ('THE CHALLENGE', 0.7), ('SURVIVOR', 0.6), ('ARE YOU THE ONE?', 0.5), ('INK MASTER', 0.4), ('QUEEN OF THE UNIVERSE', 0.4), ('BAR RESCUE', 0.3)]}, 'output': {'final': ['INK MASTER', \"RUPAUL'S DRAG RACE ALL STARS\", 'ARE YOU THE ONE?', 'Paramount+', 'QUEEN OF THE UNIVERSE', 'BIG BROTHER', 'SURVIVOR', 'THE CHALLENGE', 'BAR RESCUE']}})]\n",
      "Test Data - Final Brand: Ziploc, Confidence Score: 0.3910420801202134\n",
      "Test Data - Weights: [0.19022865 0.29618879 0.51358256]\n",
      "Expected: Carvana, Predicted: Carvana, Confidence: 0.4753895438171502, Loss: 0\n",
      "Training Data - Weights: [0.19022865 0.29618879 0.51358256]\n",
      "Expected: Febreze, Predicted: Febreze, Confidence: 0.6617146624617165, Loss: 0\n",
      "Training Data - Weights: [0.19022865 0.29618879 0.51358256]\n",
      "Expected: Unilever, Predicted: Unilever, Confidence: 0.41389694475647465, Loss: 0\n",
      "Training Data - Weights: [0.19022865 0.29618879 0.51358256]\n",
      "Expected: Paramount+, Predicted: Paramount+, Confidence: 0.689930052895147, Loss: 0\n",
      "Training Data - Weights: [0.19022865 0.29618879 0.51358256]\n",
      "Expected: Discover Newport, Predicted: Discover Newport, Confidence: 1.0, Loss: 0\n",
      "Training Data - Weights: [0.19022865 0.29618879 0.51358256]\n",
      "Expected: Raymour & Flanigan, Predicted: Raymour & Flanigan, Confidence: 0.7727390112826853, Loss: 0\n",
      "Training Data - Weights: [0.19022865 0.29618879 0.51358256]\n",
      "Expected: SmartLife, Predicted: Nectar, Confidence: 0.160107181584048, Loss: 1\n",
      "Training Data - Weights: [0.19022865 0.29618879 0.51358256]\n",
      "Expected: BETMGM, Predicted: BETMGM, Confidence: 0.5454780225653708, Loss: 0\n",
      "Training Data - Weights: [0.19022865 0.29618879 0.51358256]\n",
      "Expected: Missouri, Predicted: Missouri, Confidence: 1.0, Loss: 0\n",
      "Training Data - Weights: [0.19022865 0.29618879 0.51358256]\n",
      "Expected: Paramount+, Predicted: Paramount+, Confidence: 0.689930052895147, Loss: 0\n",
      "Training Data - Weights: [0.19022865 0.29618879 0.51358256]\n",
      "Expected: Raymour & Flanigan, Predicted: Raymour & Flanigan, Confidence: 1.0, Loss: 0\n",
      "Training Data - Weights: [0.19022865 0.29618879 0.51358256]\n",
      "Expected: HelloFresh, Predicted: HelloFresh, Confidence: 0.8645507383337424, Loss: 0\n",
      "Training Data - Weights: [0.19022865 0.29618879 0.51358256]\n",
      "Expected: CREATION MUSEUM, Predicted: CREATION MUSEUM, Confidence: 1.0, Loss: 0\n",
      "Training Data - Weights: [0.19022865 0.29618879 0.51358256]\n",
      "Expected: Ruggable, Predicted: Ruggable, Confidence: 1.0, Loss: 0\n",
      "Training Data - Weights: [0.19022865 0.29618879 0.51358256]\n",
      "Expected: WELLS FARGO, Predicted: WELLS FARGO, Confidence: 0.5454780225653708, Loss: 0\n",
      "Training Data - Weights: [0.19022865 0.29618879 0.51358256]\n",
      "Expected: Jacoby & Meyers, Predicted: Jacoby & Meyers, Confidence: 0.689930052895147, Loss: 0\n",
      "Training Data - Weights: [0.19022865 0.29618879 0.51358256]\n",
      "Expected: Ziploc, Predicted: Ziploc, Confidence: 0.42589390668767585, Loss: 0\n",
      "Training Data - Weights: [0.19022865 0.29618879 0.51358256]\n",
      "Expected: Xfinity, Predicted: Xfinity, Confidence: 0.5927995546853119, Loss: 0\n",
      "Training Data - Weights: [0.19022865 0.29618879 0.51358256]\n",
      "Expected: Comcast, Predicted: Comcast, Confidence: 0.5266360429226209, Loss: 0\n",
      "Training Data - Weights: [0.19022865 0.29618879 0.51358256]\n",
      "Expected: COMCAST BUSINESS, Predicted: COMCAST BUSINESS, Confidence: 0.5151082499449552, Loss: 0\n",
      "Training Data - Weights: [0.19022865 0.29618879 0.51358256]\n",
      "Expected: Xfinity Mobile, Predicted: Xfinity Mobile, Confidence: 1.0, Loss: 0\n",
      "Training Data - Weights: [0.19022865 0.29618879 0.51358256]\n",
      "Expected: Jacoby & Meyers, Predicted: Jacoby & Meyers, Confidence: 0.6981271519533573, Loss: 0\n",
      "Training Data - Weights: [0.19022865 0.29618879 0.51358256]\n",
      "Expected: Mastercard, Predicted: Mastercard, Confidence: 0.7727390112826853, Loss: 0\n",
      "Training Data - Weights: [0.19022865 0.29618879 0.51358256]\n",
      "Expected: BETMGM, Predicted: BETMGM, Confidence: 0.6059011268438146, Loss: 0\n",
      "Training Data - Weights: [0.19022865 0.29618879 0.51358256]\n",
      "Expected: ORIS, Predicted: ORIS, Confidence: 0.5835394977395004, Loss: 0\n",
      "Training Data - Weights: [0.19022865 0.29618879 0.51358256]\n",
      "Expected: Safelite, Predicted: Safelite, Confidence: 0.7727390112826853, Loss: 0\n",
      "Training Data - Weights: [0.19022865 0.29618879 0.51358256]\n",
      "Expected: Baker's, Predicted: AT&T, Confidence: 0.32342932492343324, Loss: 1\n",
      "Training Data - Weights: [0.19022865 0.29618879 0.51358256]\n",
      "Expected: Freeform, Predicted: Freeform, Confidence: 0.4082595322292633, Loss: 0\n",
      "Training Data - Weights: [0.19022865 0.29618879 0.51358256]\n",
      "Expected: Booking.com, Predicted: Booking.com, Confidence: 0.5743886488427657, Loss: 0\n",
      "Training Data - Weights: [0.19022865 0.29618879 0.51358256]\n",
      "Expected: Paramount+, Predicted: Paramount+, Confidence: 0.579729514957496, Loss: 0\n",
      "Training Data - Weights: [0.19022865 0.29618879 0.51358256]\n",
      "Expected: SHERWIN-WILLIAMS, Predicted: SHERWIN-WILLIAMS, Confidence: 0.4468962384022022, Loss: 0\n",
      "Training Data - Weights: [0.19022865 0.29618879 0.51358256]\n",
      "Expected: Hulu, Predicted: Hulu, Confidence: 0.3438486972720807, Loss: 0\n",
      "Training Data - Weights: [0.19022865 0.29618879 0.51358256]\n",
      "Expected: MADE IN COOKWARE, Predicted: MADE IN COOKWARE, Confidence: 0.689930052895147, Loss: 0\n",
      "Training Data - Weights: [0.19022865 0.29618879 0.51358256]\n",
      "Expected: Pandora, Predicted: Pandora, Confidence: 1.0, Loss: 0\n",
      "Training Data - Weights: [0.19022865 0.29618879 0.51358256]\n",
      "Expected: Lincoln, Predicted: Lincoln, Confidence: 1.0, Loss: 0\n",
      "Training Data - Weights: [0.19022865 0.29618879 0.51358256]\n",
      "Expected: U.S. Bank, Predicted: U.S. Bank, Confidence: 0.5266360429226209, Loss: 0\n",
      "Training Data - Weights: [0.19022865 0.29618879 0.51358256]\n",
      "Expected: INK MASTER, Predicted: Paramount+, Confidence: 0.1454613676862542, Loss: 1\n",
      "Training Data - Weights: [0.19022865 0.29618879 0.51358256]\n",
      "Expected: MAIN EVENT, Predicted: MAIN EVENT, Confidence: 1.0, Loss: 0\n",
      "Training Data - Weights: [0.19022865 0.29618879 0.51358256]\n",
      "Expected: Amazon Prime, Predicted: Amazon Prime, Confidence: 1.0, Loss: 0\n",
      "Training Data - Weights: [0.19022865 0.29618879 0.51358256]\n",
      "Expected: ARIAT, Predicted: ARIAT, Confidence: 1.0, Loss: 0\n",
      "Training Data - Weights: [0.19022865 0.29618879 0.51358256]\n",
      "Expected: Bassett, Predicted: Bassett, Confidence: 0.7059020116765176, Loss: 0\n",
      "Training Data - Weights: [0.19022865 0.29618879 0.51358256]\n",
      "Expected: Taco Bell, Predicted: Taco Bell, Confidence: 1.0, Loss: 0\n",
      "Training Data - Weights: [0.19022865 0.29618879 0.51358256]\n",
      "Expected: Bassett, Predicted: Bassett, Confidence: 0.36628471257735523, Loss: 0\n",
      "Training Data - Weights: [0.19022865 0.29618879 0.51358256]\n",
      "Expected: Taco Bell, Predicted: Taco Bell, Confidence: 1.0, Loss: 0\n",
      "Training Data - Weights: [0.19022865 0.29618879 0.51358256]\n",
      "Total Loss on Training Data: 3\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "from collections import defaultdict\n",
    "\n",
    "# Example dataset\n",
    "data = copy.deepcopy(data_set)\n",
    "\n",
    "# Combining confidence scores with weights\n",
    "def combine_confidences(inputs, weights):\n",
    "    combined_scores = defaultdict(float)\n",
    "    for source, weight in zip(['gemini_results', 'vi_results', 'ocr_text'], weights):\n",
    "        for brand, score in inputs[source]:\n",
    "            combined_scores[brand] += weight * score\n",
    "    return combined_scores\n",
    "\n",
    "# Normalizing the scores\n",
    "def normalize_scores(combined_scores):\n",
    "    total_score = sum(combined_scores.values())\n",
    "    if total_score == 0:\n",
    "        return combined_scores\n",
    "    for brand in combined_scores:\n",
    "        combined_scores[brand] /= total_score\n",
    "    return combined_scores\n",
    "\n",
    "# Computing the final prediction\n",
    "def get_final_brand(inputs, weights):\n",
    "    combined_scores = combine_confidences(inputs, weights)\n",
    "    normalized_scores = normalize_scores(combined_scores)\n",
    "    final_brand = max(normalized_scores, key=normalized_scores.get)\n",
    "    final_confidence = normalized_scores[final_brand]\n",
    "    return final_brand, final_confidence\n",
    "\n",
    "# Calculating the loss function\n",
    "def calculate_loss(predicted, actual):\n",
    "    return 1 if predicted != actual else 0\n",
    "\n",
    "# Optimizing the weights using gradient descent\n",
    "def optimize_weights(data_set, learning_rate=0.01, epochs=100):\n",
    "    \n",
    "    min_loss_weights = None\n",
    "    min_loss= None\n",
    "    min_ads = None\n",
    "    \n",
    "    weights = np.ones(3) / 3  # Initial weights for gemini_results, vi_results, ocr_text\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        weight_gradients = np.zeros(3)\n",
    "        false_ads_pred = []\n",
    "        for index,entry in enumerate(data_set):\n",
    "            actual_final = entry['output']['final'][0]\n",
    "            final_brand, _ = get_final_brand(entry['inputs'], weights)\n",
    "            loss = calculate_loss(final_brand, actual_final)\n",
    "            total_loss += loss\n",
    "            if final_brand != actual_final:\n",
    "                false_ads_pred.append((index,entry))\n",
    "                for i, source in enumerate(['gemini_results', 'vi_results', 'ocr_text']):\n",
    "                    if any(brand == actual_final for brand, _ in entry['inputs'][source]):\n",
    "                        weight_gradients[i] -= 1\n",
    "                    if any(brand == final_brand for brand, _ in entry['inputs'][source]):\n",
    "                        weight_gradients[i] += 1\n",
    "        \n",
    "        weights -= learning_rate * weight_gradients\n",
    "        weights = np.clip(weights, 0, 1)\n",
    "        weights /= np.sum(weights)\n",
    "        \n",
    "        if(min_loss == None):\n",
    "            min_loss=total_loss\n",
    "            min_loss_weights = weights\n",
    "            min_ads = copy.deepcopy(false_ads_pred)\n",
    "        elif(min_loss>total_loss):\n",
    "            min_loss=total_loss\n",
    "            min_loss_weights = weights\n",
    "            min_ads = copy.deepcopy(false_ads_pred)\n",
    "            \n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss}, Weights: {weights} min_loss_Weights: {min_loss_weights} ads: {min_ads}\")\n",
    "        \n",
    "        \n",
    "    return (weights,min_loss_weights)\n",
    "\n",
    "# Optimizing weights and testing\n",
    "final_weights,_ = optimize_weights(data)\n",
    "\n",
    "# Test case\n",
    "test_data = [\n",
    "    {'inputs': {'gemini_results': [('Disney', 1.00), ('Ziploc', 1.00), ('SC Johnson', 1.00)], 'vi_results': [('Ziploc', 0.99), ('The Walt Disney Company', 0.99)], 'ocr_text': [('Disney', 0.90), ('Ziploc', 0.80), ('MIPS', 0.50)]}},\n",
    "]\n",
    "\n",
    "# Get predictions for test data\n",
    "for entry in test_data:\n",
    "    final_brand, final_confidence = get_final_brand(entry['inputs'], final_weights)\n",
    "    print(f\"Test Data - Final Brand: {final_brand}, Confidence Score: {final_confidence}\")\n",
    "    print(f\"Test Data - Weights: {final_weights}\")\n",
    "\n",
    "# Print results for training data and calculate total loss\n",
    "total_loss = 0\n",
    "for entry in data:\n",
    "    final_brand, final_confidence = get_final_brand(entry['inputs'], final_weights)\n",
    "    actual_final = entry['output']['final'][0]\n",
    "    loss = calculate_loss(final_brand, actual_final)\n",
    "    total_loss += loss\n",
    "    print(f\"Expected: {actual_final}, Predicted: {final_brand}, Confidence: {final_confidence}, Loss: {loss}\")\n",
    "    print(f\"Training Data - Weights: {final_weights}\")\n",
    "\n",
    "print(f\"Total Loss on Training Data: {total_loss}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5000, Loss: 25.01246291782739, Weights: [0.35757408 0.25142729 0.39099863]\n",
      "Epoch 2/5000, Loss: 22.12315579589702, Weights: [0.37133075 0.1940768  0.43459245]\n",
      "Epoch 3/5000, Loss: 20.212505186303737, Weights: [0.37808984 0.15356581 0.46834435]\n",
      "Epoch 4/5000, Loss: 18.894339602171073, Weights: [0.38017489 0.12478536 0.49503976]\n",
      "Epoch 5/5000, Loss: 17.95975169860321, Weights: [0.37917327 0.10426118 0.51656555]\n",
      "Epoch 6/5000, Loss: 17.283932385227125, Weights: [0.37618434 0.08958844 0.53422722]\n",
      "Epoch 7/5000, Loss: 16.787474503229525, Weights: [0.37197363 0.07908237 0.548944  ]\n",
      "Epoch 8/5000, Loss: 16.417729172363018, Weights: [0.36707358 0.07155282 0.5613736 ]\n",
      "Epoch 9/5000, Loss: 16.138799857147887, Weights: [0.36185182 0.06615419 0.57199399]\n",
      "Epoch 10/5000, Loss: 15.925727176983143, Weights: [0.35655872 0.06228322 0.58115806]\n",
      "Epoch 11/5000, Loss: 15.760905664318702, Weights: [0.35136107 0.05950836 0.58913056]\n",
      "Epoch 12/5000, Loss: 15.631779439702376, Weights: [0.3463662 0.0575203 0.5961135]\n",
      "Epoch 13/5000, Loss: 15.529313422820827, Weights: [0.34163935 0.05609706 0.6022636 ]\n",
      "Epoch 14/5000, Loss: 15.44695564330741, Weights: [0.33721626 0.05507921 0.60770453]\n",
      "Epoch 15/5000, Loss: 15.379920915126267, Weights: [0.33311227 0.05435221 0.61253552]\n",
      "Epoch 16/5000, Loss: 15.32469008443904, Weights: [0.32932881 0.05383378 0.61683741]\n",
      "Epoch 17/5000, Loss: 15.278656620578587, Weights: [0.32585816 0.05346477 0.62067707]\n",
      "Epoch 18/5000, Loss: 15.239875352986576, Weights: [0.32268675 0.05320273 0.62411052]\n",
      "Epoch 19/5000, Loss: 15.206882787682018, Weights: [0.31979756 0.05301716 0.62718528]\n",
      "Epoch 20/5000, Loss: 15.178567997871564, Weights: [0.31717174 0.05288619 0.62994207]\n",
      "Epoch 21/5000, Loss: 15.154079474717383, Weights: [0.31478977 0.05279415 0.63241608]\n",
      "Epoch 22/5000, Loss: 15.132757674237498, Weights: [0.31263223 0.0527298  0.63463798]\n",
      "Epoch 23/5000, Loss: 15.114085998883587, Weights: [0.31068027 0.0526851  0.63663463]\n",
      "Epoch 24/5000, Loss: 15.097655047734465, Weights: [0.30891596 0.05265431 0.63842973]\n",
      "Epoch 25/5000, Loss: 15.083136444013418, Weights: [0.30732245 0.05263334 0.64004422]\n",
      "Epoch 26/5000, Loss: 15.070263593407827, Weights: [0.30588404 0.05261926 0.6414967 ]\n",
      "Epoch 27/5000, Loss: 15.058817470543218, Weights: [0.30458625 0.05261    0.64280376]\n",
      "Epoch 28/5000, Loss: 15.04861606264955, Weights: [0.30341576 0.05260408 0.64398016]\n",
      "Epoch 29/5000, Loss: 15.039506480620563, Weights: [0.30236039 0.05260047 0.64503914]\n",
      "Epoch 30/5000, Loss: 15.031359021563032, Weights: [0.30140905 0.05259843 0.64599252]\n",
      "Epoch 31/5000, Loss: 15.024062664120036, Weights: [0.30055163 0.05259745 0.64685093]\n",
      "Epoch 32/5000, Loss: 15.017521620037668, Weights: [0.29977896 0.05259716 0.64762387]\n",
      "Epoch 33/5000, Loss: 15.011652668109429, Weights: [0.29908276 0.05259732 0.64831991]\n",
      "Epoch 34/5000, Loss: 15.006383070856348, Weights: [0.29845551 0.05259775 0.64894673]\n",
      "Epoch 35/5000, Loss: 15.001648928029342, Weights: [0.29789042 0.05259835 0.64951124]\n",
      "Epoch 36/5000, Loss: 14.99739385996412, Weights: [0.29738135 0.05259901 0.65001964]\n",
      "Epoch 37/5000, Loss: 14.993567942086747, Weights: [0.29692277 0.05259971 0.65047752]\n",
      "Epoch 38/5000, Loss: 14.99012683242041, Weights: [0.29650969 0.0526004  0.65088992]\n",
      "Epoch 39/5000, Loss: 14.987031048915435, Weights: [0.29613759 0.05260106 0.65126135]\n",
      "Epoch 40/5000, Loss: 14.984245364354901, Weights: [0.29580243 0.05260168 0.65159589]\n",
      "Epoch 41/5000, Loss: 14.981738294589961, Weights: [0.29550053 0.05260226 0.65189721]\n",
      "Epoch 42/5000, Loss: 14.979481661735402, Weights: [0.2952286  0.05260279 0.65216861]\n",
      "Epoch 43/5000, Loss: 14.977450218287839, Weights: [0.29498366 0.05260327 0.65241307]\n",
      "Epoch 44/5000, Loss: 14.975621321336785, Weights: [0.29476304 0.05260371 0.65263325]\n",
      "Epoch 45/5000, Loss: 14.973974648426651, Weights: [0.29456432 0.0526041  0.65283157]\n",
      "Epoch 46/5000, Loss: 14.97249194841613, Weights: [0.29438534 0.05260446 0.65301021]\n",
      "Epoch 47/5000, Loss: 14.971156822030288, Weights: [0.29422412 0.05260478 0.65317111]\n",
      "Epoch 48/5000, Loss: 14.969954527826227, Weights: [0.2940789  0.05260506 0.65331604]\n",
      "Epoch 49/5000, Loss: 14.968871810079797, Weights: [0.29394811 0.05260532 0.65344658]\n",
      "Epoch 50/5000, Loss: 14.967896745710243, Weights: [0.29383029 0.05260555 0.65356416]\n",
      "Epoch 51/5000, Loss: 14.96701860783662, Weights: [0.29372418 0.05260575 0.65367007]\n",
      "Epoch 52/5000, Loss: 14.966227743937475, Weights: [0.2936286  0.05260594 0.65376547]\n",
      "Epoch 53/5000, Loss: 14.965515466887682, Weights: [0.29354251 0.0526061  0.65385139]\n",
      "Epoch 54/5000, Loss: 14.96487395739124, Weights: [0.29346496 0.05260625 0.65392879]\n",
      "Epoch 55/5000, Loss: 14.964296176529633, Weights: [0.29339511 0.05260638 0.65399851]\n",
      "Epoch 56/5000, Loss: 14.963775787311762, Weights: [0.2933322 0.0526065 0.6540613]\n",
      "Epoch 57/5000, Loss: 14.963307084250683, Weights: [0.29327553 0.0526066  0.65411786]\n",
      "Epoch 58/5000, Loss: 14.962884930110373, Weights: [0.29322449 0.0526067  0.65416881]\n",
      "Epoch 59/5000, Loss: 14.962504699066196, Weights: [0.29317851 0.05260678 0.6542147 ]\n",
      "Epoch 60/5000, Loss: 14.96216222560918, Weights: [0.2931371  0.05260686 0.65425604]\n",
      "Epoch 61/5000, Loss: 14.961853758599275, Weights: [0.2930998  0.05260693 0.65429327]\n",
      "Epoch 62/5000, Loss: 14.961575919937866, Weights: [0.2930662  0.05260699 0.65432681]\n",
      "Epoch 63/5000, Loss: 14.961325667387202, Weights: [0.29303594 0.05260704 0.65435702]\n",
      "Epoch 64/5000, Loss: 14.961100261114424, Weights: [0.29300868 0.05260709 0.65438423]\n",
      "Epoch 65/5000, Loss: 14.960897233582799, Weights: [0.29298413 0.05260714 0.65440873]\n",
      "Epoch 66/5000, Loss: 14.960714362451652, Weights: [0.29296201 0.05260718 0.65443081]\n",
      "Epoch 67/5000, Loss: 14.96054964618191, Weights: [0.29294209 0.05260721 0.6544507 ]\n",
      "Epoch 68/5000, Loss: 14.960401282075134, Weights: [0.29292415 0.05260725 0.65446861]\n",
      "Epoch 69/5000, Loss: 14.960267646501832, Weights: [0.29290799 0.05260727 0.65448474]\n",
      "Epoch 70/5000, Loss: 14.960147277099624, Weights: [0.29289343 0.0526073  0.65449927]\n",
      "Epoch 71/5000, Loss: 14.960038856744209, Weights: [0.29288031 0.05260732 0.65451236]\n",
      "Epoch 72/5000, Loss: 14.959941199115821, Weights: [0.2928685  0.05260734 0.65452415]\n",
      "Epoch 73/5000, Loss: 14.959853235702008, Weights: [0.29285786 0.05260736 0.65453477]\n",
      "Epoch 74/5000, Loss: 14.959774004093186, Weights: [0.29284828 0.05260738 0.65454434]\n",
      "Epoch 75/5000, Loss: 14.95970263744234, Weights: [0.29283965 0.0526074  0.65455295]\n",
      "Epoch 76/5000, Loss: 14.95963835497255, Weights: [0.29283187 0.05260741 0.65456072]\n",
      "Epoch 77/5000, Loss: 14.959580453428247, Weights: [0.29282487 0.05260742 0.65456771]\n",
      "Epoch 78/5000, Loss: 14.959528299376071, Weights: [0.29281856 0.05260743 0.654574  ]\n",
      "Epoch 79/5000, Loss: 14.959481322270841, Weights: [0.29281288 0.05260744 0.65457967]\n",
      "Epoch 80/5000, Loss: 14.95943900821049, Weights: [0.29280776 0.05260745 0.65458478]\n",
      "Epoch 81/5000, Loss: 14.959400894311432, Weights: [0.29280315 0.05260746 0.65458939]\n",
      "Epoch 82/5000, Loss: 14.959366563642721, Weights: [0.292799   0.05260747 0.65459353]\n",
      "Epoch 83/5000, Loss: 14.959335640663356, Weights: [0.29279526 0.05260747 0.65459726]\n",
      "Epoch 84/5000, Loss: 14.959307787112776, Weights: [0.29279189 0.05260748 0.65460063]\n",
      "Epoch 85/5000, Loss: 14.959282698309522, Weights: [0.29278886 0.05260749 0.65460366]\n",
      "Epoch 86/5000, Loss: 14.959260099817433, Weights: [0.29278612 0.05260749 0.65460639]\n",
      "Epoch 87/5000, Loss: 14.959239744442941, Weights: [0.29278366 0.05260749 0.65460884]\n",
      "Epoch 88/5000, Loss: 14.9592214095305, Weights: [0.29278144 0.0526075  0.65461106]\n",
      "Epoch 89/5000, Loss: 14.959204894526588, Weights: [0.29277945 0.0526075  0.65461305]\n",
      "Epoch 90/5000, Loss: 14.959190018785561, Weights: [0.29277765 0.05260751 0.65461485]\n",
      "Epoch 91/5000, Loss: 14.959176619593407, Weights: [0.29277603 0.05260751 0.65461646]\n",
      "Epoch 92/5000, Loss: 14.95916455038762, Weights: [0.29277457 0.05260751 0.65461792]\n",
      "Epoch 93/5000, Loss: 14.95915367915389, Weights: [0.29277325 0.05260751 0.65461923]\n",
      "Epoch 94/5000, Loss: 14.959143886981938, Weights: [0.29277207 0.05260752 0.65462042]\n",
      "Epoch 95/5000, Loss: 14.959135066764725, Weights: [0.292771   0.05260752 0.65462148]\n",
      "Epoch 96/5000, Loss: 14.95912712202679, Weights: [0.29277004 0.05260752 0.65462244]\n",
      "Epoch 97/5000, Loss: 14.9591199658689, Weights: [0.29276917 0.05260752 0.65462331]\n",
      "Epoch 98/5000, Loss: 14.959113520017507, Weights: [0.29276839 0.05260752 0.65462408]\n",
      "Epoch 99/5000, Loss: 14.959107713968491, Weights: [0.29276769 0.05260752 0.65462478]\n",
      "Epoch 100/5000, Loss: 14.959102484215977, Weights: [0.29276706 0.05260752 0.65462542]\n",
      "Epoch 101/5000, Loss: 14.959097773557664, Weights: [0.29276649 0.05260753 0.65462598]\n",
      "Epoch 102/5000, Loss: 14.959093530469115, Weights: [0.29276598 0.05260753 0.6546265 ]\n",
      "Epoch 103/5000, Loss: 14.959089708540164, Weights: [0.29276551 0.05260753 0.65462696]\n",
      "Epoch 104/5000, Loss: 14.959086265967283, Weights: [0.2927651  0.05260753 0.65462737]\n",
      "Epoch 105/5000, Loss: 14.95908316509632, Weights: [0.29276472 0.05260753 0.65462775]\n",
      "Epoch 106/5000, Loss: 14.959080372010614, Weights: [0.29276439 0.05260753 0.65462809]\n",
      "Epoch 107/5000, Loss: 14.959077856160024, Weights: [0.29276408 0.05260753 0.65462839]\n",
      "Epoch 108/5000, Loss: 14.959075590026783, Weights: [0.29276381 0.05260753 0.65462866]\n",
      "Epoch 109/5000, Loss: 14.959073548824488, Weights: [0.29276356 0.05260753 0.65462891]\n",
      "Epoch 110/5000, Loss: 14.959071710226976, Weights: [0.29276334 0.05260753 0.65462913]\n",
      "Epoch 111/5000, Loss: 14.959070054124165, Weights: [0.29276314 0.05260753 0.65462933]\n",
      "Epoch 112/5000, Loss: 14.95906856240204, Weights: [0.29276296 0.05260753 0.65462951]\n",
      "Epoch 113/5000, Loss: 14.959067218744556, Weights: [0.29276279 0.05260753 0.65462967]\n",
      "Epoch 114/5000, Loss: 14.959066008455164, Weights: [0.29276265 0.05260753 0.65462982]\n",
      "Epoch 115/5000, Loss: 14.959064918296066, Weights: [0.29276252 0.05260753 0.65462995]\n",
      "Epoch 116/5000, Loss: 14.959063936343412, Weights: [0.2927624  0.05260753 0.65463007]\n",
      "Epoch 117/5000, Loss: 14.959063051856887, Weights: [0.29276229 0.05260753 0.65463018]\n",
      "Epoch 118/5000, Loss: 14.959062255162264, Weights: [0.29276219 0.05260753 0.65463027]\n",
      "Epoch 119/5000, Loss: 14.959061537545514, Weights: [0.29276211 0.05260753 0.65463036]\n",
      "Epoch 120/5000, Loss: 14.959060891157568, Weights: [0.29276203 0.05260753 0.65463044]\n",
      "Epoch 121/5000, Loss: 14.959060308928432, Weights: [0.29276196 0.05260753 0.65463051]\n",
      "Epoch 122/5000, Loss: 14.959059784489872, Weights: [0.29276189 0.05260753 0.65463057]\n",
      "Epoch 123/5000, Loss: 14.959059312105724, Weights: [0.29276184 0.05260753 0.65463063]\n",
      "Epoch 124/5000, Loss: 14.959058886609215, Weights: [0.29276179 0.05260753 0.65463068]\n",
      "Epoch 125/5000, Loss: 14.959058503346391, Weights: [0.29276174 0.05260753 0.65463073]\n",
      "Epoch 126/5000, Loss: 14.95905815812524, Weights: [0.2927617  0.05260753 0.65463077]\n",
      "Epoch 127/5000, Loss: 14.959057847169843, Weights: [0.29276166 0.05260753 0.65463081]\n",
      "Epoch 128/5000, Loss: 14.959057567079073, Weights: [0.29276163 0.05260753 0.65463084]\n",
      "Epoch 129/5000, Loss: 14.959057314789389, Weights: [0.2927616  0.05260753 0.65463087]\n",
      "Epoch 130/5000, Loss: 14.959057087541321, Weights: [0.29276157 0.05260753 0.6546309 ]\n",
      "Epoch 131/5000, Loss: 14.959056882849302, Weights: [0.29276154 0.05260753 0.65463092]\n",
      "Epoch 132/5000, Loss: 14.959056698474484, Weights: [0.29276152 0.05260753 0.65463094]\n",
      "Epoch 133/5000, Loss: 14.959056532400233, Weights: [0.2927615  0.05260753 0.65463096]\n",
      "Epoch 134/5000, Loss: 14.959056382810072, Weights: [0.29276148 0.05260753 0.65463098]\n",
      "Epoch 135/5000, Loss: 14.959056248067846, Weights: [0.29276147 0.05260753 0.654631  ]\n",
      "Epoch 136/5000, Loss: 14.959056126699775, Weights: [0.29276145 0.05260753 0.65463101]\n",
      "Epoch 137/5000, Loss: 14.959056017378378, Weights: [0.29276144 0.05260753 0.65463103]\n",
      "Epoch 138/5000, Loss: 14.959055918907945, Weights: [0.29276143 0.05260753 0.65463104]\n",
      "Epoch 139/5000, Loss: 14.959055830211426, Weights: [0.29276142 0.05260753 0.65463105]\n",
      "Epoch 140/5000, Loss: 14.959055750318699, Weights: [0.29276141 0.05260753 0.65463106]\n",
      "Epoch 141/5000, Loss: 14.959055678355904, Weights: [0.2927614  0.05260753 0.65463107]\n",
      "Epoch 142/5000, Loss: 14.95905561353595, Weights: [0.29276139 0.05260753 0.65463108]\n",
      "Epoch 143/5000, Loss: 14.959055555149861, Weights: [0.29276138 0.05260753 0.65463108]\n",
      "Epoch 144/5000, Loss: 14.959055502559014, Weights: [0.29276138 0.05260753 0.65463109]\n",
      "Epoch 145/5000, Loss: 14.959055455188205, Weights: [0.29276137 0.05260753 0.65463109]\n",
      "Epoch 146/5000, Loss: 14.9590554125193, Weights: [0.29276137 0.05260753 0.6546311 ]\n",
      "Epoch 147/5000, Loss: 14.959055374085588, Weights: [0.29276136 0.05260753 0.6546311 ]\n",
      "Epoch 148/5000, Loss: 14.959055339466708, Weights: [0.29276136 0.05260753 0.65463111]\n",
      "Epoch 149/5000, Loss: 14.959055308284013, Weights: [0.29276135 0.05260753 0.65463111]\n",
      "Epoch 150/5000, Loss: 14.959055280196422, Weights: [0.29276135 0.05260753 0.65463112]\n",
      "Epoch 151/5000, Loss: 14.95905525489674, Weights: [0.29276135 0.05260753 0.65463112]\n",
      "Epoch 152/5000, Loss: 14.959055232108236, Weights: [0.29276134 0.05260753 0.65463112]\n",
      "Epoch 153/5000, Loss: 14.959055211581658, Weights: [0.29276134 0.05260753 0.65463112]\n",
      "Epoch 154/5000, Loss: 14.959055193092492, Weights: [0.29276134 0.05260753 0.65463113]\n",
      "Epoch 155/5000, Loss: 14.959055176438518, Weights: [0.29276134 0.05260753 0.65463113]\n",
      "Epoch 156/5000, Loss: 14.959055161437568, Weights: [0.29276134 0.05260753 0.65463113]\n",
      "Epoch 157/5000, Loss: 14.959055147925573, Weights: [0.29276133 0.05260753 0.65463113]\n",
      "Epoch 158/5000, Loss: 14.959055135754749, Weights: [0.29276133 0.05260753 0.65463113]\n",
      "Epoch 159/5000, Loss: 14.959055124791965, Weights: [0.29276133 0.05260753 0.65463113]\n",
      "Epoch 160/5000, Loss: 14.95905511491732, Weights: [0.29276133 0.05260753 0.65463114]\n",
      "Epoch 161/5000, Loss: 14.9590551060228, Weights: [0.29276133 0.05260753 0.65463114]\n",
      "Epoch 162/5000, Loss: 14.959055098011136, Weights: [0.29276133 0.05260753 0.65463114]\n",
      "Epoch 163/5000, Loss: 14.959055090794688, Weights: [0.29276133 0.05260753 0.65463114]\n",
      "Epoch 164/5000, Loss: 14.95905508429452, Weights: [0.29276133 0.05260753 0.65463114]\n",
      "Epoch 165/5000, Loss: 14.959055078439542, Weights: [0.29276133 0.05260753 0.65463114]\n",
      "Epoch 166/5000, Loss: 14.959055073165715, Weights: [0.29276133 0.05260753 0.65463114]\n",
      "Epoch 167/5000, Loss: 14.959055068415356, Weights: [0.29276132 0.05260753 0.65463114]\n",
      "Epoch 168/5000, Loss: 14.959055064136509, Weights: [0.29276132 0.05260753 0.65463114]\n",
      "Epoch 169/5000, Loss: 14.959055060282358, Weights: [0.29276132 0.05260753 0.65463114]\n",
      "Epoch 170/5000, Loss: 14.959055056810767, Weights: [0.29276132 0.05260753 0.65463114]\n",
      "Epoch 171/5000, Loss: 14.959055053683754, Weights: [0.29276132 0.05260753 0.65463114]\n",
      "Epoch 172/5000, Loss: 14.959055050867125, Weights: [0.29276132 0.05260753 0.65463114]\n",
      "Epoch 173/5000, Loss: 14.959055048330065, Weights: [0.29276132 0.05260753 0.65463114]\n",
      "Epoch 174/5000, Loss: 14.959055046044826, Weights: [0.29276132 0.05260753 0.65463114]\n",
      "Epoch 175/5000, Loss: 14.959055043986416, Weights: [0.29276132 0.05260753 0.65463114]\n",
      "Epoch 176/5000, Loss: 14.959055042132315, Weights: [0.29276132 0.05260753 0.65463114]\n",
      "Epoch 177/5000, Loss: 14.959055040462252, Weights: [0.29276132 0.05260753 0.65463114]\n",
      "Epoch 178/5000, Loss: 14.959055038957949, Weights: [0.29276132 0.05260753 0.65463114]\n",
      "Epoch 179/5000, Loss: 14.95905503760296, Weights: [0.29276132 0.05260753 0.65463114]\n",
      "Epoch 180/5000, Loss: 14.959055036382466, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 181/5000, Loss: 14.959055035283116, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 182/5000, Loss: 14.959055034292883, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 183/5000, Loss: 14.959055033400935, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 184/5000, Loss: 14.95905503259752, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 185/5000, Loss: 14.959055031873854, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 186/5000, Loss: 14.959055031222018, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 187/5000, Loss: 14.959055030634879, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 188/5000, Loss: 14.95905503010602, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 189/5000, Loss: 14.959055029629654, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 190/5000, Loss: 14.959055029200567, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 191/5000, Loss: 14.959055028814076, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 192/5000, Loss: 14.959055028465938, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 193/5000, Loss: 14.959055028152363, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 194/5000, Loss: 14.95905502786991, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 195/5000, Loss: 14.95905502761549, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 196/5000, Loss: 14.959055027386325, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 197/5000, Loss: 14.959055027179911, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 198/5000, Loss: 14.95905502699398, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 199/5000, Loss: 14.959055026826505, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 200/5000, Loss: 14.959055026675651, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 201/5000, Loss: 14.959055026539776, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 202/5000, Loss: 14.95905502641738, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 203/5000, Loss: 14.95905502630714, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 204/5000, Loss: 14.95905502620784, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 205/5000, Loss: 14.959055026118394, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 206/5000, Loss: 14.95905502603783, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 207/5000, Loss: 14.95905502596526, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 208/5000, Loss: 14.95905502589989, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 209/5000, Loss: 14.959055025841014, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 210/5000, Loss: 14.959055025787976, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 211/5000, Loss: 14.95905502574021, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 212/5000, Loss: 14.95905502569718, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 213/5000, Loss: 14.959055025658424, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 214/5000, Loss: 14.95905502562351, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 215/5000, Loss: 14.959055025592061, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 216/5000, Loss: 14.959055025563737, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 217/5000, Loss: 14.959055025538227, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 218/5000, Loss: 14.959055025515246, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 219/5000, Loss: 14.95905502549455, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 220/5000, Loss: 14.959055025475903, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 221/5000, Loss: 14.959055025459108, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 222/5000, Loss: 14.95905502544398, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 223/5000, Loss: 14.959055025430352, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 224/5000, Loss: 14.959055025418081, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 225/5000, Loss: 14.95905502540703, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 226/5000, Loss: 14.959055025397067, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 227/5000, Loss: 14.9590550253881, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 228/5000, Loss: 14.959055025380016, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 229/5000, Loss: 14.959055025372743, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 230/5000, Loss: 14.959055025366183, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 231/5000, Loss: 14.959055025360282, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 232/5000, Loss: 14.959055025354965, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 233/5000, Loss: 14.959055025350173, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 234/5000, Loss: 14.959055025345856, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 235/5000, Loss: 14.959055025341971, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 236/5000, Loss: 14.959055025338474, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 237/5000, Loss: 14.959055025335319, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 238/5000, Loss: 14.959055025332473, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 239/5000, Loss: 14.959055025329919, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 240/5000, Loss: 14.959055025327615, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 241/5000, Loss: 14.959055025325535, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 242/5000, Loss: 14.959055025323666, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 243/5000, Loss: 14.959055025321986, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 244/5000, Loss: 14.959055025320465, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 245/5000, Loss: 14.959055025319103, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 246/5000, Loss: 14.95905502531787, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 247/5000, Loss: 14.95905502531676, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 248/5000, Loss: 14.959055025315763, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 249/5000, Loss: 14.959055025314866, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 250/5000, Loss: 14.959055025314054, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 251/5000, Loss: 14.959055025313324, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 252/5000, Loss: 14.959055025312669, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 253/5000, Loss: 14.959055025312072, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 254/5000, Loss: 14.959055025311539, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 255/5000, Loss: 14.959055025311061, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 256/5000, Loss: 14.959055025310628, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 257/5000, Loss: 14.959055025310244, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 258/5000, Loss: 14.95905502530989, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 259/5000, Loss: 14.959055025309572, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 260/5000, Loss: 14.959055025309283, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 261/5000, Loss: 14.959055025309029, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 262/5000, Loss: 14.9590550253088, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 263/5000, Loss: 14.95905502530859, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 264/5000, Loss: 14.959055025308402, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 265/5000, Loss: 14.959055025308233, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 266/5000, Loss: 14.959055025308082, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 267/5000, Loss: 14.959055025307944, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 268/5000, Loss: 14.959055025307823, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 269/5000, Loss: 14.959055025307709, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 270/5000, Loss: 14.959055025307608, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 271/5000, Loss: 14.959055025307517, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 272/5000, Loss: 14.959055025307437, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 273/5000, Loss: 14.959055025307363, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 274/5000, Loss: 14.959055025307302, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 275/5000, Loss: 14.959055025307238, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 276/5000, Loss: 14.959055025307183, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 277/5000, Loss: 14.959055025307135, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 278/5000, Loss: 14.95905502530709, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 279/5000, Loss: 14.959055025307055, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 280/5000, Loss: 14.959055025307022, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 281/5000, Loss: 14.95905502530699, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 282/5000, Loss: 14.959055025306961, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 283/5000, Loss: 14.959055025306936, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 284/5000, Loss: 14.959055025306913, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 285/5000, Loss: 14.959055025306894, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 286/5000, Loss: 14.959055025306876, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 287/5000, Loss: 14.959055025306858, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 288/5000, Loss: 14.959055025306842, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 289/5000, Loss: 14.959055025306826, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 290/5000, Loss: 14.959055025306816, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 291/5000, Loss: 14.959055025306807, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 292/5000, Loss: 14.959055025306792, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 293/5000, Loss: 14.959055025306789, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 294/5000, Loss: 14.959055025306776, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 295/5000, Loss: 14.959055025306771, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 296/5000, Loss: 14.959055025306764, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 297/5000, Loss: 14.959055025306757, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 298/5000, Loss: 14.959055025306752, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 299/5000, Loss: 14.959055025306744, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 300/5000, Loss: 14.959055025306743, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 301/5000, Loss: 14.95905502530674, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 302/5000, Loss: 14.959055025306737, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 303/5000, Loss: 14.95905502530673, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 304/5000, Loss: 14.959055025306728, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 305/5000, Loss: 14.959055025306721, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 306/5000, Loss: 14.959055025306723, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 307/5000, Loss: 14.959055025306723, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 308/5000, Loss: 14.959055025306721, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 309/5000, Loss: 14.95905502530672, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 310/5000, Loss: 14.959055025306716, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 311/5000, Loss: 14.95905502530672, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 312/5000, Loss: 14.959055025306712, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 313/5000, Loss: 14.959055025306712, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 314/5000, Loss: 14.959055025306709, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 315/5000, Loss: 14.95905502530671, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 316/5000, Loss: 14.959055025306712, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 317/5000, Loss: 14.95905502530671, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 318/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 319/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 320/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 321/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 322/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 323/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 324/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 325/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 326/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 327/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 328/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 329/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 330/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 331/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 332/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 333/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 334/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 335/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 336/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 337/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 338/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 339/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 340/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 341/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 342/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 343/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 344/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 345/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 346/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 347/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 348/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 349/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 350/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 351/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 352/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 353/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 354/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 355/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 356/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 357/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 358/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 359/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 360/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 361/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 362/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 363/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 364/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 365/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 366/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 367/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 368/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 369/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 370/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 371/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 372/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 373/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 374/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 375/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 376/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 377/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 378/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 379/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 380/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 381/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 382/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 383/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 384/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 385/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 386/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 387/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 388/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 389/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 390/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 391/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 392/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 393/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 394/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 395/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 396/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 397/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 398/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 399/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 400/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 401/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 402/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 403/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 404/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 405/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 406/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 407/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 408/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 409/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 410/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 411/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 412/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 413/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 414/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 415/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 416/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 417/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 418/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 419/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 420/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 421/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 422/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 423/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 424/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 425/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 426/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 427/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 428/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 429/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 430/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 431/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 432/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 433/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 434/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 435/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 436/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 437/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 438/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 439/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 440/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 441/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 442/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 443/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 444/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 445/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 446/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 447/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 448/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 449/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 450/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 451/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 452/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 453/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 454/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 455/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 456/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 457/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 458/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 459/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 460/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 461/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 462/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 463/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 464/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 465/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 466/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 467/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 468/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 469/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 470/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 471/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 472/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 473/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 474/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 475/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 476/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 477/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 478/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 479/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 480/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 481/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 482/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 483/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 484/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 485/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 486/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 487/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 488/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 489/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 490/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 491/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 492/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 493/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 494/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 495/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 496/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 497/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 498/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 499/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 500/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 501/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 502/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 503/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 504/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 505/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 506/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 507/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 508/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 509/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 510/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 511/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 512/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 513/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 514/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 515/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 516/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 517/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 518/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 519/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 520/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 521/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 522/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 523/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 524/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 525/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 526/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 527/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 528/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 529/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 530/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 531/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 532/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 533/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 534/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 535/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 536/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 537/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 538/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 539/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 540/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 541/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 542/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 543/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 544/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 545/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 546/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 547/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 548/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 549/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 550/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 551/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 552/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 553/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 554/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 555/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 556/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 557/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 558/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 559/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 560/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 561/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 562/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 563/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 564/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 565/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 566/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 567/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 568/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 569/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 570/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 571/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 572/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 573/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 574/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 575/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 576/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 577/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 578/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 579/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 580/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 581/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 582/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 583/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 584/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 585/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 586/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 587/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 588/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 589/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 590/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 591/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 592/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 593/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 594/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 595/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 596/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 597/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 598/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 599/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 600/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 601/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 602/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 603/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 604/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 605/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 606/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 607/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 608/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 609/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 610/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 611/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 612/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 613/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 614/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 615/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 616/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 617/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 618/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 619/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 620/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 621/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 622/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 623/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 624/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 625/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 626/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 627/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 628/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 629/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 630/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 631/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 632/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 633/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 634/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 635/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 636/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 637/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 638/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 639/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 640/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 641/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 642/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 643/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 644/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 645/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 646/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 647/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 648/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 649/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 650/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 651/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 652/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 653/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 654/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 655/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 656/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 657/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 658/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 659/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 660/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 661/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 662/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 663/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 664/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 665/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 666/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 667/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 668/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 669/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 670/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 671/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 672/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 673/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 674/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 675/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 676/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 677/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 678/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 679/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 680/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 681/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 682/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 683/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 684/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 685/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 686/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 687/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 688/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 689/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 690/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 691/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 692/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 693/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 694/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 695/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 696/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 697/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 698/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 699/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 700/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 701/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 702/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 703/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 704/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 705/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 706/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 707/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 708/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 709/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 710/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 711/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 712/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 713/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 714/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 715/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 716/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 717/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 718/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 719/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 720/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 721/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 722/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 723/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 724/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 725/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 726/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 727/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 728/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 729/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 730/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 731/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 732/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 733/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 734/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 735/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 736/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 737/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 738/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 739/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 740/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 741/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 742/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 743/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 744/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 745/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 746/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 747/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 748/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 749/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 750/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 751/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 752/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 753/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 754/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 755/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 756/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 757/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 758/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 759/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 760/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 761/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 762/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 763/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 764/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 765/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 766/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 767/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 768/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 769/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 770/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 771/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 772/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 773/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 774/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 775/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 776/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 777/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 778/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 779/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 780/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 781/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 782/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 783/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 784/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 785/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 786/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 787/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 788/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 789/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 790/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 791/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 792/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 793/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 794/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 795/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 796/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 797/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 798/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 799/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 800/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 801/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 802/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 803/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 804/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 805/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 806/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 807/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 808/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 809/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 810/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 811/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 812/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 813/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 814/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 815/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 816/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 817/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 818/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 819/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 820/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 821/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 822/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 823/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 824/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 825/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 826/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 827/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 828/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 829/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 830/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 831/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 832/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 833/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 834/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 835/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 836/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 837/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 838/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 839/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 840/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 841/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 842/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 843/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 844/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 845/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 846/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 847/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 848/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 849/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 850/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 851/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 852/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 853/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 854/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 855/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 856/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 857/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 858/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 859/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 860/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 861/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 862/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 863/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 864/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 865/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 866/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 867/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 868/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 869/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 870/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 871/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 872/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 873/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 874/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 875/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 876/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 877/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 878/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 879/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 880/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 881/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 882/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 883/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 884/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 885/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 886/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 887/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 888/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 889/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 890/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 891/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 892/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 893/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 894/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 895/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 896/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 897/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 898/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 899/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 900/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 901/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 902/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 903/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 904/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 905/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 906/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 907/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 908/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 909/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 910/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 911/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 912/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 913/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 914/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 915/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 916/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 917/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 918/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 919/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 920/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 921/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 922/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 923/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 924/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 925/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 926/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 927/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 928/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 929/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 930/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 931/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 932/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 933/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 934/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 935/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 936/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 937/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 938/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 939/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 940/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 941/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 942/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 943/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 944/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 945/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 946/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 947/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 948/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 949/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 950/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 951/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 952/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 953/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 954/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 955/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 956/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 957/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 958/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 959/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 960/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 961/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 962/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 963/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 964/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 965/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 966/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 967/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 968/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 969/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 970/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 971/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 972/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 973/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 974/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 975/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 976/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 977/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 978/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 979/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 980/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 981/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 982/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 983/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 984/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 985/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 986/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 987/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 988/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 989/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 990/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 991/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 992/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 993/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 994/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 995/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 996/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 997/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 998/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 999/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1000/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1001/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1002/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1003/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1004/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1005/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1006/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1007/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1008/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1009/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1010/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1011/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1012/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1013/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1014/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1015/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1016/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1017/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1018/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1019/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1020/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1021/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1022/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1023/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1024/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1025/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1026/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1027/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1028/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1029/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1030/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1031/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1032/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1033/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1034/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1035/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1036/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1037/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1038/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1039/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1040/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1041/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1042/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1043/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1044/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1045/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1046/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1047/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1048/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1049/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1050/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1051/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1052/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1053/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1054/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1055/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1056/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1057/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1058/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1059/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1060/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1061/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1062/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1063/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1064/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1065/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1066/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1067/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1068/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1069/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1070/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1071/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1072/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1073/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1074/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1075/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1076/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1077/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1078/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1079/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1080/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1081/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1082/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1083/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1084/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1085/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1086/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1087/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1088/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1089/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1090/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1091/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1092/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1093/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1094/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1095/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1096/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1097/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1098/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1099/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1100/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1101/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1102/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1103/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1104/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1105/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1106/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1107/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1108/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1109/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1110/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1111/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1112/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1113/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1114/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1115/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1116/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1117/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1118/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1119/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1120/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1121/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1122/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1123/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1124/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1125/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1126/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1127/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1128/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1129/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1130/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1131/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1132/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1133/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1134/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1135/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1136/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1137/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1138/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1139/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1140/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1141/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1142/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1143/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1144/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1145/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1146/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1147/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1148/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1149/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1150/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1151/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1152/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1153/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1154/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1155/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1156/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1157/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1158/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1159/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1160/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1161/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1162/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1163/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1164/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1165/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1166/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1167/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1168/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1169/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1170/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1171/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1172/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1173/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1174/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1175/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1176/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1177/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1178/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1179/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1180/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1181/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1182/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1183/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1184/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1185/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1186/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1187/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1188/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1189/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1190/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1191/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1192/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1193/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1194/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1195/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1196/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1197/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1198/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1199/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1200/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1201/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1202/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1203/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1204/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1205/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1206/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1207/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1208/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1209/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1210/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1211/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1212/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1213/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1214/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1215/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1216/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1217/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1218/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1219/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1220/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1221/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1222/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1223/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1224/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1225/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1226/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1227/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1228/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1229/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1230/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1231/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1232/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1233/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1234/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1235/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1236/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1237/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1238/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1239/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1240/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1241/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1242/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1243/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1244/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1245/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1246/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1247/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1248/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1249/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1250/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1251/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1252/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1253/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1254/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1255/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1256/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1257/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1258/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1259/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1260/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1261/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1262/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1263/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1264/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1265/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1266/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1267/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1268/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1269/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1270/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1271/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1272/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1273/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1274/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1275/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1276/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1277/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1278/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1279/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1280/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1281/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1282/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1283/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1284/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1285/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1286/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1287/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1288/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1289/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1290/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1291/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1292/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1293/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1294/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1295/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1296/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1297/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1298/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1299/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1300/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1301/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1302/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1303/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1304/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1305/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1306/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1307/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1308/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1309/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1310/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1311/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1312/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1313/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1314/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1315/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1316/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1317/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1318/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1319/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1320/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1321/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1322/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1323/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1324/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1325/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1326/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1327/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1328/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1329/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1330/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1331/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1332/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1333/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1334/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1335/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1336/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1337/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1338/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1339/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1340/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1341/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1342/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1343/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1344/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1345/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1346/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1347/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1348/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1349/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1350/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1351/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1352/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1353/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1354/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1355/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1356/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1357/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1358/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1359/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1360/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1361/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1362/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1363/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1364/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1365/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1366/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1367/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1368/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1369/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1370/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1371/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1372/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1373/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1374/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1375/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1376/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1377/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1378/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1379/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1380/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1381/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1382/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1383/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1384/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1385/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1386/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1387/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1388/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1389/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1390/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1391/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1392/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1393/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1394/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1395/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1396/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1397/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1398/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1399/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1400/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1401/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1402/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1403/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1404/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1405/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1406/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1407/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1408/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1409/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1410/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1411/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1412/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1413/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1414/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1415/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1416/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1417/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1418/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1419/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1420/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1421/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1422/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1423/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1424/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1425/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1426/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1427/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1428/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1429/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1430/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1431/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1432/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1433/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1434/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1435/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1436/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1437/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1438/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1439/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1440/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1441/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1442/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1443/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1444/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1445/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1446/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1447/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1448/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1449/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1450/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1451/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1452/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1453/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1454/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1455/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1456/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1457/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1458/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1459/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1460/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1461/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1462/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1463/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1464/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1465/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1466/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1467/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1468/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1469/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1470/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1471/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1472/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1473/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1474/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1475/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1476/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1477/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1478/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1479/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1480/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1481/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1482/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1483/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1484/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1485/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1486/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1487/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1488/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1489/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1490/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1491/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1492/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1493/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1494/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1495/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1496/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1497/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1498/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1499/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1500/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1501/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1502/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1503/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1504/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1505/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1506/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1507/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1508/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1509/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1510/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1511/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1512/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1513/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1514/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1515/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1516/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1517/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1518/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1519/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1520/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1521/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1522/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1523/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1524/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1525/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1526/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1527/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1528/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1529/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1530/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1531/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1532/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1533/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1534/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1535/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1536/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1537/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1538/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1539/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1540/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1541/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1542/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1543/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1544/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1545/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1546/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1547/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1548/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1549/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1550/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1551/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1552/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1553/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1554/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1555/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1556/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1557/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1558/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1559/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1560/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1561/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1562/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1563/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1564/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1565/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1566/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1567/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1568/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1569/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1570/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1571/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1572/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1573/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1574/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1575/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1576/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1577/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1578/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1579/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1580/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1581/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1582/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1583/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1584/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1585/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1586/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1587/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1588/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1589/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1590/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1591/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1592/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1593/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1594/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1595/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1596/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1597/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1598/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1599/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1600/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1601/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1602/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1603/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1604/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1605/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1606/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1607/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1608/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1609/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1610/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1611/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1612/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1613/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1614/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1615/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1616/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1617/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1618/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1619/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1620/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1621/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1622/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1623/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1624/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1625/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1626/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1627/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1628/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1629/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1630/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1631/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1632/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1633/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1634/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1635/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1636/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1637/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1638/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1639/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1640/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1641/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1642/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1643/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1644/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1645/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1646/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1647/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1648/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1649/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1650/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1651/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1652/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1653/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1654/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1655/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1656/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1657/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1658/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1659/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1660/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1661/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1662/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1663/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1664/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1665/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1666/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1667/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1668/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1669/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1670/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1671/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1672/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1673/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1674/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1675/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1676/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1677/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1678/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1679/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1680/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1681/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1682/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1683/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1684/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1685/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1686/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1687/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1688/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1689/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1690/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1691/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1692/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1693/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1694/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1695/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1696/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1697/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1698/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1699/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1700/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1701/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1702/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1703/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1704/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1705/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1706/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1707/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1708/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1709/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1710/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1711/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1712/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1713/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1714/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1715/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1716/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1717/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1718/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1719/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1720/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1721/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1722/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1723/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1724/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1725/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1726/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1727/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1728/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1729/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1730/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1731/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1732/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1733/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1734/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1735/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1736/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1737/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1738/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1739/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1740/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1741/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1742/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1743/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1744/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1745/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1746/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1747/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1748/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1749/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1750/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1751/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1752/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1753/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1754/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1755/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1756/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1757/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1758/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1759/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1760/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1761/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1762/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1763/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1764/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1765/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1766/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1767/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1768/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1769/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1770/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1771/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1772/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1773/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1774/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1775/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1776/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1777/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1778/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1779/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1780/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1781/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1782/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1783/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1784/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1785/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1786/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1787/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1788/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1789/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1790/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1791/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1792/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1793/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1794/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1795/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1796/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1797/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1798/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1799/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1800/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1801/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1802/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1803/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1804/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1805/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1806/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1807/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1808/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1809/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1810/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1811/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1812/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1813/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1814/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1815/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1816/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1817/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1818/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1819/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1820/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1821/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1822/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1823/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1824/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1825/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1826/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1827/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1828/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1829/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1830/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1831/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1832/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1833/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1834/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1835/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1836/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1837/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1838/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1839/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1840/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1841/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1842/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1843/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1844/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1845/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1846/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1847/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1848/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1849/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1850/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1851/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1852/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1853/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1854/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1855/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1856/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1857/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1858/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1859/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1860/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1861/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1862/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1863/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1864/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1865/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1866/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1867/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1868/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1869/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1870/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1871/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1872/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1873/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1874/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1875/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1876/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1877/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1878/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1879/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1880/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1881/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1882/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1883/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1884/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1885/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1886/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1887/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1888/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1889/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1890/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1891/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1892/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1893/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1894/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1895/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1896/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1897/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1898/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1899/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1900/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1901/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1902/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1903/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1904/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1905/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1906/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1907/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1908/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1909/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1910/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1911/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1912/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1913/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1914/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1915/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1916/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1917/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1918/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1919/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1920/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1921/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1922/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1923/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1924/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1925/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1926/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1927/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1928/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1929/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1930/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1931/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1932/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1933/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1934/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1935/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1936/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1937/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1938/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1939/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1940/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1941/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1942/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1943/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1944/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1945/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1946/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1947/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1948/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1949/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1950/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1951/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1952/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1953/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1954/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1955/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1956/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1957/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1958/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1959/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1960/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1961/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1962/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1963/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1964/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1965/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1966/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1967/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1968/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1969/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1970/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1971/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1972/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1973/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1974/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1975/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1976/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1977/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1978/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1979/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1980/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1981/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1982/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1983/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1984/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1985/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1986/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1987/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1988/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1989/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1990/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1991/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1992/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1993/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1994/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1995/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1996/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1997/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1998/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 1999/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2000/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2001/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2002/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2003/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2004/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2005/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2006/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2007/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2008/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2009/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2010/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2011/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2012/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2013/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2014/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2015/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2016/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2017/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2018/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2019/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2020/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2021/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2022/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2023/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2024/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2025/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2026/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2027/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2028/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2029/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2030/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2031/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2032/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2033/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2034/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2035/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2036/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2037/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2038/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2039/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2040/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2041/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2042/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2043/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2044/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2045/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2046/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2047/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2048/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2049/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2050/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2051/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2052/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2053/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2054/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2055/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2056/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2057/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2058/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2059/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2060/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2061/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2062/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2063/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2064/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2065/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2066/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2067/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2068/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2069/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2070/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2071/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2072/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2073/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2074/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2075/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2076/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2077/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2078/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2079/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2080/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2081/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2082/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2083/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2084/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2085/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2086/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2087/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2088/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2089/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2090/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2091/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2092/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2093/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2094/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2095/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2096/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2097/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2098/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2099/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2100/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2101/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2102/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2103/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2104/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2105/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2106/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2107/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2108/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2109/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2110/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2111/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2112/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2113/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2114/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2115/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2116/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2117/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2118/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2119/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2120/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2121/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2122/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2123/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2124/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2125/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2126/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2127/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2128/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2129/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2130/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2131/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2132/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2133/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2134/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2135/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2136/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2137/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2138/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2139/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2140/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2141/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2142/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2143/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2144/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2145/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2146/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2147/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2148/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2149/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2150/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2151/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2152/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2153/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2154/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2155/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2156/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2157/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2158/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2159/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2160/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2161/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2162/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2163/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2164/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2165/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2166/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2167/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2168/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2169/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2170/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2171/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2172/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2173/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2174/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2175/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2176/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2177/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2178/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2179/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2180/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2181/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2182/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2183/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2184/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2185/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2186/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2187/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2188/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2189/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2190/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2191/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2192/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2193/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2194/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2195/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2196/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2197/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2198/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2199/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2200/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2201/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2202/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2203/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2204/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2205/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2206/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2207/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2208/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2209/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2210/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2211/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2212/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2213/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2214/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2215/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2216/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2217/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2218/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2219/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2220/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2221/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2222/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2223/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2224/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2225/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2226/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2227/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2228/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2229/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2230/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2231/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2232/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2233/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2234/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2235/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2236/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2237/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2238/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2239/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2240/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2241/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2242/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2243/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2244/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2245/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2246/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2247/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2248/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2249/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2250/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2251/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2252/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2253/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2254/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2255/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2256/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2257/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2258/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2259/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2260/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2261/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2262/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2263/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2264/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2265/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2266/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2267/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2268/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2269/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2270/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2271/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2272/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2273/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2274/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2275/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2276/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2277/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2278/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2279/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2280/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2281/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2282/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2283/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2284/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2285/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2286/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2287/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2288/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2289/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2290/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2291/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2292/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2293/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2294/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2295/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2296/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2297/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2298/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2299/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2300/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2301/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2302/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2303/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2304/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2305/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2306/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2307/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2308/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2309/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2310/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2311/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2312/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2313/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2314/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2315/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2316/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2317/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2318/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2319/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2320/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2321/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2322/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2323/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2324/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2325/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2326/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2327/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2328/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2329/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2330/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2331/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2332/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2333/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2334/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2335/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2336/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2337/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2338/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2339/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2340/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2341/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2342/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2343/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2344/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2345/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2346/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2347/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2348/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2349/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2350/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2351/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2352/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2353/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2354/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2355/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2356/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2357/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2358/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2359/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2360/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2361/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2362/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2363/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2364/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2365/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2366/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2367/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2368/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2369/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2370/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2371/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2372/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2373/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2374/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2375/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2376/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2377/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2378/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2379/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2380/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2381/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2382/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2383/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2384/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2385/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2386/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2387/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2388/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2389/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2390/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2391/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2392/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2393/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2394/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2395/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2396/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2397/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2398/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2399/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2400/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2401/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2402/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2403/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2404/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2405/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2406/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2407/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2408/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2409/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2410/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2411/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2412/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2413/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2414/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2415/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2416/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2417/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2418/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2419/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2420/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2421/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2422/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2423/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2424/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2425/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2426/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2427/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2428/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2429/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2430/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2431/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2432/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2433/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2434/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2435/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2436/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2437/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2438/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2439/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2440/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2441/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2442/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2443/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2444/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2445/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2446/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2447/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2448/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2449/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2450/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2451/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2452/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2453/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2454/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2455/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2456/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2457/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2458/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2459/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2460/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2461/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2462/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2463/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2464/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2465/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2466/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2467/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2468/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2469/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2470/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2471/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2472/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2473/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2474/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2475/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2476/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2477/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2478/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2479/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2480/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2481/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2482/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2483/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2484/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2485/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2486/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2487/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2488/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2489/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2490/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2491/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2492/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2493/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2494/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2495/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2496/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2497/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2498/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2499/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2500/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2501/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2502/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2503/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2504/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2505/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2506/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2507/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2508/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2509/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2510/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2511/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2512/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2513/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2514/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2515/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2516/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2517/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2518/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2519/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2520/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2521/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2522/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2523/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2524/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2525/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2526/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2527/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2528/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2529/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2530/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2531/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2532/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2533/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2534/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2535/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2536/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2537/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2538/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2539/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2540/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2541/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2542/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2543/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2544/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2545/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2546/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2547/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2548/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2549/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2550/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2551/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2552/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2553/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2554/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2555/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2556/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2557/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2558/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2559/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2560/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2561/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2562/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2563/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2564/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2565/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2566/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2567/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2568/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2569/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2570/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2571/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2572/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2573/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2574/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2575/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2576/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2577/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2578/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2579/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2580/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2581/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2582/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2583/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2584/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2585/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2586/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2587/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2588/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2589/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2590/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2591/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2592/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2593/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2594/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2595/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2596/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2597/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2598/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2599/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2600/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2601/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2602/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2603/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2604/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2605/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2606/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2607/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2608/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2609/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2610/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2611/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2612/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2613/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2614/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2615/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2616/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2617/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2618/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2619/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2620/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2621/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2622/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2623/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2624/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2625/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2626/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2627/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2628/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2629/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2630/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2631/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2632/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2633/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2634/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2635/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2636/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2637/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2638/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2639/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2640/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2641/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2642/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2643/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2644/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2645/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2646/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2647/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2648/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2649/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2650/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2651/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2652/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2653/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2654/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2655/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2656/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2657/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2658/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2659/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2660/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2661/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2662/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2663/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2664/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2665/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2666/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2667/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2668/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2669/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2670/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2671/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2672/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2673/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2674/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2675/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2676/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2677/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2678/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2679/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2680/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2681/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2682/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2683/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2684/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2685/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2686/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2687/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2688/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2689/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2690/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2691/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2692/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2693/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2694/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2695/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2696/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2697/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2698/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2699/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2700/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2701/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2702/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2703/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2704/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2705/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2706/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2707/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2708/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2709/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2710/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2711/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2712/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2713/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2714/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2715/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2716/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2717/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2718/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2719/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2720/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2721/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2722/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2723/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2724/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2725/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2726/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2727/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2728/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2729/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2730/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2731/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2732/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2733/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2734/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2735/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2736/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2737/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2738/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2739/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2740/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2741/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2742/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2743/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2744/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2745/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2746/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2747/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2748/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2749/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2750/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2751/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2752/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2753/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2754/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2755/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2756/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2757/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2758/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2759/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2760/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2761/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2762/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2763/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2764/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2765/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2766/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2767/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2768/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2769/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2770/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2771/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2772/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2773/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2774/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2775/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2776/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2777/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2778/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2779/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2780/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2781/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2782/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2783/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2784/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2785/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2786/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2787/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2788/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2789/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2790/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2791/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2792/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2793/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2794/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2795/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2796/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2797/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2798/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2799/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2800/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2801/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2802/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2803/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2804/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2805/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2806/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2807/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2808/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2809/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2810/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2811/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2812/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2813/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2814/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2815/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2816/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2817/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2818/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2819/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2820/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2821/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2822/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2823/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2824/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2825/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2826/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2827/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2828/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2829/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2830/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2831/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2832/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2833/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2834/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2835/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2836/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2837/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2838/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2839/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2840/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2841/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2842/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2843/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2844/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2845/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2846/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2847/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2848/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2849/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2850/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2851/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2852/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2853/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2854/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2855/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2856/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2857/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2858/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2859/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2860/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2861/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2862/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2863/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2864/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2865/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2866/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2867/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2868/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2869/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2870/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2871/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2872/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2873/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2874/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2875/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2876/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2877/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2878/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2879/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2880/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2881/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2882/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2883/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2884/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2885/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2886/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2887/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2888/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2889/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2890/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2891/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2892/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2893/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2894/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2895/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2896/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2897/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2898/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2899/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2900/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2901/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2902/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2903/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2904/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2905/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2906/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2907/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2908/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2909/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2910/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2911/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2912/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2913/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2914/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2915/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2916/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2917/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2918/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2919/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2920/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2921/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2922/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2923/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2924/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2925/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2926/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2927/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2928/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2929/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2930/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2931/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2932/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2933/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2934/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2935/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2936/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2937/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2938/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2939/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2940/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2941/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2942/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2943/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2944/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2945/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2946/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2947/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2948/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2949/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2950/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2951/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2952/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2953/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2954/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2955/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2956/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2957/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2958/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2959/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2960/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2961/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2962/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2963/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2964/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2965/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2966/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2967/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2968/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2969/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2970/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2971/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2972/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2973/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2974/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2975/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2976/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2977/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2978/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2979/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2980/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2981/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2982/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2983/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2984/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2985/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2986/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2987/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2988/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2989/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2990/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2991/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2992/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2993/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2994/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2995/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2996/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2997/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2998/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 2999/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3000/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3001/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3002/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3003/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3004/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3005/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3006/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3007/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3008/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3009/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3010/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3011/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3012/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3013/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3014/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3015/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3016/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3017/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3018/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3019/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3020/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3021/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3022/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3023/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3024/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3025/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3026/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3027/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3028/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3029/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3030/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3031/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3032/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3033/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3034/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3035/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3036/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3037/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3038/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3039/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3040/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3041/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3042/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3043/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3044/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3045/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3046/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3047/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3048/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3049/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3050/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3051/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3052/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3053/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3054/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3055/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3056/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3057/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3058/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3059/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3060/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3061/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3062/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3063/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3064/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3065/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3066/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3067/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3068/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3069/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3070/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3071/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3072/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3073/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3074/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3075/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3076/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3077/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3078/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3079/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3080/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3081/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3082/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3083/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3084/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3085/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3086/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3087/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3088/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3089/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3090/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3091/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3092/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3093/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3094/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3095/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3096/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3097/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3098/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3099/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3100/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3101/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3102/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3103/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3104/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3105/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3106/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3107/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3108/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3109/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3110/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3111/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3112/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3113/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3114/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3115/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3116/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3117/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3118/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3119/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3120/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3121/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3122/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3123/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3124/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3125/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3126/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3127/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3128/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3129/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3130/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3131/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3132/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3133/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3134/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3135/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3136/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3137/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3138/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3139/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3140/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3141/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3142/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3143/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3144/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3145/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3146/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3147/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3148/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3149/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3150/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3151/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3152/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3153/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3154/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3155/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3156/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3157/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3158/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3159/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3160/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3161/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3162/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3163/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3164/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3165/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3166/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3167/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3168/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3169/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3170/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3171/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3172/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3173/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3174/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3175/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3176/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3177/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3178/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3179/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3180/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3181/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3182/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3183/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3184/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3185/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3186/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3187/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3188/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3189/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3190/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3191/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3192/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3193/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3194/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3195/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3196/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3197/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3198/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3199/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3200/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3201/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3202/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3203/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3204/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3205/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3206/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3207/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3208/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3209/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3210/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3211/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3212/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3213/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3214/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3215/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3216/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3217/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3218/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3219/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3220/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3221/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3222/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3223/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3224/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3225/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3226/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3227/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3228/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3229/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3230/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3231/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3232/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3233/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3234/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3235/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3236/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3237/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3238/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3239/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3240/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3241/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3242/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3243/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3244/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3245/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3246/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3247/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3248/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3249/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3250/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3251/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3252/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3253/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3254/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3255/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3256/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3257/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3258/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3259/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3260/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3261/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3262/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3263/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3264/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3265/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3266/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3267/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3268/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3269/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3270/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3271/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3272/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3273/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3274/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3275/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3276/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3277/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3278/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3279/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3280/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3281/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3282/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3283/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3284/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3285/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3286/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3287/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3288/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3289/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3290/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3291/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3292/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3293/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3294/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3295/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3296/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3297/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3298/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3299/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3300/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3301/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3302/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3303/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3304/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3305/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3306/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3307/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3308/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3309/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3310/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3311/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3312/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3313/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3314/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3315/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3316/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3317/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3318/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3319/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3320/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3321/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3322/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3323/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3324/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3325/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3326/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3327/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3328/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3329/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3330/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3331/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3332/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3333/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3334/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3335/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3336/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3337/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3338/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3339/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3340/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3341/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3342/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3343/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3344/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3345/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3346/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3347/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3348/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3349/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3350/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3351/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3352/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3353/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3354/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3355/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3356/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3357/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3358/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3359/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3360/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3361/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3362/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3363/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3364/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3365/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3366/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3367/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3368/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3369/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3370/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3371/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3372/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3373/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3374/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3375/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3376/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3377/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3378/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3379/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3380/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3381/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3382/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3383/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3384/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3385/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3386/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3387/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3388/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3389/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3390/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3391/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3392/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3393/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3394/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3395/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3396/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3397/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3398/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3399/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3400/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3401/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3402/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3403/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3404/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3405/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3406/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3407/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3408/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3409/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3410/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3411/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3412/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3413/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3414/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3415/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3416/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3417/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3418/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3419/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3420/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3421/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3422/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3423/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3424/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3425/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3426/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3427/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3428/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3429/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3430/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3431/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3432/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3433/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3434/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3435/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3436/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3437/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3438/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3439/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3440/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3441/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3442/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3443/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3444/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3445/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3446/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3447/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3448/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3449/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3450/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3451/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3452/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3453/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3454/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3455/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3456/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3457/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3458/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3459/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3460/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3461/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3462/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3463/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3464/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3465/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3466/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3467/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3468/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3469/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3470/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3471/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3472/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3473/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3474/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3475/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3476/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3477/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3478/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3479/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3480/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3481/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3482/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3483/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3484/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3485/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3486/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3487/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3488/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3489/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3490/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3491/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3492/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3493/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3494/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3495/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3496/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3497/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3498/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3499/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3500/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3501/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3502/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3503/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3504/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3505/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3506/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3507/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3508/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3509/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3510/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3511/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3512/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3513/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3514/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3515/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3516/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3517/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3518/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3519/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3520/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3521/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3522/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3523/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3524/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3525/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3526/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3527/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3528/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3529/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3530/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3531/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3532/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3533/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3534/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3535/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3536/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3537/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3538/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3539/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3540/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3541/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3542/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3543/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3544/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3545/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3546/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3547/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3548/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3549/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3550/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3551/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3552/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3553/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3554/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3555/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3556/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3557/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3558/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3559/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3560/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3561/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3562/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3563/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3564/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3565/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3566/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3567/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3568/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3569/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3570/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3571/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3572/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3573/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3574/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3575/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3576/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3577/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3578/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3579/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3580/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3581/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3582/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3583/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3584/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3585/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3586/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3587/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3588/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3589/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3590/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3591/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3592/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3593/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3594/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3595/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3596/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3597/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3598/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3599/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3600/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3601/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3602/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3603/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3604/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3605/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3606/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3607/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3608/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3609/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3610/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3611/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3612/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3613/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3614/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3615/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3616/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3617/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3618/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3619/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3620/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3621/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3622/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3623/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3624/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3625/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3626/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3627/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3628/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3629/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3630/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3631/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3632/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3633/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3634/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3635/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3636/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3637/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3638/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3639/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3640/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3641/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3642/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3643/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3644/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3645/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3646/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3647/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3648/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3649/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3650/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3651/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3652/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3653/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3654/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3655/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3656/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3657/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3658/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3659/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3660/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3661/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3662/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3663/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3664/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3665/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3666/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3667/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3668/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3669/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3670/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3671/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3672/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3673/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3674/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3675/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3676/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3677/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3678/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3679/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3680/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3681/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3682/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3683/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3684/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3685/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3686/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3687/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3688/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3689/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3690/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3691/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3692/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3693/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3694/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3695/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3696/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3697/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3698/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3699/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3700/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3701/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3702/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3703/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3704/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3705/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3706/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3707/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3708/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3709/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3710/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3711/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3712/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3713/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3714/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3715/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3716/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3717/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3718/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3719/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3720/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3721/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3722/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3723/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3724/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3725/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3726/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3727/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3728/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3729/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3730/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3731/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3732/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3733/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3734/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3735/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3736/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3737/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3738/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3739/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3740/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3741/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3742/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3743/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3744/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3745/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3746/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3747/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3748/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3749/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3750/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3751/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3752/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3753/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3754/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3755/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3756/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3757/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3758/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3759/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3760/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3761/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3762/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3763/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3764/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3765/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3766/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3767/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3768/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3769/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3770/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3771/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3772/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3773/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3774/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3775/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3776/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3777/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3778/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3779/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3780/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3781/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3782/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3783/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3784/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3785/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3786/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3787/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3788/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3789/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3790/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3791/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3792/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3793/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3794/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3795/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3796/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3797/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3798/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3799/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3800/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3801/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3802/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3803/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3804/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3805/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3806/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3807/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3808/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3809/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3810/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3811/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3812/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3813/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3814/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3815/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3816/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3817/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3818/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3819/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3820/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3821/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3822/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3823/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3824/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3825/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3826/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3827/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3828/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3829/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3830/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3831/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3832/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3833/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3834/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3835/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3836/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3837/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3838/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3839/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3840/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3841/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3842/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3843/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3844/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3845/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3846/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3847/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3848/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3849/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3850/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3851/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3852/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3853/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3854/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3855/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3856/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3857/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3858/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3859/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3860/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3861/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3862/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3863/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3864/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3865/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3866/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3867/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3868/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3869/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3870/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3871/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3872/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3873/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3874/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3875/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3876/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3877/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3878/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3879/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3880/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3881/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3882/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3883/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3884/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3885/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3886/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3887/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3888/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3889/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3890/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3891/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3892/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3893/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3894/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3895/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3896/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3897/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3898/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3899/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3900/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3901/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3902/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3903/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3904/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3905/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3906/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3907/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3908/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3909/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3910/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3911/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3912/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3913/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3914/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3915/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3916/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3917/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3918/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3919/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3920/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3921/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3922/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3923/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3924/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3925/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3926/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3927/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3928/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3929/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3930/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3931/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3932/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3933/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3934/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3935/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3936/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3937/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3938/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3939/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3940/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3941/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3942/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3943/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3944/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3945/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3946/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3947/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3948/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3949/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3950/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3951/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3952/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3953/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3954/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3955/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3956/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3957/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3958/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3959/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3960/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3961/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3962/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3963/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3964/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3965/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3966/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3967/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3968/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3969/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3970/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3971/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3972/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3973/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3974/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3975/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3976/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3977/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3978/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3979/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3980/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3981/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3982/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3983/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3984/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3985/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3986/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3987/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3988/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3989/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3990/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3991/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3992/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3993/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3994/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3995/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3996/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3997/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3998/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 3999/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4000/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4001/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4002/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4003/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4004/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4005/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4006/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4007/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4008/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4009/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4010/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4011/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4012/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4013/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4014/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4015/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4016/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4017/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4018/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4019/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4020/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4021/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4022/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4023/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4024/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4025/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4026/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4027/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4028/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4029/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4030/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4031/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4032/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4033/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4034/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4035/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4036/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4037/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4038/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4039/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4040/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4041/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4042/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4043/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4044/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4045/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4046/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4047/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4048/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4049/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4050/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4051/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4052/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4053/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4054/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4055/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4056/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4057/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4058/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4059/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4060/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4061/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4062/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4063/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4064/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4065/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4066/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4067/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4068/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4069/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4070/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4071/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4072/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4073/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4074/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4075/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4076/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4077/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4078/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4079/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4080/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4081/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4082/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4083/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4084/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4085/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4086/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4087/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4088/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4089/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4090/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4091/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4092/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4093/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4094/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4095/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4096/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4097/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4098/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4099/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4100/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4101/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4102/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4103/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4104/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4105/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4106/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4107/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4108/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4109/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4110/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4111/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4112/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4113/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4114/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4115/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4116/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4117/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4118/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4119/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4120/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4121/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4122/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4123/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4124/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4125/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4126/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4127/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4128/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4129/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4130/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4131/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4132/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4133/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4134/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4135/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4136/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4137/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4138/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4139/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4140/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4141/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4142/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4143/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4144/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4145/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4146/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4147/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4148/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4149/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4150/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4151/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4152/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4153/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4154/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4155/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4156/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4157/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4158/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4159/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4160/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4161/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4162/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4163/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4164/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4165/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4166/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4167/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4168/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4169/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4170/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4171/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4172/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4173/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4174/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4175/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4176/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4177/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4178/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4179/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4180/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4181/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4182/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4183/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4184/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4185/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4186/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4187/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4188/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4189/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4190/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4191/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4192/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4193/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4194/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4195/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4196/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4197/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4198/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4199/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4200/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4201/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4202/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4203/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4204/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4205/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4206/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4207/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4208/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4209/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4210/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4211/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4212/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4213/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4214/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4215/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4216/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4217/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4218/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4219/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4220/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4221/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4222/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4223/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4224/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4225/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4226/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4227/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4228/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4229/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4230/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4231/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4232/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4233/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4234/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4235/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4236/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4237/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4238/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4239/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4240/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4241/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4242/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4243/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4244/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4245/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4246/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4247/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4248/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4249/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4250/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4251/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4252/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4253/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4254/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4255/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4256/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4257/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4258/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4259/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4260/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4261/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4262/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4263/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4264/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4265/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4266/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4267/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4268/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4269/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4270/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4271/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4272/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4273/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4274/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4275/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4276/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4277/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4278/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4279/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4280/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4281/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4282/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4283/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4284/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4285/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4286/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4287/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4288/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4289/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4290/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4291/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4292/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4293/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4294/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4295/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4296/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4297/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4298/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4299/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4300/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4301/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4302/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4303/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4304/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4305/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4306/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4307/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4308/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4309/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4310/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4311/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4312/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4313/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4314/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4315/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4316/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4317/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4318/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4319/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4320/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4321/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4322/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4323/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4324/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4325/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4326/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4327/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4328/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4329/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4330/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4331/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4332/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4333/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4334/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4335/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4336/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4337/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4338/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4339/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4340/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4341/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4342/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4343/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4344/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4345/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4346/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4347/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4348/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4349/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4350/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4351/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4352/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4353/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4354/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4355/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4356/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4357/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4358/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4359/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4360/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4361/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4362/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4363/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4364/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4365/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4366/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4367/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4368/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4369/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4370/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4371/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4372/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4373/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4374/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4375/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4376/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4377/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4378/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4379/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4380/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4381/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4382/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4383/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4384/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4385/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4386/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4387/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4388/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4389/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4390/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4391/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4392/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4393/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4394/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4395/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4396/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4397/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4398/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4399/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4400/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4401/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4402/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4403/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4404/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4405/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4406/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4407/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4408/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4409/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4410/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4411/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4412/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4413/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4414/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4415/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4416/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4417/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4418/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4419/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4420/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4421/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4422/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4423/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4424/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4425/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4426/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4427/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4428/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4429/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4430/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4431/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4432/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4433/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4434/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4435/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4436/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4437/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4438/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4439/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4440/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4441/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4442/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4443/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4444/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4445/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4446/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4447/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4448/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4449/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4450/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4451/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4452/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4453/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4454/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4455/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4456/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4457/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4458/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4459/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4460/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4461/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4462/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4463/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4464/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4465/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4466/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4467/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4468/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4469/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4470/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4471/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4472/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4473/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4474/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4475/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4476/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4477/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4478/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4479/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4480/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4481/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4482/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4483/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4484/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4485/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4486/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4487/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4488/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4489/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4490/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4491/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4492/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4493/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4494/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4495/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4496/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4497/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4498/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4499/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4500/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4501/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4502/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4503/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4504/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4505/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4506/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4507/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4508/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4509/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4510/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4511/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4512/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4513/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4514/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4515/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4516/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4517/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4518/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4519/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4520/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4521/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4522/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4523/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4524/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4525/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4526/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4527/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4528/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4529/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4530/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4531/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4532/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4533/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4534/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4535/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4536/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4537/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4538/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4539/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4540/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4541/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4542/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4543/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4544/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4545/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4546/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4547/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4548/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4549/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4550/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4551/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4552/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4553/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4554/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4555/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4556/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4557/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4558/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4559/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4560/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4561/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4562/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4563/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4564/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4565/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4566/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4567/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4568/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4569/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4570/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4571/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4572/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4573/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4574/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4575/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4576/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4577/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4578/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4579/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4580/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4581/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4582/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4583/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4584/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4585/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4586/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4587/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4588/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4589/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4590/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4591/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4592/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4593/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4594/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4595/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4596/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4597/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4598/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4599/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4600/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4601/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4602/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4603/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4604/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4605/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4606/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4607/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4608/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4609/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4610/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4611/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4612/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4613/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4614/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4615/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4616/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4617/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4618/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4619/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4620/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4621/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4622/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4623/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4624/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4625/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4626/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4627/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4628/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4629/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4630/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4631/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4632/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4633/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4634/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4635/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4636/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4637/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4638/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4639/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4640/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4641/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4642/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4643/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4644/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4645/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4646/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4647/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4648/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4649/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4650/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4651/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4652/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4653/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4654/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4655/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4656/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4657/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4658/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4659/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4660/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4661/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4662/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4663/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4664/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4665/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4666/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4667/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4668/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4669/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4670/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4671/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4672/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4673/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4674/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4675/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4676/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4677/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4678/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4679/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4680/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4681/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4682/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4683/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4684/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4685/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4686/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4687/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4688/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4689/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4690/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4691/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4692/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4693/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4694/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4695/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4696/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4697/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4698/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4699/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4700/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4701/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4702/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4703/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4704/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4705/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4706/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4707/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4708/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4709/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4710/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4711/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4712/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4713/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4714/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4715/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4716/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4717/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4718/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4719/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4720/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4721/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4722/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4723/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4724/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4725/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4726/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4727/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4728/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4729/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4730/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4731/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4732/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4733/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4734/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4735/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4736/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4737/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4738/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4739/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4740/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4741/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4742/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4743/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4744/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4745/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4746/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4747/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4748/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4749/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4750/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4751/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4752/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4753/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4754/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4755/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4756/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4757/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4758/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4759/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4760/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4761/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4762/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4763/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4764/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4765/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4766/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4767/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4768/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4769/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4770/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4771/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4772/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4773/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4774/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4775/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4776/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4777/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4778/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4779/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4780/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4781/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4782/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4783/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4784/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4785/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4786/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4787/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4788/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4789/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4790/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4791/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4792/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4793/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4794/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4795/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4796/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4797/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4798/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4799/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4800/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4801/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4802/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4803/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4804/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4805/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4806/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4807/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4808/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4809/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4810/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4811/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4812/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4813/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4814/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4815/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4816/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4817/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4818/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4819/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4820/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4821/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4822/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4823/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4824/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4825/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4826/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4827/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4828/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4829/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4830/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4831/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4832/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4833/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4834/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4835/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4836/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4837/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4838/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4839/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4840/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4841/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4842/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4843/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4844/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4845/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4846/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4847/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4848/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4849/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4850/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4851/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4852/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4853/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4854/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4855/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4856/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4857/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4858/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4859/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4860/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4861/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4862/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4863/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4864/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4865/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4866/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4867/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4868/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4869/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4870/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4871/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4872/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4873/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4874/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4875/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4876/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4877/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4878/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4879/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4880/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4881/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4882/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4883/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4884/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4885/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4886/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4887/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4888/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4889/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4890/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4891/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4892/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4893/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4894/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4895/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4896/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4897/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4898/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4899/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4900/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4901/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4902/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4903/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4904/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4905/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4906/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4907/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4908/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4909/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4910/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4911/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4912/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4913/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4914/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4915/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4916/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4917/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4918/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4919/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4920/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4921/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4922/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4923/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4924/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4925/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4926/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4927/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4928/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4929/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4930/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4931/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4932/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4933/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4934/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4935/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4936/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4937/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4938/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4939/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4940/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4941/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4942/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4943/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4944/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4945/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4946/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4947/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4948/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4949/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4950/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4951/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4952/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4953/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4954/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4955/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4956/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4957/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4958/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4959/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4960/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4961/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4962/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4963/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4964/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4965/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4966/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4967/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4968/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4969/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4970/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4971/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4972/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4973/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4974/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4975/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4976/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4977/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4978/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4979/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4980/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4981/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4982/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4983/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4984/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4985/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4986/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4987/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4988/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4989/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4990/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4991/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4992/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4993/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4994/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4995/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4996/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4997/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4998/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 4999/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Epoch 5000/5000, Loss: 14.959055025306705, Weights: [0.29276132 0.05260753 0.65463115]\n",
      "Final Brand: Disney, Confidence Score: 0.3640371769903729\n",
      "Weights: [0.29276132 0.05260753 0.65463115]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import copy\n",
    "\n",
    "# Example dataset\n",
    "data=copy.deepcopy(data_set)\n",
    "\n",
    "# Aggregating confidence scores\n",
    "def aggregate_confidences(inputs, weights):\n",
    "    aggregated_scores = defaultdict(float)\n",
    "    for i, source in enumerate(['gemini_results', 'vi_results', 'ocr_text']):\n",
    "        for brand, score in inputs[source]:\n",
    "            aggregated_scores[brand] += weights[i] * score\n",
    "    return aggregated_scores\n",
    "\n",
    "# Compute final prediction\n",
    "def get_final_brand(inputs, weights):\n",
    "    aggregated_scores = aggregate_confidences(inputs, weights)\n",
    "    total_score = sum(aggregated_scores.values())\n",
    "    if total_score == 0:\n",
    "        probabilities = {brand: 1 / len(aggregated_scores) for brand in aggregated_scores}\n",
    "    else:\n",
    "        probabilities = {brand: score / total_score for brand, score in aggregated_scores.items()}\n",
    "    final_brand = max(probabilities, key=probabilities.get)\n",
    "    final_confidence = probabilities[final_brand]\n",
    "    return final_brand, final_confidence, probabilities\n",
    "\n",
    "# Calculate cross-entropy loss\n",
    "def cross_entropy_loss(predicted_probs, actual_label, all_brands):\n",
    "    epsilon = 1e-15\n",
    "    predicted_probs = np.array([predicted_probs.get(brand, epsilon) for brand in all_brands])\n",
    "    predicted_probs = np.clip(predicted_probs, epsilon, 1 - epsilon)\n",
    "    actual_vector = np.array([1 if brand == actual_label else 0 for brand in all_brands])\n",
    "    return -np.sum(actual_vector * np.log(predicted_probs))\n",
    "\n",
    "# Optimize weights using gradient descent\n",
    "def optimize_weights(data_set, learning_rate=0.009, epochs=5000):\n",
    "    weights = np.ones(3) / 3\n",
    "    all_brands = set()\n",
    "    for entry in data_set:\n",
    "        for source in ['gemini_results', 'vi_results', 'ocr_text']:\n",
    "            all_brands.update([brand for brand, _ in entry['inputs'][source]])\n",
    "    all_brands = list(all_brands)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        weight_gradients = np.zeros(3)\n",
    "        for entry in data_set:\n",
    "            actual_final = entry['output']['final'][0]\n",
    "            final_brand, _, predicted_probs = get_final_brand(entry['inputs'], weights)\n",
    "            loss = cross_entropy_loss(predicted_probs, actual_final, all_brands)\n",
    "            total_loss += loss\n",
    "            for i, source in enumerate(['gemini_results', 'vi_results', 'ocr_text']):\n",
    "                for brand, score in entry['inputs'][source]:\n",
    "                    gradient = (predicted_probs[brand] - (1 if brand == actual_final else 0)) * score\n",
    "                    weight_gradients[i] += gradient\n",
    "        weights -= learning_rate * weight_gradients\n",
    "        weights = np.clip(weights, 0, 1)\n",
    "        weights /= np.sum(weights)\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss}, Weights: {weights}\")\n",
    "    return weights\n",
    "\n",
    "# Train the model\n",
    "final_weights = optimize_weights(data)\n",
    "\n",
    "# Test case\n",
    "test_data = [\n",
    "    {'inputs': {'gemini_results': [('Disney', 1.00), ('Ziploc', 1.00), ('SC Johnson', 1.00)], \n",
    "                'vi_results': [('Ziploc', 0.99), ('The Walt Disney Company', 0.99)], \n",
    "                'ocr_text': [('Disney', 0.90), ('Ziploc', 0.80), ('MIPS', 0.50)]}}\n",
    "]\n",
    "\n",
    "# Get predictions for test data\n",
    "for entry in test_data:\n",
    "    final_brand, final_confidence, weights = get_final_brand(entry['inputs'], final_weights)\n",
    "    print(f\"Final Brand: {final_brand}, Confidence Score: {final_confidence}\")\n",
    "    print(f\"Weights: {final_weights}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
